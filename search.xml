<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Redis 集群规范]]></title>
      <url>%2F2018%2Fdatabase-redis-cluster-spec%2F</url>
      <content type="text"><![CDATA[摘要:参考官方文档Redis Cluster spec总结的Redis规范 正文:Redis 集群规范安全写入两个写入丢失的可能 写入操作到达主节点，主节点异步冗余备份还没传播到从节点时候主节点挂了，该写入会丢失 几率很小，虽然是异步备份，但主节点写入并回复客户端的时间和传播给slave节点时间大致相同 故障转移时候，一个没有更新路由表的客户端会在主–&gt;从之前做写入操作（几率更小） 原因：长时间无法被大多数主节点访问的节点会被故障转移掉，不再接受任何写入操作，其修复好后仍然会有一小段时间拒绝写入。好让其他节点有时间去告知配置信息的变更 可用性每个master节点都至少要有一个salve节点可达，最好是从节点数量&gt;主节点数量 master遇到故障转移到slave后，集群会再次恢复可用 master故障修复后会重新加入集群成为新master的从节点，防止下次故障 当从节点有两个就可以多一次故障转移 性能在Redis的集群中，节点并不是把命令转发到负责键的节点上，而是把客户端重定向到服务一定范围内的键的节点上。 最终客户端获得一份最新的集群路由表，里面有写着哪些节点服务哪些键，所以在正常操作中客户端是直接联系到对应的节点来发送指令。 由于使用了异步复制，节点不会等待其他节点对写入操作的回复 所以普通操作是可以被处理得跟在Redis单机版一样的，在一个拥有 N 个master节点的 Redis 集群中，由于线性扩展的设计，你可以认为同样的操作在集群上的性能是Redis单机版的n倍 键分布模型Redis 集群的键空间被分割为 16384 个槽（slot）， 集群的最大节点数量也是 16384 个。 推荐的最大节点数量为 1000 个左右。 每个主节点都负责处理 16384 个哈希槽的其中一部分。 参考链接Redis Cluster Spec Redis 集群规范]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis 集群部署]]></title>
      <url>%2F2018%2Fdatabase-redis-cluster%2F</url>
      <content type="text"><![CDATA[摘要:最近工作搭建redis集群时候的笔记 正文:Redis集群搭建版本 系统: CentOS 7.4 Redis: redis-4.0.2 ruby: 2.4.2 安装gcc1234rpm -ivh gcc-c++-4.8.5-16.el7.x86_64.rpm --nodepsPreparing... ################################# [100%]Updating / installing... 1:gcc-c++-4.8.5-16.el7 ################################# [100%] 安装Redis1234cd /opt tar xzf redis-4.0.2.tar.gzcd redis-4.0.2make 如果因为编译失败可以使用make distclean 创建节点 创建redis-cluster目录 123mkdir /opt/redis-4.0.2/redis-clustercd /opt/redis-4.0.2/redis-clustermkdir 7100 7101 7102 分别修改这三个配置文件，把如下redis.conf 配置内容粘贴进去 123vi 7100/redis.confvi 7101/redis.conf vi 7102/redis.conf redis.conf 12345678port 7100bind 192.168.103.14daemonize yespidfile /var/run/redis_7100.pidcluster-enabled yescluster-config-file nodes_7100.confcluster-node-timeout 20100appendonly yes 配置说明 1234567891011121314151617181920212223#端口7100,7101,7102port 7100#默认ip为127.0.0.1，需要改为其他节点机器可访问的ip，否则创建集群时无法访问对应的端口，无法创建集群bind 192.168.103.14#redis后台运行daemonize yes#pidfile文件对应7100，7101，7102pidfile /var/run/redis_7100.pid#开启集群，把注释#去掉cluster-enabled yes#集群的配置，配置文件首次启动自动生成 7100，7101，7102 cluster-config-file nodes_7100.conf#请求超时，默认15秒，可自行设置 cluster-node-timeout 20100 #aof日志开启，有需要就开启，它会每次写操作都记录一条日志appendonly yes 在另外一台机器上重复以上操作，目录和端口改为7103、7104、7105 启动集群12345# 第一台机器上执行 3个节点for((i=0;i&lt;=2;i++)); do /opt/redis-4.0.2/src/redis-server /opt/redis-4.0.2/redis-cluster/710$i/redis.conf; done#第二台机器上执行 3个节点for((i=3;i&lt;=5;i++)); do /opt/redis-4.0.2/src/redis-server /opt/redis-4.0.2/redis-cluster/710$i/redis.conf; done 检查服务12ps -ef | grep redis //redis是否启动成功netstat -tnlp | grep redis //监听redis端口 搭建集群现在我们已经有了六个正在运行中的 Redis 实例，通过使用 Redis 集群命令行工具 redis-trib ， 编写节点配置文件的工作可以非常容易地完成： redis-trib 位于 Redis 源码的 src 文件夹中， 它是一个 Ruby 程序， 这个程序通过向实例发送特殊命令来完成创建新集群， 检查集群， 或者对集群进行重新分片（reshared）等工作。所以我们先来安装ruby。 安装ruby通过yum安装的ruby往往版本较低，这里使用安装包安装 下载地址 12345tar -xvzf ruby-2.4.2.tar.gzcd ruby-2.4.2./configuremakesudo make install 安装完成后，可以查看是否安装成功，若遇到没有输出版本可以重新打开命令窗口试试 1ruby -v 接下来我们安装redis依赖 1gem install redis 创建集群接下来我们使用 Redis 集群命令行工具 redis-trib，在其中一台机器上运行如下命令 1/opt/redis-4.0.2/src/redis-trib.rb create --replicas 1 192.168.103.14:7100 192.168.103.14:7101 192.168.103.14:7102 192.168.103.28:7103 192.168.103.28:7104 192.168.103.28:7105 会出现如下内容 12345678910111213141516171819202122&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:192.168.103.14:7100192.168.103.28:7103192.168.103.14:7101Adding replica 192.168.103.28:7104 to 192.168.103.14:7100Adding replica 192.168.103.14:7102 to 192.168.103.28:7103Adding replica 192.168.103.28:7105 to 192.168.103.14:7101M: c190d12629fd227c909caa96f5e978ff996364ed 192.168.103.14:7100 slots:0-5460 (5461 slots) masterM: 77ea96b2eb31b0dd44acc986fe8484358cd9863f 192.168.103.14:7101 slots:10923-16383 (5461 slots) masterS: b08c0a2e59ef7564eeda7f8d7ca08ec7f3766c1d 192.168.103.14:7102 replicates 76d59f4caaf766bea9122b1e6327e13721c8ca3bM: 76d59f4caaf766bea9122b1e6327e13721c8ca3b 192.168.103.28:7103 slots:5461-10922 (5462 slots) masterS: 77abb939328acb2198fe3e4a495c217d25b91cda 192.168.103.28:7104 replicates c190d12629fd227c909caa96f5e978ff996364edS: 82f48a3c8d0d684fe31254fd4115d8c3b5622f4e 192.168.103.28:7105 replicates 77ea96b2eb31b0dd44acc986fe8484358cd9863fCan I set the above configuration? (type &apos;yes&apos; to accept): yes 输入yes继续 123456789101112131415161718192021222324252627&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join....&gt;&gt;&gt; Performing Cluster Check (using node 192.168.103.14:7100)M: c190d12629fd227c909caa96f5e978ff996364ed 192.168.103.14:7100 slots:0-5460 (5461 slots) master 1 additional replica(s)M: 77ea96b2eb31b0dd44acc986fe8484358cd9863f 192.168.103.14:7101 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: 82f48a3c8d0d684fe31254fd4115d8c3b5622f4e 192.168.103.28:7105 slots: (0 slots) slave replicates 77ea96b2eb31b0dd44acc986fe8484358cd9863fS: b08c0a2e59ef7564eeda7f8d7ca08ec7f3766c1d 192.168.103.14:7102 slots: (0 slots) slave replicates 76d59f4caaf766bea9122b1e6327e13721c8ca3bM: 76d59f4caaf766bea9122b1e6327e13721c8ca3b 192.168.103.28:7103 slots:5461-10922 (5462 slots) master 1 additional replica(s)S: 77abb939328acb2198fe3e4a495c217d25b91cda 192.168.103.28:7104 slots: (0 slots) slave replicates c190d12629fd227c909caa96f5e978ff996364ed[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 可以看到master节点分别是14:7100(0-5460)、14:7101(10923-16383)、28:7103(5461-10922)，salve节点分别是28:7150 、14:7102 、28:7104 对应关系可以根据上面可以看到分别是3主3从 若输入yes后出现 12345678910111213Can I set the above configuration? (type &apos;yes&apos; to accept): yes/usr/local/lib/ruby/gems/2.4.0/gems/redis-4.0.1/lib/redis/client.rb:119:in `call&apos;: ERR Slot 5798 is already busy (Redis::CommandError) from /usr/local/lib/ruby/gems/2.4.0/gems/redis-4.0.1/lib/redis.rb:2764:in `block in method_missing&apos; from /usr/local/lib/ruby/gems/2.4.0/gems/redis-4.0.1/lib/redis.rb:45:in `block in synchronize&apos; from /usr/local/lib/ruby/2.4.0/monitor.rb:214:in `mon_synchronize&apos; from /usr/local/lib/ruby/gems/2.4.0/gems/redis-4.0.1/lib/redis.rb:45:in `synchronize&apos; from /usr/local/lib/ruby/gems/2.4.0/gems/redis-4.0.1/lib/redis.rb:2763:in `method_missing&apos; from /opt/redis-4.0.2/src/redis-trib.rb:212:in `flush_node_config&apos; from /opt/redis-4.0.2/src/redis-trib.rb:776:in `block in flush_nodes_config&apos; from /opt/redis-4.0.2/src/redis-trib.rb:775:in `each&apos; from /opt/redis-4.0.2/src/redis-trib.rb:775:in `flush_nodes_config&apos; from /opt/redis-4.0.2/src/redis-trib.rb:1296:in `create_cluster_cmd&apos; from /opt/redis-4.0.2/src/redis-trib.rb:1700:in `&lt;main&gt;&apos; 解决办法 1234567891011121314# 每个节点执行以下命令,然后重新执行创建集群命令/opt/redis-4.0.2/src/redis-cli -h 192.168.103.14 -p 7100192.168.103.14:7100&gt; flushallOK192.168.103.14:7100&gt; cluster reset softOK192.168.103.14:7100&gt; exit.../opt/redis-4.0.2/src/redis-cli -h 192.168.103.28 -p 7103192.168.103.28:7103&gt; flushallOK192.168.103.28:7103&gt; cluster reset softOK192.168.103.28:7103&gt; exit 集群验证连接集群测试1234567891011121314# 选择一个节点set值/opt/redis-4.0.2/src/redis-cli -c -h 192.168.103.28 -p 7104192.168.103.28:7104&gt; set name admin-&gt; Redirected to slot [5798] located at 192.168.103.28:7103OK192.168.103.28:7103&gt; get name&quot;admin&quot;192.168.103.28:7103&gt; exit# 换个节点测试[root@server28 /]# /opt/redis-4.0.2/src/redis-cli -c -h 192.168.103.14 -p 7101192.168.103.14:7101&gt; get name-&gt; Redirected to slot [5798] located at 192.168.103.28:7103&quot;admin&quot;192.168.103.28:7103&gt; exit 可以发现name &quot;admin&quot;被放置在28:7103主节点上，槽位是(5461-10922) 注: Redis 集群没有使用一致性hash, 而是引入了 哈希槽的概念. Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽.集群的每个节点负责一部分hash槽,举个例子,比如当前集群有3个节点,那么: 节点 A 包含 0 到 5500号哈希槽. 节点 B 包含5501 到 11000 号哈希槽. 节点 C 包含11001 到 16384号哈希槽. 这种结构很容易添加或者删除节点. 比如如果我想新添加个节点D, 我需要从节点 A, B, C中得部分槽到D上. 如果我想移除节点A,需要将A中的槽移到B和C节点上,然后将没有任何槽的A节点从集群中移除即可. 由于从一个节点将哈希槽移动到另一个节点并不会停止服务,所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态. 检查集群状态1234567891011121314151617181920/opt/redis-4.0.2/src/redis-trib.rb check 192.168.103.14:7100&gt;&gt;&gt; Performing Cluster Check (using node 192.168.103.14:7100)M: c190d12629fd227c909caa96f5e978ff996364ed 192.168.103.14:7100 slots:0-5460 (5461 slots) master 1 additional replica(s)M: 77ea96b2eb31b0dd44acc986fe8484358cd9863f 192.168.103.14:7101 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: 82f48a3c8d0d684fe31254fd4115d8c3b5622f4e 192.168.103.28:7105 slots: (0 slots) slave replicates 77ea96b2eb31b0dd44acc986fe8484358cd9863fS: b08c0a2e59ef7564eeda7f8d7ca08ec7f3766c1d 192.168.103.14:7102 slots: (0 slots) slave replicates 76d59f4caaf766bea9122b1e6327e13721c8ca3bM: 76d59f4caaf766bea9122b1e6327e13721c8ca3b 192.168.103.28:7103 slots:5461-10922 (5462 slots) master 1 additional replica(s)S: 77abb939328acb2198fe3e4a495c217d25b91cda 192.168.103.28:7104 slots: (0 slots) slave replicates c190d12629fd227c909caa96f5e978ff996364ed 列出集群节点12345678/opt/redis-4.0.2/src/redis-cli -c -h 192.168.103.14 -p 7101192.168.103.14:7101&gt; cluster nodes77abb939328acb2198fe3e4a495c217d25b91cda 192.168.103.28:7104@17104 slave c190d12629fd227c909caa96f5e978ff996364ed 0 1523435804915 5 connected76d59f4caaf766bea9122b1e6327e13721c8ca3b 192.168.103.28:7103@17103 master - 0 1523435804000 4 connected 5461-1092282f48a3c8d0d684fe31254fd4115d8c3b5622f4e 192.168.103.28:7105@17105 slave 77ea96b2eb31b0dd44acc986fe8484358cd9863f 0 1523435805918 6 connectedb08c0a2e59ef7564eeda7f8d7ca08ec7f3766c1d 192.168.103.14:7102@17102 slave 76d59f4caaf766bea9122b1e6327e13721c8ca3b 0 1523435803000 4 connected77ea96b2eb31b0dd44acc986fe8484358cd9863f 192.168.103.14:7101@17101 myself,master - 0 1523435803000 2 connected 10923-16383c190d12629fd227c909caa96f5e978ff996364ed 192.168.103.14:7100@17100 master - 0 1523435806920 1 connected 0-5460 打印集群信息123456789101112131415161718192.168.103.14:7101&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:2cluster_stats_messages_ping_sent:1605cluster_stats_messages_pong_sent:1682cluster_stats_messages_meet_sent:5cluster_stats_messages_sent:3292cluster_stats_messages_ping_received:1681cluster_stats_messages_pong_received:1610cluster_stats_messages_meet_received:1cluster_stats_messages_received:3292 节点cluster meet &lt;ip&gt; &lt;port&gt;将 ip 和 port 所指定的节点添加到集群当中 cluster forget &lt;node_id&gt; 从集群中移除 node_id 指定的节点 123456789101112192.168.103.14:7100&gt; cluster meet 192.168.103.28 7106OK192.168.103.14:7100&gt; cluster nodes047f60047efa74c6f597e935b8b5896c15057cf6 192.168.103.28:7106@17106 master - 0 1523448401000 0 connected77ea96b2eb31b0dd44acc986fe8484358cd9863f 192.168.103.14:7101@17101 master - 0 1523448401961 2 connected 10923-1638382f48a3c8d0d684fe31254fd4115d8c3b5622f4e 192.168.103.28:7105@17105 slave 77ea96b2eb31b0dd44acc986fe8484358cd9863f 0 1523448402964 6 connectedb08c0a2e59ef7564eeda7f8d7ca08ec7f3766c1d 192.168.103.14:7102@17102 slave 76d59f4caaf766bea9122b1e6327e13721c8ca3b 0 1523448403965 4 connected76d59f4caaf766bea9122b1e6327e13721c8ca3b 192.168.103.28:7103@17103 master - 0 1523448402000 4 connected 5461-1092277abb939328acb2198fe3e4a495c217d25b91cda 192.168.103.28:7104@17104 slave c190d12629fd227c909caa96f5e978ff996364ed 0 1523448404969 5 connectedc190d12629fd227c909caa96f5e978ff996364ed 192.168.103.14:7100@17100 myself,master - 0 1523448401000 1 connected 0-5460192.168.103.14:7100&gt; cluster forget 047f60047efa74c6f597e935b8b5896c15057cf6OK cluster nodes命令的结果含义如下： 节点ID IP:端口 标志: master, slave, myself, fail, … 如果是个从节点, 这里是它的主节点的NODE ID 集群最近一次向节点发送 PING 命令之后， 过去了多长时间还没接到回复。. 节点最近一次返回 PONG 回复的时间。 节点的配置纪元（configuration epoch）：详细信息请参考 Redis 集群规范 。 本节点的网络连接情况：例如 connected 。 节点目前包含的槽：例如 192.168.103.28:7103 目前包含号码为 5960 至 10921 的哈希槽。 使用redis-trib.rb 新增节点 添加master节点 1/opt/redis-4.0.2/src/redis-trib.rb add-node 192.168.103.28:7106 192.168.103.14:7100 添加salve节点(随机选一个主节点),前提是节点要为空 1/opt/redis-4.0.2/src/redis-trib.rb add-node --slave 192.168.103.28:7106 192.168.103.14:7100 添加salve节点(指定主节点为192.168.103.14:7101) 1/opt/redis-4.0.2/src/redis-trib.rb add-node --slave --master-id 77ea96b2eb31b0dd44acc986fe8484358cd9863f 192.168.103.28:7106 192.168.103.14:7100 ​ 也可以使用cluster replicate 1192.168.103.28:7106&gt; cluster replicate 77ea96b2eb31b0dd44acc986fe8484358cd9863f 使用redis-trib.rb 移除节点 1/opt/redis-4.0.2/src/redis-trib.rb del-node 192.168.103.14:7100 `&lt;node-id&gt;` 参考链接CentOs7.3 搭建 Redis-4.0.1 Cluster 集群服务 Redis 集群教程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Cloud Netflix OSS 学习总结]]></title>
      <url>%2F2018%2FSpringCloud-Netflix%2F</url>
      <content type="text"><![CDATA[摘要: 本篇博客是使用SpringCloud框架开发微服务时候的一篇技术分享 正文:Spring Cloud Netflix OSSSpring Cloud Eureka提供了对Netflix开源项目的集成，使我们可以以Spring Boot编程风格使用Netflix旗下相关框架，只需要在程序里添加注解，就可以使用成熟的Netflix组件(Eureka、Hystrix、Zuul、Ribbon、Sidecar) Eureka客户端 向Eureka注册服务 高可用(HA) 多注册中心主机 如果配置了多个Eureka注册服务器，那么默认情况只有一台可用的服务器，存在注册信息。如果Down掉了，则会选择下一台可用的Eureka服务器。 配置 应用间隔 registry-fetch-interval-seconds:30 去服务端获取注册信息的间隔时间 同步间隔 instance-info-replication-interval-seconds:30 更新实例信息的变化到服务端的间隔时间 参考链接 注意 端口不要使用0 Eureka缓存 Eureka Server对注册列表进行缓存，默认时间为30s。 Eureka Client对获取到的注册信息进行缓存，默认时间为30s。 Ribbon会从上面提到的Eureka Client获取服务列表，将负载均衡后的结果缓存30s。 Eureka服务端 注册中心对比 Feature Consul zookeeper etcd euerka 服务健康检查 服务状态，内存，硬盘等 (弱)长连接，keepalive 连接心跳 可配支持 多数据中心 支持 — — — kv存储服务 支持 支持 支持 — 一致性 raft paxos raft — cap ca cp cp ap 使用接口(多语言能力) 支持http和dns 客户端 http/grpc http（sidecar） watch支持 全量/支持long polling 支持 支持 long polling 支持 long polling/大部分增量 自身监控 metrics — metrics metrics 安全 acl /https acl https支持（弱） — spring cloud集成 已支持 已支持 已支持 已支持 CAP C 数据一致性 一致性是指数据的原子性，在经典的数据库中通过事务来保障，事务完成时，无论成功或回滚，数据都会处于一致的状态，在分布式环境下，一致性是指多个节点数据是否一致 raft A 服务可用性 服务一直保持可用的状态，当用户发出一个请求，服务能在一定的时间内返回结果 P 网络分区故障的容错性 在分布式应用中，可能因为一些分布式的原因导致系统无法运转，好的分区容忍性，使应用虽然是一个分布式系统，但是好像一个可以正常运转的整体 Consul 服务发现 健康检查 键值存储 多数据中心 官网 Spring Cloud Consul 参考文档 Eureka Server高可用配置 12345678910111213141516171819---spring: profiles: peer1eureka: instance: hostname: peer1 client: serviceUrl: defaultZone: http://peer2/eureka/---spring: profiles: peer2eureka: instance: hostname: peer2 client: serviceUrl: defaultZone: http://peer1/eureka/ 参考文档 Spring Cloud Ribbon主要功能是为REST客户端实现负载均衡 Netflix Ribbon 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; Ribbon 客户端 12345678910@SpringBootApplication@RibbonClients(&#123; @RibbonClient(name = "service-provider")&#125;)public class Application &#123; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 配置 application.properties 12service-provider.ribbon.listOfServers = \ http://$&#123;host&#125;:$&#123;port&#125; Netflix Ribbon 整合 Eureka Ribbon 客户端 123456789101112@SpringBootApplication@RibbonClients(&#123; @RibbonClient(name = "service-provider")&#125;)@EnableDiscoveryClientpublic class Application &#123; @Bean @LoadBalanced public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 配置 Spring Cloud OpenFeign 发展 9.0.0版本之后groupId io.netflix.feign更改为io.github.openfeign 对应依赖spring-cloud-starter-feign–&gt;spring-cloud-starter-openfeign 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt; feign 客户端 Application.java 123456789@SpringBootApplication@EnableFeignClientspublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; feignClient.java 12345@FeignClient(value = "ms-business-task-engine-server")public interface ITaskEngineService &#123; @RequestMapping(value = "/TaskQueue/addTaskToQueue",method = RequestMethod.POST) BaseResponse addTaskToQueue(@RequestBody List&lt;SubTaskDTO&gt; subTaskDTOList);&#125; 配置参考ribbon Spring Cloud Hystrixhystrix可帮助隔离每个服务，使单个服务的响应失败，避免微服务架构中因个别服务出现异常而引起级联故障蔓延。 特性 断路器机制(断路–&gt;半开–&gt;恢复) 资源隔离 熔断降级 Hystrix Dashboard 监控Spring Cloud Zuul在没有网关的时候，随着系统不断庞大，运维维护越来越复杂，接口校验逻辑的冗余越来越多，校验逻辑升级更为复杂。 ZuulFilter过滤器类型 pre 路由之前执行 route 路由请求时被调用 post 在route和error过滤器之后被过滤 error 处理请求发生错误时候被调用 过滤器执行顺序 order越小，优先级越高 过滤器是否被执行 shouldFilter = true(结合yaml控制开启) 过滤器具体逻辑 run() Routes路由规则与列表 Spring Cloud Sidecar非JVM语言接入SpringCloud的两种方案 Sidecar 必须去实现一个健康检查接口 只有状态，服务治理只能从网关层控制流量 自己实现注册中心API Http接口(推荐) 示例代码-github]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK8的ConcurrentHashMap源码学习笔记]]></title>
      <url>%2F2018%2Fjavase-Map-ConcurrentHashMap%2F</url>
      <content type="text"><![CDATA[摘要:继上篇HashMap分析后，接下来分析ConcurrentHashMap的put和扩容… 正文:目标 首要目标:保持并发的可读性,同时最小化更新产生的竞争 次要目标:保持与HashMap相同或更好的空间消耗,并支持许多线程在空表上的高初始插入率。 设计 使用CAS代替之前版本的分段锁 红黑树 putVal()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178/** * sizeCtl：表初始化和调整控制。当负值时，表被初始化或调整大小:-1用于初始化，-(1 +主动调整大小的线程数)用于调整大小，默认为0。初始化完成后，保存下一个元素count值，以调整表的大小。 */private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; //volatile读 while ((tab = table) == null || tab.length == 0) &#123; //如果一个线程发现sizeCtl&lt;0，意味着另外的线程执行CAS操作成功，当前线程只需要让出cpu时间片 //volatile读 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin //第一次put操作的线程会执行Unsafe.compareAndSwapInt方法修改sizeCtl为-1，有且只有一个线程能够修改成功，其它线程通过Thread.yield()让出CPU时间片等待table初始化完成 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125;/** * 使用Unsafe.getObjectVolatile()获取数组元素，原因是Java数组是无法表达元素是volatile、final的 */final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) //初始化 tab = initTable(); //为空，则设置为头节点(CAS) else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; //节点添加 V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; //达到阈值转为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125;/** * 如果当前table的个数未达到MIN_TREEIFY_CAPACITY(64)则先进行扩容 */private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) tryPresize(n &lt;&lt; 1); else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; synchronized (b) &#123; if (tabAt(tab, index) == b) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &#125; setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125;&#125;/** * 扩容(size = 2n) */private final void tryPresize(int size) &#123; //size如果大于max(Int)/2 则直接扩为max(Int),否则为大于3*size + 1的最小二次幂 int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; //volatile读，sizeCtl大于0指没有进行初始化和扩容的操作 while ((sc = sizeCtl) &gt;= 0) &#123; Node&lt;K,V&gt;[] tab = table; int n; if (tab == null || (n = tab.length) == 0) &#123; n = (sc &gt; c) ? sc : c; //执行Unsafe.compareAndSwapInt方法修改sizeCtl为-1，有且只有一个线程能够修改成功，其它线程通过Thread.yield()让出CPU时间片等待table初始化完成 if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; @SuppressWarnings("unchecked") //初始化 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; &#125; &#125; //最大了 else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; else if (tab == table) &#123; int rs = resizeStamp(n); if (sc &lt; 0) &#123; //竞争失败 Node&lt;K,V&gt;[] nt; //正在咨询大佬... if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; //竞争成功 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); &#125; &#125;&#125; transfer()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; //分片 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range //nextTab初始化(CAS保证只有一个线程调用此方法) if (nextTab == null) &#123; // initiating try &#123; //根据当前数组长度n，新建一个两倍长度的数组nextTable @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; //初始化ForwardingNode(nextTab) 用于并发移动时，其它线程可以知道这个节点正在被移动，或已经被移动 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; //循环的关键变量，判断是否已经扩容完成，完成就return，退出循环 boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; while (advance) &#123; int nextIndex, nextBound; //i指当前处理的槽位序号，bound指需要处理的槽位边界 if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; nextTable = null; table = nextTab; //sizeCtl设为新数组大小的3/4(2n-n/2) sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; //resizeStamp()没看懂 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) &#123; //使用fn&amp;n可以快速把链表中的元素分为两份 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; //放到新Tab setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); //红黑树同样是根据h&amp;n分为两份 if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; //拆分之后如果长度小于默认阈值(6)则转为链表 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; //设置新的Tab setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125; HashMap vs ConcurrentHashMap ConcurrentHashMap是线程安全的，在并发环境下不需要额外同步 ConcurrentHashMap有很好的扩展性，在多线程环境下性能方面比做了同步的HashMap要好，但是在单线程环境下，HashMap会比ConcurrentHashMap好一点 参考链接 深入分析ConcurrentHashMap1.8的扩容实现 seaswalker/JDK 晚安~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK8的HashMap源码学习笔记]]></title>
      <url>%2F2018%2Fjavase-Map-HashMap%2F</url>
      <content type="text"><![CDATA[摘要:接下来开始学习JDK常用类的源码部分，从HashMap开始…. 正文:概念HashMap是数组+链表+红黑树实现的，红黑树是在JDK8中增加的，优化了链表过长的效率问题 泊松分布HashMap源码注释有提到这个概念，泊松分布是单位时间内独立事件发生次数的概率分布，指数分布是独立事件的时间间隔的概率分布，可以参考阮一峰泊松分布博客 设计方法参数 都会带hash值作为参数(通常由公共参数提供)，允许它们彼此调用而无需重新计算用户哈希代码。 全局变量1234567static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 默认初始容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //最大容量(超出则扩为(2^31)-1)static final float DEFAULT_LOAD_FACTOR = 0.75f; //默认加载因子static final int TREEIFY_THRESHOLD = 8; //转树的阈值static final int MIN_TREEIFY_CAPACITY = 64; //当桶数组容量小于该值时，优先进行扩容，而不是树化(容量大小会影响碰撞率)static final int UNTREEIFY_THRESHOLD = 6; //红黑树转链表阈值(扩容时候红黑树拆分用到)int threshold; //当前HashMap所能容纳键值对数量的最大值 算threshold的方法： 123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; tableSizeFor()方法作用是算出大于或等于cap的最小2的幂，如2^5+1的结果则是2^6也就是64 hash()方法1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 可以看到在JDK8的实现中，优化了高位运算的算法，自己的高半区和低半区做异或，减少了低位的碰撞率。 putVal()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //初始化buckets table+为null扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //位置为null直接插入新的节点 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //如果hash值相同并且key相同则直接覆盖 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //判断该链是不是红黑树，是的话走Tree版本的putVal else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //否则则是链表 else &#123; for (int binCount = 0; ; ++binCount) &#123; //如果下个节点为空则放入下个节点 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //链表长度大于8转换为红黑树进行处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //覆盖 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //超出当前容量最大值就扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; resize()方法我们先来看下扩容机制，在HashMap中元素位置都是2的幂，接下来我们来看具体代码实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; //如果当前容量大于默认值2^30，则扩容至2^31-1 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //double else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //initial capacity else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //默认构造方法初始化Cap else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //newThr 为 0 时，按阈值计算公式进行计算 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; //把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) //对红黑树进行拆分 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; //遍历链表 do &#123; next = e.next; //原位置(根据0和非0判断是否扩容) if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; //原位置+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); //原位置的放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; //原位置+oldCap的放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; split()方法该方法是红黑树拆分方法，普通链表需要拆分，红黑树也同样需要拆分 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; //对红黑树节点进行分组(同链表一个原理) for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; if (loHead != null) &#123; //如果 loHead 不为空，且链表长度小于等于 6，则将红黑树转成链表 if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; //原位置的放到bucket里 tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; //原位置+oldCap的放到bucket里 tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125;&#125; untreeify()方法此方法是将红黑树转为链表 1234567891011121314151617final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; //转为Node Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd;&#125;Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(p.hash, p.key, p.value, next);&#125; 晚安~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[XXL-JOB使用笔记]]></title>
      <url>%2F2018%2Fscheduler-xxl-job%2F</url>
      <content type="text"><![CDATA[摘要:XXL-JOB是一个轻量级分布式任务调度框架，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用正文: XXL-JOB的介绍XXL-JOB是一个轻量级分布式任务调度框架，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用 XXL-JOB快速入门文档地址 中文文档 English Documentation 下载源码 源码仓库地址 Release Download https://github.com/xuxueli/xxl-job Download http://gitee.com/xuxueli0323/xxl-job Download 配置部署”调度中心”初始化“调度数据库”1xxl-job\doc\db\tables_xxl_job.sql 修改数据库配置信息1xxl-job\xxl-job-admin\src\main\resources\xxl-job-admin.properties 打包在xxl-job根目录下执行 1mvn clean package 部署“调度中心” 找到xxl-job-admin的target目录 1xxl-job\xxl-job-admin\target\xxl-job-admin-1.9.1-SNAPSHOT.war 更改名字为xxl-job-admin.war,放在tomcat的webapps下,在bin文件夹双击执行startup.bat 访问http://localhost:8080/xxl-job-admin 登录(密码在xxl-job-admin.properties)后界面如下图所示: Docker部署”调度中心” PreBuild.sh 123#!/bin/bashdocker rm -f $(docker ps -a | grep &quot;tomcat/xxl-job-admim&quot;| awk &apos;&#123; print $1 &#125;&apos;) &gt;/dev/null 2&gt;&amp;1docker rmi -f tomcat/xxl-job-admim &gt;/dev/null 2&gt;&amp;1 Dockerfile 12345678FROM tomcat:8## db设置为获取环境变量 方便动态传参ENV driverClass com.mysql.jdbc.DriverENV url jdbc:mysql://localhost:3306/xxl-job?useUnicode=true&amp;characterEncoding=UTF-8ENV user rootENV password rootADD xxl-job-admin.war /usr/local/tomcat/webapps/CMD [&quot;catalina.sh&quot;, &quot;run&quot;] Dockerbuild.sh 1docker build -t tomcat/xxl-job-admim . DockerRun.sh 1docker run --restart=always -d -p 8997:8080 tomcat/xxl-job-admim &gt;/dev/null 2&gt;&amp;1 配置部署“执行器项目”参考官方Demo1xxl-job\xxl-job-executor-samples\xxl-job-executor-sample-springboot 在根目录 mvn clean package然后执行java -jar xxx.jar或者IDE启动SpringBoot 页面配置 新增执行器 打开“调度中心”的执行器管理，发现有一个默认的，AppName正对应xxl-job-executor-sample-springboot服务配置的xxl.job.executor.appname，此时可以使用默认的无需添加。 新增任务 打开”调度中心”的任务管理，点击新增任务： 配置参考如下配置，JobHandler填写xxl-job-executor-sample-springboot的DemoJobHandler.java类上的@JobHandler(value=&quot;demoJobHandler&quot;)value值，Cron表达式可以参考在线Cron表达式生成器 保存成功后点击执行按钮 查看日志点击任务右侧的日志按钮，可以查看该任务的日志： 点击执行日志可以看到当前执行的log,对应xxl-job-executor-sample-springbootDemo的DemoJobHandler.java的代码:]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Validator 使用总结]]></title>
      <url>%2F2018%2Fframe-validator%2F</url>
      <content type="text"><![CDATA[摘要:祝大家元旦快乐！在日常开发中，前台对参数校验后，为了避免用户直接使用http工具直接向后台发起不合法请求，后台往往也需要校验，本文将要介绍的是使用Validator对数据进行校验。 正文:介绍首先说下大家常用的hibernate-validator，它是对JSR-303/JSR-349标准的实现，然后spring为了给开发者提供便捷集成了 hibernate-validator，默认在springmvc模块。 依赖本文所介绍皆在springboot应用的基础上，首先加上web模块： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 可以查看其子依赖，发现web模块默认使用了hibernate-validator： 1234567891011121314151617181920&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;&lt;/dependency&gt; 对实体类添加校验1234567891011121314151617181920212223242526public class AgentTrustor implements Serializable,UniqueVerifiableVO &#123; private static final long serialVersionUID = 4095871718305603749L; /** * 主键ID */ @Id @ApiModelProperty(value="主键ID", required = true) private Integer fid; /** * 代理人代码 */ @Length(min = 3,message = "代理人代码位数至少三位") @Column(name = "ftrustor_id") @ApiModelProperty(value="代理人代码", required = true) private String ftrustorId; /** * 联系人邮箱 */ @Email(message = "邮箱格式错误") @Column(name = "femail") @ApiModelProperty(value="联系人邮箱", required = true) private String femail;&#125; 通过注释名即可推断出校验的内容，message用作校验失败时的提示信息。 对Rest层添加校验1234567@ApiOperation(value="新增", notes="") @PostMapping(value = "") //@Transactional(rollbackFor=Exception.class) public ObjectRestResponse&lt;AgentTrustor&gt; add(@RequestBody @Validated AgentTrustor agentTrustor) throws BaseException&#123; agentTrustorBiz.bizInsertSelective(agentTrustor); return new ObjectRestResponse&lt;AgentTrustor&gt;().rel(true); &#125; 统一异常的处理经过对校验异常的debug发现，该异常为MethodArgumentNotValidException： 可以看到该异常对象的结构，同样我们可以根据其结构解析出想要的结果： 12345678910111213@ExceptionHandler(MethodArgumentNotValidException.class) public BaseResponse validExceptionHandler(HttpServletResponse response, MethodArgumentNotValidException ex) &#123; BindingResult bindingResult = ex.getBindingResult(); StringBuffer stringBuffer = new StringBuffer(); if(bindingResult.hasErrors())&#123; for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; //该格式仅仅作为response展示和log作用，前端应自己做校验 stringBuffer.append(fieldError.getObjectName() + "--" + fieldError.getDefaultMessage() + " "); &#125; &#125; logger.error(stringBuffer.toString()); return new BaseResponse(HttpStatus.BAD_REQUEST.value(),stringBuffer.toString()); &#125; 上面代码是统一异常处理中的一部分，主要是用来处理参数校验产生的MethodArgumentNotValidException异常。 分组校验当我们遇到不同场景需要有不同的校验规则时候，我们可以使用分组校验。如：一个请求只校验id,一个请求只校验email： 123456789101112131415161718192021222324252627282930public class AgentTrustor implements Serializable,UniqueVerifiableVO &#123; private static final long serialVersionUID = 4095871718305603749L; /** * 主键ID */ @Id @ApiModelProperty(value="主键ID", required = true) private Integer fid; /** * 代理人代码 */ @Length(min = 3,message = "代理人代码位数至少三位",groups = &#123;ID.class&#125;) @Column(name = "ftrustor_id") @ApiModelProperty(value="代理人代码", required = true) private String ftrustorId; /** * 联系人邮箱 */ @Email(message = "邮箱格式错误",groups = &#123;EMAIL.class&#125;) @Column(name = "femail") @ApiModelProperty(value="联系人邮箱", required = true) private String femail; public interface ID&#123;&#125;; public interface EMAIL&#123;&#125;;&#125; 根据需要在@Validated属性中指定需要校验的分组名，可以指定1到多个。指定到的分组名会全部进行校验，不指定的不校验 1234567@ApiOperation(value="新增", notes="") @PostMapping(value = "") //@Transactional(rollbackFor=Exception.class) public ObjectRestResponse&lt;AgentTrustor&gt; add(@RequestBody @Validated(AgentTrustor.ID.class) AgentTrustor agentTrustor) throws BaseException&#123; agentTrustorBiz.bizInsertSelective(agentTrustor); return new ObjectRestResponse&lt;AgentTrustor&gt;().rel(true); &#125; APIJSR提供的校验注解 12345678910111213@Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式 Hibernate Validator提供的校验注解 12345@NotBlank(message =) 验证字符串非null，且长度必须大于0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[docker部署基于nodejs的vue应用]]></title>
      <url>%2F2017%2FDocker-Nodejs-Vue%2F</url>
      <content type="text"><![CDATA[摘要:use Docker containers for Vue.js applications 正文:环境准备安装docker，具体操作参考官方文档。 Vue项目准备- 在项目根目录下，添加Dockerfile文件，Dockerfile是一个文本文档，其中包含用户可以在命令行上调用以构建镜像的所有命令(注意要先清除node_modules文件夹内容)1234567891011121314151617181920212223242526#指定我们的基础镜像是node，版本是v8.0.0 指定的基础image可以是官方远程仓库中的，也可以位于本地仓库 FROM node:8.0.0 #指定维护者的信息 MAINTAINER mser #将根目录下的文件都copy到container（运行此镜像的容器）文件系统的app文件夹下 ADD . /app/ #cd到app文件夹下 WORKDIR /app#安装项目依赖包 RUN npm install RUN npm rebuild node-sass --force #配置环境变量 ENV HOST 0.0.0.0 ENV PORT 9528 #容器对外暴露的端口号 EXPOSE 9528 #容器启动时执行的命令 每个Dockerfile只有一个CMD命令 多了则会覆盖之前的CMD CMD [&quot;npm&quot;, &quot;run&quot;,&quot;dev&quot;] 构建镜像- 查看本地docker镜像1234[root@localhost AG-Admin-v2.0]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/sebp/elk latest 2918030b8729 8 days ago 1.051 GBdocker.io/node 8.0.0 065e283f68bd 5 months ago 666.5 MB - build123456789101112[root@localhost AG-Admin-v2.0]# docker build -t ms-ui:1.0 .Sending build context to Docker daemon 3.897 MBStep 1 : FROM node:8.0.0 ---&gt; 065e283f68bdStep 2 : MAINTAINER EOI---&gt; Running in 275025d855c0 ---&gt; e66a97693ac5Removing intermediate container 275025d855c0Step 3 : ADD . /app/ ---&gt; bbb817cfbb8b.....省略一万行Successfully built 6af9d7ffb2ab - 启动镜像12345678[root@localhost AG-Admin-v2.0]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEms-ui 1.0 6af9d7ffb2ab 2 minutes ago 920.5 MBdocker.io/sebp/elk latest 2918030b8729 8 days ago 1.051 GBdocker.io/node 8.0.0 065e283f68bd 5 months ago 666.5 MB[root@localhost AG-Admin-v2.0]# docker run -d -p 9528:9528 ms-ui:1.01ffc51cbea42bb4ee9f43a5987ed2569923cfe42bb5f140cf8268fd38d9dd37a docker run -d -p 9528:9528 ms-ui:1.0中的 -d 代表是后台运行、-p 9528:9528代表本地9528映射到容器内的9528端口，ms-ui:1.0是我们要运行的镜像 - 测试是否成功12345678910111213141516171819202122[root@localhost AG-Admin-v2.0]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1ffc51cbea42 ms-ui:1.0 &quot;npm run dev&quot; About a minute ago Up About a minute 0.0.0.0:9528-&gt;9528/tcp zen_lamarrea9400d0259b sebp/elk &quot;/usr/local/bin/start&quot; 6 days ago Exited (137) 2 hours ago test_elk_173e22237ef4e sebp/elk &quot;/usr/local/bin/start&quot; 6 days ago Exited (1) 6 days ago elk[root@localhost AG-Admin-v2.0]# docker logs 1ffc51cbea42npm info it worked if it ends with oknpm info using npm@5.0.0npm info using node@v8.0.0&gt; juicy@1.2.0 dev /app&gt; node build/dev-server.jsnpm info lifecycle juicy@1.2.0~predev: juicy@1.2.0npm info lifecycle juicy@1.2.0~dev: juicy@1.2.0[HPM] Proxy created: /jwt -&gt; http://localhost:8765[HPM] Proxy rewrite rule created: &quot;^/jwt&quot; ~&gt; &quot;/jwt&quot;[HPM] Proxy created: /api -&gt; http://localhost:8765[HPM] Proxy rewrite rule created: &quot;^/api&quot; ~&gt; &quot;/api&quot;(node:15) UnhandledPromiseRejectionWarning: Unhandled promise rejection (rejection id: 1): Error: Exited with code 3(node:15) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code. DONE Compiled successfully in 10673ms07:51:55&gt; Listening at http://localhost:9528 docker ps -a可以查看docker的运行容器，发现我们的容器正在运行，可以通过docker logs 来查看运行日志，当看到我们熟悉的Listening at http://localhost:9528 就知道成功啦，可以在本地通过浏览器访问UI。 - 常用命令123456789docker stop &lt;CONTAINER ID&gt;可以停止容器运行 docker start &lt;CONTAINER ID&gt;可以启动容器运行 docker restart &lt;CONTAINER ID&gt;可以重启容器 docker rm &lt;CONTAINER ID&gt; -f可以强制删除在运行的容器docker rmi &lt;IMAGE NAME&gt; 可以删除镜像]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK8的CAS实现学习笔记]]></title>
      <url>%2F2017%2Fjavase-CAS%2F</url>
      <content type="text"><![CDATA[摘要:CAS全称为compare and swap，是原子操作的一种，可用于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某一数据时由于执行顺序不确定性以及中断的不可预知性产生的数据不一致问题。 该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值。 –from Wikipedia 正文:在使用上，通常会记录下某块内存中的旧值，通过对旧值进行一系列的操作后得到新值，然后通过CAS操作将新值与旧值进行交换。如果这块内存的值在这期间内没被修改过，则旧值会与内存中的数据相同，这时CAS操作将会成功执行 使内存中的数据变为新值。如果内存中的值在这期间内被修改过，则一般来说旧值会与内存中的数据不同，这时CAS操作将会失败，新值将不会被写入内存。 CAS的实现接下来我们去看CAS在java中的实现，sun.misc.Unsafe提供了compareAndSwap系列函数。 1234567891011121314151617181920212223242526/** * Atomically update Java variable to &lt;tt&gt;x&lt;/tt&gt; if it is currently * holding &lt;tt&gt;expected&lt;/tt&gt;. * @return &lt;tt&gt;true&lt;/tt&gt; if successful */ public final native boolean compareAndSwapObject(Object o, long offset, Object expected, Object x); /** * Atomically update Java variable to &lt;tt&gt;x&lt;/tt&gt; if it is currently * holding &lt;tt&gt;expected&lt;/tt&gt;. * @return &lt;tt&gt;true&lt;/tt&gt; if successful */ public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x); /** * Atomically update Java variable to &lt;tt&gt;x&lt;/tt&gt; if it is currently * holding &lt;tt&gt;expected&lt;/tt&gt;. * @return &lt;tt&gt;true&lt;/tt&gt; if successful */ public final native boolean compareAndSwapLong(Object o, long offset, long expected, long x); 可以看到native发现这是一个本地方法调用，可以去查看对应的OpenJDK中调用代码atomic_linux_x86.inline.hpp / atomic_windows_x86.inline.hpp 1234567891011121314//linux(int 类型)inline jint Atomic::cmpxchg(jint exchange_value, volatile jint* dest, jint compare_value) &#123; int mp = os::is_MP(); __asm__ volatile (LOCK_IF_MP(%4) "cmpxchgl %1,(%3)" : "=a" (exchange_value) : "r" (exchange_value), "a" (compare_value), "r" (dest), "r" (mp) : "cc", "memory"); return exchange_value;&#125;//windows(int 类型)inline jint Atomic::cmpxchg(jint exchange_value, volatile jint* dest, jint compare_value) &#123; return (*os::atomic_cmpxchg_func)(exchange_value, dest, compare_value);&#125; 可以看到其实现方式是基于硬件平台的汇编指令cmpxchg指令完成的，JVM只是封装了汇编调用。以linux x86处理器为例子，int mp = os::is_MP()中的MP是multiprocessor，即多处理器，当遇到是多处理器的情况下加上LOCK。cmpxchgl指的应该是compare and exchange指令。 CAS在Java中的使用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 public class UnsafeTest &#123; private static Unsafe unsafe; static &#123; try &#123; // 通过反射获取rt.jar下的Unsafe类 Field field = Unsafe.class.getDeclaredField("theUnsafe"); field.setAccessible(true); unsafe = (Unsafe) field.get(null); &#125; catch (Exception e) &#123; System.out.println("Get Unsafe instance occur error" + e); &#125; &#125; public static void main(String[] args) throws Exception &#123; Class clazz = Target.class; Field[] fields = clazz.getDeclaredFields(); Target target = new Target(); Field intFiled = clazz.getDeclaredField("intParam"); Field longFiled = clazz.getDeclaredField("longParam"); Field strFiled = clazz.getDeclaredField("strParam"); Field strFiled2 = clazz.getDeclaredField("strParam2"); // intParam System.out.print(unsafe.compareAndSwapInt(target, 12, 3, 10) + ":"); System.out.println((Integer) intFiled.get(target)); // longParam System.out.print(unsafe.compareAndSwapLong(target, 16, 1l, 2l) + ":"); System.out.println((Long) longFiled.get(target)); // strParam System.out.print(unsafe.compareAndSwapObject(target, 24, null, "5") + ":"); System.out.println((String) strFiled.get(target)); // strParam2 System.out.print(unsafe.compareAndSwapObject(target, 28, null, "6") + ":"); System.out.println((String) strFiled2.get(target)); &#125; &#125; class Target &#123; int intParam = 3; long longParam = 1l; String strParam; String strParam2;&#125; 如代码所示，compareAndSwapXx方法会根据第二个参数”偏移量”去拿偏移量这么多的属性的值和第三个参数对比，如果相同则将该属性值替换为第四个参数。该偏移量是指某个字段相对Java对象的起始位置的偏移量，可以通过unsafe.objectFieldOffset(param)去获取对应属性的偏移量。 顺便介绍个查看对象的属性位置分布的一个小工具：jol 使用Demo:首先引用jol-core包 123456&lt;!-- https://mvnrepository.com/artifact/org.openjdk.jol/jol-core --&gt;&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt;&lt;/dependency&gt; 然后在项目里简单使用下： 123456public class TestOffset &#123; public static void main(String[] args) &#123; out.println(VM.current().details()); out.println(ClassLayout.parseClass(Throwable.class).toPrintable()); &#125;&#125; 结果如下，根据偏移量界面化的显示属性分布的位置： 1234567891011121314151617# Running 64-bit HotSpot VM.# Using compressed oop with 3-bit shift.# Using compressed klass with 3-bit shift.# Objects are 8 bytes aligned.# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]java.lang.Throwable object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 12 (object header) N/A 12 4 (alignment/padding gap) 16 4 java.lang.String Throwable.detailMessage N/A 20 4 java.lang.Throwable Throwable.cause N/A 24 4 java.lang.StackTraceElement[] Throwable.stackTrace N/A 28 4 java.util.List Throwable.suppressedExceptions N/AInstance size: 32 bytesSpace losses: 4 bytes internal + 0 bytes external = 4 bytes total CAS存在的ABA问题CAS普遍存在的一个问题就是ABA问题，即是当线程一将变量A修改为B，之后又修改为A，线程二去对比A发现没变化就会判断出错。目前很多都是使用加上版本号来解决，加个version字段，每次修改就++，每次判断时候多判断下版本号是否变化来确定某变量是否被修改。 下班啦，暂且到这里，祝大家十一玩的开心~~~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Method的invoke方法源码分析]]></title>
      <url>%2F2017%2Fjavase-Method-invoke%2F</url>
      <content type="text"><![CDATA[摘要:最近有使用到Method的invoke方法，于是就学习了下Method的invoke方法源码(暂未深入到native) 正文:源码分析首先看一下invoke方法的代码实现： 123456789101112131415161718192021222324class AccessibleObject implements AnnotatedElement &#123; boolean override; //访问权限 public boolean isAccessible() &#123; return override; &#125;&#125;//Method.classpublic Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException &#123; if (!override) &#123; if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, obj, modifiers); &#125; &#125; MethodAccessor ma = methodAccessor; // read volatile if (ma == null) &#123; ma = acquireMethodAccessor(); &#125; return ma.invoke(obj, args); &#125; 可以看到在该方法第一步会先去判断AccessibleObject的override属性是否为true 若为true则忽略访问权限的控制 若为false则会去调用Reflection.quickCheckMemberAccess()判断是不是public，若不是则会使用Reflection.getCallerClass()获取调用此方法的class，然后校验其是否有权限 最后会调用MethodAccessor的invoke()方法 MethodAccessor的invoke方法源码如下所示，就是一个接口： 12345public interface MethodAccessor &#123; /** Matches specification in &#123;@link java.lang.reflect.Method&#125; */ public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException;&#125; 可以看到它只是一个单方法接口，其invoke()方法与Method.invoke()的对应。 创建MethodAccessor实例的是ReflectionFactory。 sun.reflect.ReflectionFactory： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class ReflectionFactory &#123; private static boolean initted = false; // ... // // "Inflation" mechanism. Loading bytecodes to implement // Method.invoke() and Constructor.newInstance() currently costs // 3-4x more than an invocation via native code for the first // invocation (though subsequent invocations have been benchmarked // to be over 20x faster). Unfortunately this cost increases // startup time for certain applications that use reflection // intensively (but only once per class) to bootstrap themselves. // To avoid this penalty we reuse the existing JVM entry points // for the first few invocations of Methods and Constructors and // then switch to the bytecode-based implementations. // // Package-private to be accessible to NativeMethodAccessorImpl // and NativeConstructorAccessorImpl private static boolean noInflation = false; private static int inflationThreshold = 15; // ... /** We have to defer full initialization of this class until after the static initializer is run since java.lang.reflect.Method's static initializer (more properly, that for java.lang.reflect.AccessibleObject) causes this class's to be run, before the system properties are set up. */ private static void checkInitted() &#123; if (initted) return; AccessController.doPrivileged(new PrivilegedAction() &#123; public Object run() &#123; // Tests to ensure the system properties table is fully // initialized. This is needed because reflection code is // called very early in the initialization process (before // command-line arguments have been parsed and therefore // these user-settable properties installed.) We assume that // if System.out is non-null then the System class has been // fully initialized and that the bulk of the startup code // has been run. if (System.out == null) &#123; // java.lang.System not yet fully initialized return null; &#125; String val = System.getProperty("sun.reflect.noInflation"); if (val != null &amp;&amp; val.equals("true")) &#123; noInflation = true; &#125; val = System.getProperty("sun.reflect.inflationThreshold"); if (val != null) &#123; try &#123; inflationThreshold = Integer.parseInt(val); &#125; catch (NumberFormatException e) &#123; throw (RuntimeException) new RuntimeException("Unable to parse property sun.reflect.inflationThreshold"). initCause(e); &#125; &#125; initted = true; return null; &#125; &#125;); &#125; // ... public MethodAccessor newMethodAccessor(Method method) &#123; checkInitted(); if (noInflation) &#123; return new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); &#125; else &#123; NativeMethodAccessorImpl acc = new NativeMethodAccessorImpl(method); DelegatingMethodAccessorImpl res = new DelegatingMethodAccessorImpl(acc); acc.setParent(res); return res; &#125; &#125;&#125; 可以看到，实际的MethodAccessor实现有两个版本，一个是Java实现的，另一个是native code实现的。Java实现的版本在初始化时需要较多时间，但长久来说性能较好；native版本正好相反，启动时相对较快，但运行时间长了之后速度就比不过Java版了。 这个需要注意的是inflationThreshold的值是15，也就是说前15次是使用的native版本，之后使用的是java版本，具体实现可以往下看。 为了权衡两个版本的性能，Sun的JDK使用了“inflation”的技巧：让Java方法在被反射调用时，开头若干次使用native版，等反射调用次数超过阈值时则生成一个专用的MethodAccessor实现类，生成其中的invoke()方法的字节码，以后对该Java方法的反射调用就会使用Java版。 (Sun的JDK是从1.4系开始采用这种优化的) 可以在启动命令里加上-Dsun.reflect.noInflation=true，就会RefactionFactorynoInflation属性就变成true了，这样不用等到15调用后，程序一开始就会用java版的MethodAccessor了 可以在上段代码newMethodAccessor()方法看到DelegatingMethodAccessorImpl res = new DelegatingMethodAccessorImpl(acc); sun.reflect.DelegatingMethodAccessorImpl： 1234567891011121314151617class DelegatingMethodAccessorImpl extends MethodAccessorImpl &#123; private MethodAccessorImpl delegate; DelegatingMethodAccessorImpl(MethodAccessorImpl delegate) &#123; setDelegate(delegate); &#125; public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException &#123; return delegate.invoke(obj, args); &#125; void setDelegate(MethodAccessorImpl delegate) &#123; this.delegate = delegate; &#125;&#125; 这个类是方便在native与Java版的MethodAccessor之间实现切换。 sun.reflect.NativeMethodAccessorImpl： 123456789101112131415161718192021222324252627282930313233class NativeMethodAccessorImpl extends MethodAccessorImpl &#123; private Method method; private DelegatingMethodAccessorImpl parent; private int numInvocations; NativeMethodAccessorImpl(Method method) &#123; this.method = method; &#125; public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException &#123; if (++numInvocations &gt; ReflectionFactory.inflationThreshold()) &#123; MethodAccessorImpl acc = (MethodAccessorImpl) new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); parent.setDelegate(acc); &#125; return invoke0(method, obj, args); &#125; void setParent(DelegatingMethodAccessorImpl parent) &#123; this.parent = parent; &#125; private static native Object invoke0(Method m, Object obj, Object[] args);&#125; 可以看到在每次调用invoke方法时候会++numInvocations，inflationThreshold的值是15，该块就是上文所说的native版本和java版本的切换实现部分。当numInvocations超过inflationThreshold的值调用MethodAccessorGenerator.generateMethod()来生成Java版的MethodAccessor的实现类，并且改变DelegatingMethodAccessorImpl所引用的MethodAccessor为Java版。后续经由DelegatingMethodAccessorImpl.invoke()调用到的就是Java版的实现了。 测试用例可以使用demo测试invoke方法执行的流程： 123456789101112131415161718public class A &#123; public void foo(String name) &#123; System.out.println("Hello," + name); &#125;&#125;//Testpublic class TestClassLoad &#123; public static void main(String[] args) throws Exception &#123; Class&lt;?&gt; clz = Class.forName("testinvoke.A"); Object o = clz.newInstance(); Method m = clz.getMethod("foo", String.class); for (int i = 0; i &lt; 16; i++) &#123; m.invoke(o, Integer.toString(i)); &#125; &#125; &#125;&#125; 可以在运行的时候使用-XX:+TraceClassLoading参数监控类加载情况： 12345678910111213141516171819202122232425262728293031323334353637[Loaded testinvoke.A from file:/C:/Users/itliusir/git/test/Test/bin/][Loaded sun.reflect.NativeMethodAccessorImpl from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.DelegatingMethodAccessorImpl from D:\jdk8\jre\lib\rt.jar]Hello,0Hello,1Hello,2Hello,3Hello,4Hello,5Hello,6Hello,7Hello,8Hello,9Hello,10Hello,11Hello,12Hello,13Hello,14[Loaded sun.reflect.ClassFileConstants from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.AccessorGenerator from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.MethodAccessorGenerator from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.ByteVectorFactory from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.ByteVector from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.ByteVectorImpl from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.ClassFileAssembler from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.UTF8 from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.Label from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.Label$PatchInfo from D:\jdk8\jre\lib\rt.jar][Loaded java.util.ArrayList$Itr from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.MethodAccessorGenerator$1 from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.ClassDefiner from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.ClassDefiner$1 from D:\jdk8\jre\lib\rt.jar][Loaded java.util.concurrent.ConcurrentHashMap$ForwardingNode from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.GeneratedMethodAccessor1 from __JVM_DefineClass__]Hello,15[Loaded java.lang.Shutdown from D:\jdk8\jre\lib\rt.jar][Loaded java.lang.Shutdown$Lock from D:\jdk8\jre\lib\rt.jar]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MAT内存分析工具使用]]></title>
      <url>%2F2017%2FJVM-MAT%2F</url>
      <content type="text"><![CDATA[摘要:Eclipse Memory Analysis Tools (MAT) 是一个分析 Java堆数据的专业工具,用它可以定位内存泄漏的原因。 正文:Memory Analyzer的安装 Eclipse-&gt;Help-&gt;Eclipse Marketplace 安装完成后可以调用jdk工具jps查看当前的java进程，然后调用jmap将该进程的内存heap输出到文件。 通过MAT以图像形式直观的展示内存泄漏报表等 首先Eclipse-&gt;File-&gt;Open File 打开上一步生成的文件 第一个选项是内存泄漏报表（自动检查可能存在内存泄露的对象，通过报表展示存活的对象以及为什么他们没有被垃圾收集）； 第二个是对象报表（对可疑对象进行分析，如字符串是否定义重了，空的collection、finalizer以及弱引用等）； 这里我们打开第一个： Memory Analyzer主界面介绍 下面的Histogram（列出内存中的对象，对象的个数以及大小）这里我们可以使用正则去进行匹配 可以在具体的Class右键List objects-&gt;with incoming…./outgoing…查看该Class的实例 1. outgoing references ：表示该对象的出节点（被该对象引用的对象）。 2. incoming references ：表示该对象的入节点（引用到该对象的对象）。 下面的Dominator Tree是列出最大的对象以及其依赖存活的Object （大小是以Retained Heap为标准排序的） 而Top Consumers则是通过图形列出最大的Object Duplicate Class是通过MAT自动分析泄漏的原因 一般Histogram和 Dominator Tree是最常用的。 Memory Analyzer中概念介绍 Shallow heap Shallow size就是对象本身占用内存的大小，不包含其引用的对象。 1. 常规对象（非数组）的Shallow size由其成员变量的数量和类型决定。 2. 数组的shallow size由数组元素的类型（对象类型、基本类型）和数组长度决定 Retained Heap 它表示如果一个对象被释放，那么因为该对象的释放而减少引用从而导致释放所有的对象所占用的heap大小 为了计算Retained Memory，MAT引入了Dominator Tree。加入对象A引用B和C，B和C又都引用到D（一个菱形）。此时要计算Retained Memory，A的包括A本身和B，C，D。B和C因为共同引用D，所以他俩的Retained Memory都只是他们本身。D当然也只是自己。我觉得是为了加快计算的速度，MAT改变了对象引用图，而转换成一个对象引用树。在这里例子中，树根是A，而B，C，D是他的三个儿子。B，C，D不再有相互关系。把引用图变成引用树，计算Retained Heap就会非常方便，显示也非常方便。对应到MAT UI上，在dominator tree这个view中，显示了每个对象的shallow heap和retained heap。然后可以以该节点位树根，一步步的细化看看retained heap到底是用在什么地方了。要说一下的是，这种从图到树的转换确实方便了内存分析，但有时候会让人有些疑惑。本来对象B是对象A的一个成员，但因为B还被C引用，所以B在树中并不在A下面，而很可能是平级，如下图所示。 为了纠正这点，MAT中点击右键，可以List objects中选择with outgoing references和with incoming references。这是个真正的引用图的概念 GC Root GC发现通过任何reference chain(引用链)无法访问某个对象的时候，该对象即被回收。名词GC Roots正是分析这一过程的起点，例如JVM自己确保了对象的可到达性(那么JVM就是GC Roots)，所以GC Roots就是这样在内存中保持对象可到达性的，一旦不可到达，即被回收。通常GC Roots是一个在current thread(当前线程)的call stack(调用栈)上的对象（例如方法参数和局部变量），或者是线程自身或者是system class loader(系统类加载器)加载的类以及native code(本地代码)保留的活动对象。所以GC Roots是分析对象为何还存活于内存中的利器。 在Histogram或者Domiantor Tree的某一个条目上，右键可以查看其GC Root Path 参考： http://blog.csdn.net/yxz329130952/article/details/50288145 http://www.jianshu.com/p/d8e247b1e7b2 晚安~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK8的LinkedList源码学习笔记]]></title>
      <url>%2F2017%2Fjavase-List-LinkedList1%2F</url>
      <content type="text"><![CDATA[摘要:上一篇分析了ArrayList之后接下来分析下LinkedList的底层设计,它与ArrayList在底层的实现上有所不同。 正文:首先，LinkedList的继承和实现了的类和接口： LinkedList 是一个继承于AbstractSequentialList的双向链表。它也可以被当作堆栈、队列或双端队列进行操作。同时实现了Deque接口，即能将LinkedList当作双端队列使用。 另外实现了Cloneable接口，Serializable接口。接下来看LinkedList的构造方法： 123456789101112131415161718/** * Constructs an empty list. */ public LinkedList() &#123; &#125; /** * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection's * iterator. * * @param c the collection whose elements are to be placed into this list * @throws NullPointerException if the specified collection is null */ public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c); &#125; LinkedList提供了两个构造方法，第一个是默认无参的，第二个是带Collection的类型参数： 使用this()调用默认的构造方法 成员变量分析 1234567891011121314151617/** * 当前有多少个节点 */transient int size = 0; /** * 第一个节点. * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * 最后一个节点. * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last; 核心方法分析 1. addAll()方法 addAll有两个重载函数，addAll(Collection&lt;? extends E&gt;)型和addAll(int, Collection&lt;? extends E&gt;)型，我们平时习惯调用的addAll(Collection&lt;? extends E&gt;)型会转化为addAll(int, Collection&lt;? extends E&gt;)型，所以我们着重分析此函数即可 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; //JDK8将对index的判断封装了一个方法checkPositionIndex(index); //这个就不用说了，集合转为数组 Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; //succ指向当前需要插入节点的位置，pred指向其前一个节点 Node&lt;E&gt; pred, succ; //在列表尾部插入的时候 if (index == size) &#123; succ = null; pred = last; &#125; else &#123; //若不是在尾部插入时候则先去根据索引查询对应的元素可见该块最下面的node()方法 succ = node(index); pred = succ.prev; &#125; //遍历collection中的所有元素将其依次插入到此链表中指定位置 for (Object o : a) &#123; @SuppressWarnings("unchecked") E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; &#125; if (succ == null) &#123; last = pred; &#125; else &#123; pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true; &#125;/** * 根据index返回对应元素. */ Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); //若index&lt;size/2正序移位获取索引位置 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125; &#125; 2. removeXXX()方法 LinkedList提供了头删除removeFirst()、尾删除removeLast()、remove(int index)、remove(Object o)、clear()这些删除元素的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133/** * Removes and returns the first element from this list. */public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f); &#125; /** * Removes and returns the last element from this list. */ public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l); &#125;/** * Unlinks non-null first node f. * 删除非空的首节点f. */ private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC //将原首节点的next节点设置为首节点 first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element; &#125; /** * Unlinks non-null last node l. * 删除非空的尾节点f. */ private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC //将原尾节点的prev节点设置为尾节点 last = prev; if (prev == null) first = null; else prev.next = null; size--; modCount++; return element; &#125;/** * Remove. */public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false; &#125;/** * Unlinks non-null node x. * 删除非空节点. */ E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; //如果被删除节点为头节点 if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; //如果被删除节点为尾节点 if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; //size-1 modCount++; return element; &#125;/** * Removes all of the elements from this list. * 清空所有节点. */ public void clear() &#123; // Clearing all of the links between nodes is "unnecessary", but: // - helps a generational GC if the discarded nodes inhabit // more than one generation // - is sure to free memory even if there is a reachable Iterator for (Node&lt;E&gt; x = first; x != null; ) &#123; Node&lt;E&gt; next = x.next; x.item = null; x.next = null; x.prev = null; x = next; &#125; first = last = null; size = 0; modCount++; &#125; 3. set()方法 12345678//很容易分析，先检查index，然后根据index返回对应元素，最后将元素--&gt;x.itempublic E set(int index, E element) &#123; checkElementIndex(index); Node&lt;E&gt; x = node(index); E oldVal = x.item; x.item = element; return oldVal; &#125; 4. getXXX()方法 LinkedList提供了getFirst()、getLast()、contains(Object o)、get(int index)、indexOf(Object o)、lastIndexOf(Object o)这些查找元素的方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * Returns the first element in this list. */ public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item; &#125;/** * Returns the last element in this list. */ public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item; &#125;public boolean contains(Object o) &#123; return indexOf(o) != -1; &#125;/** * 正向查找，返回LinkedList中元素值Object o第一次出现的位置，如果元素不存在，则返回-1 */ public int indexOf(Object o) &#123; int index = 0; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; //正向 if (x.item == null) return index; index++; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1; &#125;//逆向查找，返回LinkedList中元素值Object o最后一次出现的位置，如果元素不存在，则返回-1 public int lastIndexOf(Object o) &#123; int index = size; //LinkedList可以为null if (o == null) &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; //逆向 index--; if (x.item == null) return index; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; index--; if (o.equals(x.item)) return index; &#125; &#125; return -1; &#125;/** * 根据index获取当前元素. */ public E get(int index) &#123; checkElementIndex(index); return node(index).item; &#125; 5. Queue操作 Queue操作提供了peek()、element()、poll()、remove()、offer(E e)这些方法。 123456789101112131415161718192021222324252627//获取但不移除此队列的头；如果此队列为空，则返回 null public E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125; //获取但不移除此队列的头；如果此队列为空，则抛出NoSuchElementException异常 public E element() &#123; return getFirst(); &#125; //获取并移除此队列的头，如果此队列为空，则返回 null public E poll() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); &#125; //获取并移除此队列的头，如果此队列为空，则抛出NoSuchElementException异常 public E remove() &#123; return removeFirst(); &#125; //将指定的元素值(E e)插入此列表末尾 public boolean offer(E e) &#123; return add(e); &#125; 6. Deque操作 Deque操作提供了offerFirst(E e)、offerLast(E e)、peekFirst()、peekLast()、pollFirst()、pollLast()、push(E e)、pop()、removeFirstOccurrence(Object o)、removeLastOccurrence(Object o)这些方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879//将指定的元素值(E e)插入此列表末尾 public boolean offer(E e) &#123; return add(e); &#125; // Deque operations //将指定的元素插入此双端队列的开头 public boolean offerFirst(E e) &#123; addFirst(e); return true; &#125; //将指定的元素插入此双端队列的末尾 public boolean offerLast(E e) &#123; addLast(e); return true; &#125; //获取，但不移除此双端队列的第一个元素；如果此双端队列为空，则返回 null public E peekFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125; //获取，但不移除此双端队列的最后一个元素；如果此双端队列为空，则返回 null public E peekLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : l.item; &#125; //获取并移除此双端队列的第一个元素；如果此双端队列为空，则返回 null public E pollFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); &#125; //获取并移除此双端队列的最后一个元素；如果此双端队列为空，则返回 null public E pollLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : unlinkLast(l); &#125; //将一个元素推入此双端队列所表示的堆栈（换句话说，此双端队列的头部） public void push(E e) &#123; addFirst(e); &#125; //从此双端队列所表示的堆栈中弹出一个元素（换句话说，移除并返回此双端队列的头部） public E pop() &#123; return removeFirst(); &#125; //从此双端队列移除第一次出现的指定元素，如果列表中不包含次元素，则没有任何改变 public boolean removeFirstOccurrence(Object o) &#123; return remove(o); &#125; //从此双端队列移除最后一次出现的指定元素,如果列表中不包含次元素，则没有任何改变 public boolean removeLastOccurrence(Object o) &#123; //由于LinkedList中允许存放null，因此下面通过两种情况来分别处理 if (o == null) &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; //逆向向前 if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false; &#125; LinkedList同样也采用了快速失败的机制，通过记录modCount参数来实现。在面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险。 晚安~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK8的ArrayList源码学习笔记]]></title>
      <url>%2F2017%2Fjavase-List-ArrayList1%2F</url>
      <content type="text"><![CDATA[摘要:ArrayList基本上是我们在java编程中用得最多的集合类了，是一个动态的数组，在我们用ArrayList的时候发现其非常方面，功能也很强大，但是其这强大的功能是底层是怎么实现的呢？ 正文:首先，ArrayList的继承和实现了的类和接口： 可以看出，ArrayList不仅实现了Cloneable、Serializable接口，还实现了RandomAccess接口、List接口。 RandomAccess是一个标记接口，用于标明实现该接口的List支持快速随机访问，主要目的是使算法能够在随机和顺序访问的list中表现的更加高效。因为这个接口是没有任何实现的，实现了这个接口的类，就表明这个类支持快速访问，就相当于实现了Serializable就等于支持序列化和反序列化，这是个标准。 接下来看ArrayList的构造方法： 12345678910111213141516171819202122232425public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+initialCapacity); &#125; &#125; public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; ArrayList提供了三个构造方法，第一个是由调用者传入指定List的大小来创建elementData数组。第二个是默认的构造方法，默认数组容量是10。第三个是根据传入的一个集合，将集合转化成数组，然后赋给elementData。面试题里经常出现ArrayList list = new ArrayList(20)一共扩容了几次，虽然ArrayList默认容量是10，但是它有一个是指定list大小的构造方法，会在new ArrayList(20)时候自动生成一个20容量的集合，所以是不会发生扩容也即是0次。 成员变量分析 123456789101112//默认容量 private static final int DEFAULT_CAPACITY = 10; //空数组 private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;//空数组，新增元素时候用 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;//数组 transient Object[] elementData; //数组大小 private int size;//数组最大容量private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 核心方法分析 1. trim to size 压缩空间 123456789public void trimToSize() &#123; modCount++; //一个精简的三元表达式 if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125; &#125; 2. grow 扩容 1234567891011121314151617181920212223242526private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; //新空间分配直接扩大50% int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //得出较大的值 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: //元素复制 elementData = Arrays.copyOf(elementData, newCapacity); &#125;private static int hugeCapacity(int minCapacity) &#123; /** * hugeCapacity的判断小于0则为溢出，由于在jvm内部是以反 * 码存储的数据，首位为符号位，当容量扩增后，若溢出，首位 * 则变为1，此时变为负数，则可以快速判断出是否溢出。 */ if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; 3. fail-fast机制 1234/** * 子类使用这个字段是可选的，若子类希望提供fail-fast(快速失败) iterators或者list iterators 可以在方法里使用该方法. */protected transient int modCount = 0; 这个变量用于快速判断该实例是否有变化，若在进行迭代的时候有变更，那么就抛出一个并发修改异常(ConcurrentModificationException)。fail-fast是Java集合的一种错误检测机制。当多个线程对集合进行结构上的改变的操作时，有可能会产生fail-fast机制。 4. add 新增一个元素 指定位置插入： 123456789101112public void add(int index, E element) &#123; //下标检查，是否越界了 rangeCheckForAdd(index); //扩增容量，同时改变modcount ensureCapacityInternal(size + 1); //index后面的元素后移 System.arraycopy(elementData, index, elementData, index + 1, size - index); //指定位置放置元素 elementData[index] = element; //元素数量大小自增 size++; &#125; 向后插入： 12345678910public boolean add(E e) &#123; //扩大容量,修改modcount ensureCapacityInternal(size + 1); // Increments modCount!! //注意 //数组是从0开始的存元素的，而数组个数是从1开始计数的 //这个地方是往第size个位置上存元素 //再将元素个数加1 elementData[size++] = e; return true; &#125; 由此可见，向后插入没有使用数组复制，因此效率会高于指定位置插入。 5. remove 移除一个元素 由上面的插入方法可以看到List底层的数组处理使用到了System.arraycopy()方法,下面综合删除和数组复制方法讲下删除原理，下面是删除代码： 1234567891011121314151617181920212223242526272829303132333435363738394041 public class TestArrayList &#123; static Object[] elementData = null; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add("A"); list.add("B"); list.add("C"); list.add("D"); list.add("E"); int size = list.size(); elementData = list.toArray(); /** * removeMyList(要删除元素的位置,size); * */ removeMyList(2,size); for(Object ele:elementData)&#123; System.out.println(ele); &#125; &#125; private static void removeMyList(int index,int size) &#123; /** * arraycopy(Object src,int srcPos, * Object dest,int destPos, * int length); * src:源数组； srcPos:源数组要复制的起始位置； * dest:目的数组； destPos:目的数组放置的起始位置； * length:复制的长度。 * * 若自己到自己复制实现过程是先生成一个长度为length的临时数组, * 将elementData数组中srcPos到srcPos+length-1之间的数据拷贝到临时数组中， * 再执行System.arraycopy(临时数组,index+1,elementData,index,size-index-1). * index:要删除元素的位置 * list删除元素时候是srcPos=index+1,destPos=index,length=size-index-1 * 意思是将要删除的元素和之后元素复制到自己元素和之后的位置将自己覆盖 * */ System.arraycopy(elementData, index+1, elementData, index, size-index-1); elementData[--size] = null; //相当于往前移了一位将最后一位重复的置null &#125;&#125; 其删除操作如下图所示： 下一篇将要写关于LinkedList的源码分析~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于Spring事务的传播特性]]></title>
      <url>%2F2017%2Fspring-Transactional%2F</url>
      <content type="text"><![CDATA[摘要:Spring事务管理基于底层数据库本身的事务处理机制，对数据库事务操作的一次封装，相当于把使用JDBC代码开启、提交、回滚事务进行了封装。其传播特性共有七个 正文:事务的传播特性 Propagation.REQUIRED 方法被调用时自动开启事务，在事务范围内使用则使用同一个事务，如果当前线程中已经存在事务, 方法调用会加入此事务, 如果当前没有事务，就新建一个事务。 Propagation.REQUIRES_NEW 无论何时自身都会开启事务，这个事务不依赖于外部事务，它拥有自己的隔离范围，自己的锁，等等。当内部事务开始执行时，外部事务将被挂起，内部事务结束时，外部事务将继续执行。 Propagation.SUPPORTS 自身不会开启事务，在事务范围内使用挂起事务，运行完毕不使用事务 Propagation.NOT_SUPPORTED 自身不会开启事务，在事务范围内使用挂起事务，运行完毕恢复事务 Propagation.MANDATORY 自身不会开启事务，必须在事务环境使用否则报错 Propagation.NEVER 自身不会开启事务，在事务范围内使用抛出异常 Propagation.NESTED 如果当前存在事务，则在嵌套的事务中执行，如果没有则按照TransactionDefinition.PROPAGATION_REQUIRED 属性执行。可以认为是已经存在事务的一个真正的子事务。嵌套事务开始执行时，它将取得一个 save point。如果这个嵌套事务失败，我们将回滚到此save point。嵌套事务是外部事务的一部分，只有外部事务结束后它才会被提交。 Propagation.REQUIRES_NEW和Propagation.NESTED 的最大区别在于，Propagation.REQUIRES_NEW完全是一个新的事务，而 Propagation.NESTED 则是外部事务的子事务。如果外部事务 commit，嵌套事务也会被 commit，这个规则同样适用于rollback。 测试代码因为业务的需要，业务逻辑优先在单个Service中实现，同样为了保证数据的一致性需要使用事务，在单个Service中实现会出现嵌套事务。 如我们使用service C同时调用service A和service B ，如果service B抛出异常那么service C（外部事务）如果没有特殊配置（如异常时事务提交）那么整个事务是一定会rollback的。 测试代码：Service C：如下代码所示，使用声明式注解@Transactional(rollbackFor=Exception.class)默认传播特性是Propagation.REQUIRED。1234567@Transactional(rollbackFor=Exception.class,propagation=Propagation.REQUIRED)@Overridepublic int insert(Users users) throws Exception&#123; int i = users1Service.insert(users); int j = users2Service.insert1(users); return i+j;&#125; Controller层：1234567@RequestMapping(value = "/", method = RequestMethod.POST)public ResponseInfo postUser1(@RequestBody Users user) throws Exception &#123; ResponseInfo resInfo = new ResponseInfo(); int i = usersService.insert(user); resInfo.setResponseInfo("users一共新增了" + i + "条数据"); return resInfo;&#125; Service A：12345@Transactional(rollbackFor=Exception.class,propagation=Propagation.REQUIRES_NEW)@Overridepublic int insert(Users users) throws Exception&#123; return usersMapper.insert(users);&#125; Service B：12345@Transactional(rollbackFor=Exception.class,propagation=Propagation.REQUIRED)@Overridepublic int insert1(Users users) throws Exception&#123; return usersMapper.insert1(users);&#125; 根据以上代码可以通过测试两张表同时插入而一张表失败最后返回的数据进行分析：本次使用Postman测试工具，数据库oracle 11g。两张表其中一张age字段为number6位，一张为number2位，测试数据为三位，会有一张表插入失败，测试数据如下图所示。 结果是两张表都没有插入，如下图所示。 经过测试，说明嵌套事务与事务的传播特性有关，都使用默认的传播属性REQUIRED第一张插入后，第二张失败会导致外部事务（Service C）rollback，保证了数据的一致性。若内部事务有使用REQUIRES_NEW属性，则会单独开一事务其运行结果不会影响外部数据会出现数据不一致。若内部事务有使用NESTED属性，内部事务如果出现异常则会rollback到save point，从而外部事务可以使用try-catch进行分支执行（try里执行Service A，catch里执行Service B）。查询语句应该设置为read-only，传播范围设置为NOT_SUPPORTED如下代码所示：12345678910/** * &#123;@inheritDoc&#125; * &#123;@link newframe.business.demo.service.SecurityInfoService#queryAll()&#125; * */ @Transactional(propagation = Propagation.NOT_SUPPORTED, readOnly = true) @Override public List&lt;SecurityInfo&gt; queryAll() throws MessageException &#123; List&lt;SecurityInfo&gt; list = securityInfoMapper.queryAll(); return list; &#125; 具体使用哪个属性根据业务来进行选择。 Spring注解在项目中如果大量组件采用xml的bean定义来配置，显然会增加配置文件的体积，查找不太方便。而注解可以很方便的标注完将其放入spring容器管理。 业务层注解@Service：用于标注业务层组件。@Controller：用于标注控制层组件。@Repository：用于标注数据访问组件，即Dao组件。@Component：泛指组件，不容易归类可以使用该组件。 Bean容器相关的注解@Autowired：等同autowire=byType，根据类型的自动注入依赖。@Qualifier：等同autowire=byName，当@Autowired注解需要判断多个 bean类型相同时，就需要使用@Qualifier(“xxBean”)来指定依赖的bean 的id。@Resource：属于JSR250标准，作用同@Autowired，是属于byName类 型的依赖注入，使用方式：@Resource(name=”xxBean”)，不带参数是默 认类名首字母小写。 @RequestBody：用于读取request请求的body部分数据(Json串或XML数据)，将其转化为需要的对象。@ResponseBody：将Controller的方法返回的对象通过适当的转换(通过配置可以返回Json或XML数据)，写入response对象的body数据区。新框架可以在Controller里使用该注解返回Json数据。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[很方便的密码加密算法BCrypt]]></title>
      <url>%2F2017%2FAlgorithm-BCrypt%2F</url>
      <content type="text"><![CDATA[摘要:用户表的密码一般都不是使用明文，使用明文坏处可以参考之前CSDN数据库被黑导致用户密码泄露造成的影响。虽然使用明文也有一定的方便之处(毕竟现在的加密都是单向的，比如客户打电话问密码、老大或者上级问密码)，但是我们完全可以根据用户提供的其他信息(比如密保让客户自己输入密码进行更改而不是直接告诉用户密码)，无论怎么样明文存储密码的坏处一定大于好处。下面将介绍使用Spring Security时候遇到的默认密码加密算法BCrypt： 正文:BCrypt算法将salt随机并混入最终加密后的密码，验证时也无需单独提供之前的salt，从而无需单独处理salt问题。 salt随机部分代码： 123//根据SecureRandom对象与gensalt()方法产生随机值String salt = gensalt(xx, new SecureRandom());String BCpwd = hashpw("123456", salt); 用法很简单： 12//BCpwd是加密后的密文String BCpwd = BCrypt.hashpw(password, BCrypt.gensalt()); 加密后的格式一般为： $2a$10$/bTVvqqlH9UiE0ZJZ7N2Me3RIgUCdgMheyTgV0B4cMCSokPa.6oCa 其中：$是分割符，无意义；2a是bcrypt加密版本号；10是cost的值；而后的前22位是salt值；再然后的字符串就是密码的密文了。 这块代码的格式拼接可以查看gensalt()方法源码： 123456789101112131415161718public static String gensalt(int log_rounds, SecureRandom random) &#123; if (log_rounds &lt; 4 || log_rounds &gt; 31) &#123; throw new IllegalArgumentException("Bad number of rounds"); &#125; StringBuilder rs = new StringBuilder(); byte rnd[] = new byte[BCRYPT_SALT_LEN]; random.nextBytes(rnd); rs.append("$2a$"); if (log_rounds &lt; 10) &#123; rs.append("0"); &#125; rs.append(log_rounds); rs.append("$"); encode_base64(rnd, rnd.length, rs); return rs.toString();&#125; 下面是我整理的一套BCrypt算法源码，可以很方便的直接拿来用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544package bcrypt;import java.io.ByteArrayOutputStream;import java.io.UnsupportedEncodingException;import java.security.SecureRandom;import java.util.regex.Pattern;public class TestBCrypt &#123; private static Pattern BCRYPT_PATTERN = Pattern .compile("\\A\\$2a?\\$\\d\\d\\$[./0-9A-Za-z]&#123;53&#125;"); private static final int GENSALT_DEFAULT_LOG2_ROUNDS = 10; private static final int BCRYPT_SALT_LEN = 16; // Blowfish parameters private static final int BLOWFISH_NUM_ROUNDS = 16; // Initial contents of key schedule private static final int P_orig[] = &#123; 0x243f6a88, 0x85a308d3, 0x13198a2e, 0x03707344, 0xa4093822, 0x299f31d0, 0x082efa98, 0xec4e6c89, 0x452821e6, 0x38d01377, 0xbe5466cf, 0x34e90c6c, 0xc0ac29b7, 0xc97c50dd, 0x3f84d5b5, 0xb5470917, 0x9216d5d9, 0x8979fb1b &#125;; private static final int S_orig[] = &#123; 0xd1310ba6, 0x98dfb5ac, 0x2ffd72db, 0xd01adfb7, 0xb8e1afed, 0x6a267e96, 0xba7c9045, 0xf12c7f99, 0x24a19947, 0xb3916cf7, 0x0801f2e2, 0x858efc16, 0x636920d8, 0x71574e69, 0xa458fea3, 0xf4933d7e, 0x0d95748f, 0x728eb658, 0x718bcd58, 0x82154aee, 0x7b54a41d, 0xc25a59b5, 0x9c30d539, 0x2af26013, 0xc5d1b023, 0x286085f0, 0xca417918, 0xb8db38ef, 0x8e79dcb0, 0x603a180e, 0x6c9e0e8b, 0xb01e8a3e, 0xd71577c1, 0xbd314b27, 0x78af2fda, 0x55605c60, 0xe65525f3, 0xaa55ab94, 0x57489862, 0x63e81440, 0x55ca396a, 0x2aab10b6, 0xb4cc5c34, 0x1141e8ce, 0xa15486af, 0x7c72e993, 0xb3ee1411, 0x636fbc2a, 0x2ba9c55d, 0x741831f6, 0xce5c3e16, 0x9b87931e, 0xafd6ba33, 0x6c24cf5c, 0x7a325381, 0x28958677, 0x3b8f4898, 0x6b4bb9af, 0xc4bfe81b, 0x66282193, 0x61d809cc, 0xfb21a991, 0x487cac60, 0x5dec8032, 0xef845d5d, 0xe98575b1, 0xdc262302, 0xeb651b88, 0x23893e81, 0xd396acc5, 0x0f6d6ff3, 0x83f44239, 0x2e0b4482, 0xa4842004, 0x69c8f04a, 0x9e1f9b5e, 0x21c66842, 0xf6e96c9a, 0x670c9c61, 0xabd388f0, 0x6a51a0d2, 0xd8542f68, 0x960fa728, 0xab5133a3, 0x6eef0b6c, 0x137a3be4, 0xba3bf050, 0x7efb2a98, 0xa1f1651d, 0x39af0176, 0x66ca593e, 0x82430e88, 0x8cee8619, 0x456f9fb4, 0x7d84a5c3, 0x3b8b5ebe, 0xe06f75d8, 0x85c12073, 0x401a449f, 0x56c16aa6, 0x4ed3aa62, 0x363f7706, 0x1bfedf72, 0x429b023d, 0x37d0d724, 0xd00a1248, 0xdb0fead3, 0x49f1c09b, 0x075372c9, 0x80991b7b, 0x25d479d8, 0xf6e8def7, 0xe3fe501a, 0xb6794c3b, 0x976ce0bd, 0x04c006ba, 0xc1a94fb6, 0x409f60c4, 0x5e5c9ec2, 0x196a2463, 0x68fb6faf, 0x3e6c53b5, 0x1339b2eb, 0x3b52ec6f, 0x6dfc511f, 0x9b30952c, 0xcc814544, 0xaf5ebd09, 0xbee3d004, 0xde334afd, 0x660f2807, 0x192e4bb3, 0xc0cba857, 0x45c8740f, 0xd20b5f39, 0xb9d3fbdb, 0x5579c0bd, 0x1a60320a, 0xd6a100c6, 0x402c7279, 0x679f25fe, 0xfb1fa3cc, 0x8ea5e9f8, 0xdb3222f8, 0x3c7516df, 0xfd616b15, 0x2f501ec8, 0xad0552ab, 0x323db5fa, 0xfd238760, 0x53317b48, 0x3e00df82, 0x9e5c57bb, 0xca6f8ca0, 0x1a87562e, 0xdf1769db, 0xd542a8f6, 0x287effc3, 0xac6732c6, 0x8c4f5573, 0x695b27b0, 0xbbca58c8, 0xe1ffa35d, 0xb8f011a0, 0x10fa3d98, 0xfd2183b8, 0x4afcb56c, 0x2dd1d35b, 0x9a53e479, 0xb6f84565, 0xd28e49bc, 0x4bfb9790, 0xe1ddf2da, 0xa4cb7e33, 0x62fb1341, 0xcee4c6e8, 0xef20cada, 0x36774c01, 0xd07e9efe, 0x2bf11fb4, 0x95dbda4d, 0xae909198, 0xeaad8e71, 0x6b93d5a0, 0xd08ed1d0, 0xafc725e0, 0x8e3c5b2f, 0x8e7594b7, 0x8ff6e2fb, 0xf2122b64, 0x8888b812, 0x900df01c, 0x4fad5ea0, 0x688fc31c, 0xd1cff191, 0xb3a8c1ad, 0x2f2f2218, 0xbe0e1777, 0xea752dfe, 0x8b021fa1, 0xe5a0cc0f, 0xb56f74e8, 0x18acf3d6, 0xce89e299, 0xb4a84fe0, 0xfd13e0b7, 0x7cc43b81, 0xd2ada8d9, 0x165fa266, 0x80957705, 0x93cc7314, 0x211a1477, 0xe6ad2065, 0x77b5fa86, 0xc75442f5, 0xfb9d35cf, 0xebcdaf0c, 0x7b3e89a0, 0xd6411bd3, 0xae1e7e49, 0x00250e2d, 0x2071b35e, 0x226800bb, 0x57b8e0af, 0x2464369b, 0xf009b91e, 0x5563911d, 0x59dfa6aa, 0x78c14389, 0xd95a537f, 0x207d5ba2, 0x02e5b9c5, 0x83260376, 0x6295cfa9, 0x11c81968, 0x4e734a41, 0xb3472dca, 0x7b14a94a, 0x1b510052, 0x9a532915, 0xd60f573f, 0xbc9bc6e4, 0x2b60a476, 0x81e67400, 0x08ba6fb5, 0x571be91f, 0xf296ec6b, 0x2a0dd915, 0xb6636521, 0xe7b9f9b6, 0xff34052e, 0xc5855664, 0x53b02d5d, 0xa99f8fa1, 0x08ba4799, 0x6e85076a, 0x4b7a70e9, 0xb5b32944, 0xdb75092e, 0xc4192623, 0xad6ea6b0, 0x49a7df7d, 0x9cee60b8, 0x8fedb266, 0xecaa8c71, 0x699a17ff, 0x5664526c, 0xc2b19ee1, 0x193602a5, 0x75094c29, 0xa0591340, 0xe4183a3e, 0x3f54989a, 0x5b429d65, 0x6b8fe4d6, 0x99f73fd6, 0xa1d29c07, 0xefe830f5, 0x4d2d38e6, 0xf0255dc1, 0x4cdd2086, 0x8470eb26, 0x6382e9c6, 0x021ecc5e, 0x09686b3f, 0x3ebaefc9, 0x3c971814, 0x6b6a70a1, 0x687f3584, 0x52a0e286, 0xb79c5305, 0xaa500737, 0x3e07841c, 0x7fdeae5c, 0x8e7d44ec, 0x5716f2b8, 0xb03ada37, 0xf0500c0d, 0xf01c1f04, 0x0200b3ff, 0xae0cf51a, 0x3cb574b2, 0x25837a58, 0xdc0921bd, 0xd19113f9, 0x7ca92ff6, 0x94324773, 0x22f54701, 0x3ae5e581, 0x37c2dadc, 0xc8b57634, 0x9af3dda7, 0xa9446146, 0x0fd0030e, 0xecc8c73e, 0xa4751e41, 0xe238cd99, 0x3bea0e2f, 0x3280bba1, 0x183eb331, 0x4e548b38, 0x4f6db908, 0x6f420d03, 0xf60a04bf, 0x2cb81290, 0x24977c79, 0x5679b072, 0xbcaf89af, 0xde9a771f, 0xd9930810, 0xb38bae12, 0xdccf3f2e, 0x5512721f, 0x2e6b7124, 0x501adde6, 0x9f84cd87, 0x7a584718, 0x7408da17, 0xbc9f9abc, 0xe94b7d8c, 0xec7aec3a, 0xdb851dfa, 0x63094366, 0xc464c3d2, 0xef1c1847, 0x3215d908, 0xdd433b37, 0x24c2ba16, 0x12a14d43, 0x2a65c451, 0x50940002, 0x133ae4dd, 0x71dff89e, 0x10314e55, 0x81ac77d6, 0x5f11199b, 0x043556f1, 0xd7a3c76b, 0x3c11183b, 0x5924a509, 0xf28fe6ed, 0x97f1fbfa, 0x9ebabf2c, 0x1e153c6e, 0x86e34570, 0xeae96fb1, 0x860e5e0a, 0x5a3e2ab3, 0x771fe71c, 0x4e3d06fa, 0x2965dcb9, 0x99e71d0f, 0x803e89d6, 0x5266c825, 0x2e4cc978, 0x9c10b36a, 0xc6150eba, 0x94e2ea78, 0xa5fc3c53, 0x1e0a2df4, 0xf2f74ea7, 0x361d2b3d, 0x1939260f, 0x19c27960, 0x5223a708, 0xf71312b6, 0xebadfe6e, 0xeac31f66, 0xe3bc4595, 0xa67bc883, 0xb17f37d1, 0x018cff28, 0xc332ddef, 0xbe6c5aa5, 0x65582185, 0x68ab9802, 0xeecea50f, 0xdb2f953b, 0x2aef7dad, 0x5b6e2f84, 0x1521b628, 0x29076170, 0xecdd4775, 0x619f1510, 0x13cca830, 0xeb61bd96, 0x0334fe1e, 0xaa0363cf, 0xb5735c90, 0x4c70a239, 0xd59e9e0b, 0xcbaade14, 0xeecc86bc, 0x60622ca7, 0x9cab5cab, 0xb2f3846e, 0x648b1eaf, 0x19bdf0ca, 0xa02369b9, 0x655abb50, 0x40685a32, 0x3c2ab4b3, 0x319ee9d5, 0xc021b8f7, 0x9b540b19, 0x875fa099, 0x95f7997e, 0x623d7da8, 0xf837889a, 0x97e32d77, 0x11ed935f, 0x16681281, 0x0e358829, 0xc7e61fd6, 0x96dedfa1, 0x7858ba99, 0x57f584a5, 0x1b227263, 0x9b83c3ff, 0x1ac24696, 0xcdb30aeb, 0x532e3054, 0x8fd948e4, 0x6dbc3128, 0x58ebf2ef, 0x34c6ffea, 0xfe28ed61, 0xee7c3c73, 0x5d4a14d9, 0xe864b7e3, 0x42105d14, 0x203e13e0, 0x45eee2b6, 0xa3aaabea, 0xdb6c4f15, 0xfacb4fd0, 0xc742f442, 0xef6abbb5, 0x654f3b1d, 0x41cd2105, 0xd81e799e, 0x86854dc7, 0xe44b476a, 0x3d816250, 0xcf62a1f2, 0x5b8d2646, 0xfc8883a0, 0xc1c7b6a3, 0x7f1524c3, 0x69cb7492, 0x47848a0b, 0x5692b285, 0x095bbf00, 0xad19489d, 0x1462b174, 0x23820e00, 0x58428d2a, 0x0c55f5ea, 0x1dadf43e, 0x233f7061, 0x3372f092, 0x8d937e41, 0xd65fecf1, 0x6c223bdb, 0x7cde3759, 0xcbee7460, 0x4085f2a7, 0xce77326e, 0xa6078084, 0x19f8509e, 0xe8efd855, 0x61d99735, 0xa969a7aa, 0xc50c06c2, 0x5a04abfc, 0x800bcadc, 0x9e447a2e, 0xc3453484, 0xfdd56705, 0x0e1e9ec9, 0xdb73dbd3, 0x105588cd, 0x675fda79, 0xe3674340, 0xc5c43465, 0x713e38d8, 0x3d28f89e, 0xf16dff20, 0x153e21e7, 0x8fb03d4a, 0xe6e39f2b, 0xdb83adf7, 0xe93d5a68, 0x948140f7, 0xf64c261c, 0x94692934, 0x411520f7, 0x7602d4f7, 0xbcf46b2e, 0xd4a20068, 0xd4082471, 0x3320f46a, 0x43b7d4b7, 0x500061af, 0x1e39f62e, 0x97244546, 0x14214f74, 0xbf8b8840, 0x4d95fc1d, 0x96b591af, 0x70f4ddd3, 0x66a02f45, 0xbfbc09ec, 0x03bd9785, 0x7fac6dd0, 0x31cb8504, 0x96eb27b3, 0x55fd3941, 0xda2547e6, 0xabca0a9a, 0x28507825, 0x530429f4, 0x0a2c86da, 0xe9b66dfb, 0x68dc1462, 0xd7486900, 0x680ec0a4, 0x27a18dee, 0x4f3ffea2, 0xe887ad8c, 0xb58ce006, 0x7af4d6b6, 0xaace1e7c, 0xd3375fec, 0xce78a399, 0x406b2a42, 0x20fe9e35, 0xd9f385b9, 0xee39d7ab, 0x3b124e8b, 0x1dc9faf7, 0x4b6d1856, 0x26a36631, 0xeae397b2, 0x3a6efa74, 0xdd5b4332, 0x6841e7f7, 0xca7820fb, 0xfb0af54e, 0xd8feb397, 0x454056ac, 0xba489527, 0x55533a3a, 0x20838d87, 0xfe6ba9b7, 0xd096954b, 0x55a867bc, 0xa1159a58, 0xcca92963, 0x99e1db33, 0xa62a4a56, 0x3f3125f9, 0x5ef47e1c, 0x9029317c, 0xfdf8e802, 0x04272f70, 0x80bb155c, 0x05282ce3, 0x95c11548, 0xe4c66d22, 0x48c1133f, 0xc70f86dc, 0x07f9c9ee, 0x41041f0f, 0x404779a4, 0x5d886e17, 0x325f51eb, 0xd59bc0d1, 0xf2bcc18f, 0x41113564, 0x257b7834, 0x602a9c60, 0xdff8e8a3, 0x1f636c1b, 0x0e12b4c2, 0x02e1329e, 0xaf664fd1, 0xcad18115, 0x6b2395e0, 0x333e92e1, 0x3b240b62, 0xeebeb922, 0x85b2a20e, 0xe6ba0d99, 0xde720c8c, 0x2da2f728, 0xd0127845, 0x95b794fd, 0x647d0862, 0xe7ccf5f0, 0x5449a36f, 0x877d48fa, 0xc39dfd27, 0xf33e8d1e, 0x0a476341, 0x992eff74, 0x3a6f6eab, 0xf4f8fd37, 0xa812dc60, 0xa1ebddf8, 0x991be14c, 0xdb6e6b0d, 0xc67b5510, 0x6d672c37, 0x2765d43b, 0xdcd0e804, 0xf1290dc7, 0xcc00ffa3, 0xb5390f92, 0x690fed0b, 0x667b9ffb, 0xcedb7d9c, 0xa091cf0b, 0xd9155ea3, 0xbb132f88, 0x515bad24, 0x7b9479bf, 0x763bd6eb, 0x37392eb3, 0xcc115979, 0x8026e297, 0xf42e312d, 0x6842ada7, 0xc66a2b3b, 0x12754ccc, 0x782ef11c, 0x6a124237, 0xb79251e7, 0x06a1bbe6, 0x4bfb6350, 0x1a6b1018, 0x11caedfa, 0x3d25bdd8, 0xe2e1c3c9, 0x44421659, 0x0a121386, 0xd90cec6e, 0xd5abea2a, 0x64af674e, 0xda86a85f, 0xbebfe988, 0x64e4c3fe, 0x9dbc8057, 0xf0f7c086, 0x60787bf8, 0x6003604d, 0xd1fd8346, 0xf6381fb0, 0x7745ae04, 0xd736fccc, 0x83426b33, 0xf01eab71, 0xb0804187, 0x3c005e5f, 0x77a057be, 0xbde8ae24, 0x55464299, 0xbf582e61, 0x4e58f48f, 0xf2ddfda2, 0xf474ef38, 0x8789bdc2, 0x5366f9c3, 0xc8b38e74, 0xb475f255, 0x46fcd9b9, 0x7aeb2661, 0x8b1ddf84, 0x846a0e79, 0x915f95e2, 0x466e598e, 0x20b45770, 0x8cd55591, 0xc902de4c, 0xb90bace1, 0xbb8205d0, 0x11a86248, 0x7574a99e, 0xb77f19b6, 0xe0a9dc09, 0x662d09a1, 0xc4324633, 0xe85a1f02, 0x09f0be8c, 0x4a99a025, 0x1d6efe10, 0x1ab93d1d, 0x0ba5a4df, 0xa186f20f, 0x2868f169, 0xdcb7da83, 0x573906fe, 0xa1e2ce9b, 0x4fcd7f52, 0x50115e01, 0xa70683fa, 0xa002b5c4, 0x0de6d027, 0x9af88c27, 0x773f8641, 0xc3604c06, 0x61a806b5, 0xf0177a28, 0xc0f586e0, 0x006058aa, 0x30dc7d62, 0x11e69ed7, 0x2338ea63, 0x53c2dd94, 0xc2c21634, 0xbbcbee56, 0x90bcb6de, 0xebfc7da1, 0xce591d76, 0x6f05e409, 0x4b7c0188, 0x39720a3d, 0x7c927c24, 0x86e3725f, 0x724d9db9, 0x1ac15bb4, 0xd39eb8fc, 0xed545578, 0x08fca5b5, 0xd83d7cd3, 0x4dad0fc4, 0x1e50ef5e, 0xb161e6f8, 0xa28514d9, 0x6c51133c, 0x6fd5c7e7, 0x56e14ec4, 0x362abfce, 0xddc6c837, 0xd79a3234, 0x92638212, 0x670efa8e, 0x406000e0, 0x3a39ce37, 0xd3faf5cf, 0xabc27737, 0x5ac52d1b, 0x5cb0679e, 0x4fa33742, 0xd3822740, 0x99bc9bbe, 0xd5118e9d, 0xbf0f7315, 0xd62d1c7e, 0xc700c47b, 0xb78c1b6b, 0x21a19045, 0xb26eb1be, 0x6a366eb4, 0x5748ab2f, 0xbc946e79, 0xc6a376d2, 0x6549c2c8, 0x530ff8ee, 0x468dde7d, 0xd5730a1d, 0x4cd04dc6, 0x2939bbdb, 0xa9ba4650, 0xac9526e8, 0xbe5ee304, 0xa1fad5f0, 0x6a2d519a, 0x63ef8ce2, 0x9a86ee22, 0xc089c2b8, 0x43242ef6, 0xa51e03aa, 0x9cf2d0a4, 0x83c061ba, 0x9be96a4d, 0x8fe51550, 0xba645bd6, 0x2826a2f9, 0xa73a3ae1, 0x4ba99586, 0xef5562e9, 0xc72fefd3, 0xf752f7da, 0x3f046f69, 0x77fa0a59, 0x80e4a915, 0x87b08601, 0x9b09e6ad, 0x3b3ee593, 0xe990fd5a, 0x9e34d797, 0x2cf0b7d9, 0x022b8b51, 0x96d5ac3a, 0x017da67d, 0xd1cf3ed6, 0x7c7d2d28, 0x1f9f25cf, 0xadf2b89b, 0x5ad6b472, 0x5a88f54c, 0xe029ac71, 0xe019a5e6, 0x47b0acfd, 0xed93fa9b, 0xe8d3c48d, 0x283b57cc, 0xf8d56629, 0x79132e28, 0x785f0191, 0xed756055, 0xf7960e44, 0xe3d35e8c, 0x15056dd4, 0x88f46dba, 0x03a16125, 0x0564f0bd, 0xc3eb9e15, 0x3c9057a2, 0x97271aec, 0xa93a072a, 0x1b3f6d9b, 0x1e6321f5, 0xf59c66fb, 0x26dcf319, 0x7533d928, 0xb155fdf5, 0x03563482, 0x8aba3cbb, 0x28517711, 0xc20ad9f8, 0xabcc5167, 0xccad925f, 0x4de81751, 0x3830dc8e, 0x379d5862, 0x9320f991, 0xea7a90c2, 0xfb3e7bce, 0x5121ce64, 0x774fbe32, 0xa8b6e37e, 0xc3293d46, 0x48de5369, 0x6413e680, 0xa2ae0810, 0xdd6db224, 0x69852dfd, 0x09072166, 0xb39a460a, 0x6445c0dd, 0x586cdecf, 0x1c20c8ae, 0x5bbef7dd, 0x1b588d40, 0xccd2017f, 0x6bb4e3bb, 0xdda26a7e, 0x3a59ff45, 0x3e350a44, 0xbcb4cdd5, 0x72eacea8, 0xfa6484bb, 0x8d6612ae, 0xbf3c6f47, 0xd29be463, 0x542f5d9e, 0xaec2771b, 0xf64e6370, 0x740e0d8d, 0xe75b1357, 0xf8721671, 0xaf537d5d, 0x4040cb08, 0x4eb4e2cc, 0x34d2466a, 0x0115af84, 0xe1b00428, 0x95983a1d, 0x06b89fb4, 0xce6ea048, 0x6f3f3b82, 0x3520ab82, 0x011a1d4b, 0x277227f8, 0x611560b1, 0xe7933fdc, 0xbb3a792b, 0x344525bd, 0xa08839e1, 0x51ce794b, 0x2f32c9b7, 0xa01fbac9, 0xe01cc87e, 0xbcc7d1f6, 0xcf0111c3, 0xa1e8aac7, 0x1a908749, 0xd44fbd9a, 0xd0dadecb, 0xd50ada38, 0x0339c32a, 0xc6913667, 0x8df9317c, 0xe0b12b4f, 0xf79e59b7, 0x43f5bb3a, 0xf2d519ff, 0x27d9459c, 0xbf97222c, 0x15e6fc2a, 0x0f91fc71, 0x9b941525, 0xfae59361, 0xceb69ceb, 0xc2a86459, 0x12baa8d1, 0xb6c1075e, 0xe3056a0c, 0x10d25065, 0xcb03a442, 0xe0ec6e0e, 0x1698db3b, 0x4c98a0be, 0x3278e964, 0x9f1f9532, 0xe0d392df, 0xd3a0342b, 0x8971f21e, 0x1b0a7441, 0x4ba3348c, 0xc5be7120, 0xc37632d8, 0xdf359f8d, 0x9b992f2e, 0xe60b6f47, 0x0fe3f11d, 0xe54cda54, 0x1edad891, 0xce6279cf, 0xcd3e7e6f, 0x1618b166, 0xfd2c1d05, 0x848fd2c5, 0xf6fb2299, 0xf523f357, 0xa6327623, 0x93a83531, 0x56cccd02, 0xacf08162, 0x5a75ebb5, 0x6e163697, 0x88d273cc, 0xde966292, 0x81b949d0, 0x4c50901b, 0x71c65614, 0xe6c6c7bd, 0x327a140a, 0x45e1d006, 0xc3f27b9a, 0xc9aa53fd, 0x62a80f00, 0xbb25bfe2, 0x35bdd2f6, 0x71126905, 0xb2040222, 0xb6cbcf7c, 0xcd769c2b, 0x53113ec0, 0x1640e3d3, 0x38abbd60, 0x2547adf0, 0xba38209c, 0xf746ce76, 0x77afa1c5, 0x20756060, 0x85cbfe4e, 0x8ae88dd8, 0x7aaaf9b0, 0x4cf9aa7e, 0x1948c25c, 0x02fb8a8c, 0x01c36ae4, 0xd6ebe1f9, 0x90d4f869, 0xa65cdea0, 0x3f09252d, 0xc208e69f, 0xb74e6132, 0xce77e25b, 0x578fdfe3, 0x3ac372e6 &#125;; // bcrypt IV: "OrpheanBeholderScryDoubt" static private final int bf_crypt_ciphertext[] = &#123; 0x4f727068, 0x65616e42, 0x65686f6c, 0x64657253, 0x63727944, 0x6f756274 &#125;; // Table for Base64 encoding static private final char base64_code[] = &#123; '.', '/', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9' &#125;; // Table for Base64 decoding static private final byte index_64[] = &#123; -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, -1, -1, -1, -1, -1, -1, -1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, -1, -1, -1, -1, -1, -1, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, -1, -1, -1, -1, -1 &#125;; // Expanded Blowfish key private static int P[]; private static int S[]; public static void main(String[] args) &#123; //10是不确定的 此处只是个例子 String salt = gensalt(10, new SecureRandom()); //对123456加密 System.out.println(hashpw("123456", salt)); //是否匹配 System.out.println(matches("123456", "$2a$10$/bTVvqqlH9UiE0ZJZ7N2Me3RIgUCdgMheyTgV0B4cMCSokPa.6oCa")); &#125; private static void init_key() &#123; P = (int[]) P_orig.clone(); S = (int[]) S_orig.clone(); &#125; static void encode_base64(byte d[], int len, StringBuilder rs) throws IllegalArgumentException &#123; int off = 0; int c1, c2; if (len &lt;= 0 || len &gt; d.length) &#123; throw new IllegalArgumentException("Invalid len"); &#125; while (off &lt; len) &#123; c1 = d[off++] &amp; 0xff; rs.append(base64_code[(c1 &gt;&gt; 2) &amp; 0x3f]); c1 = (c1 &amp; 0x03) &lt;&lt; 4; if (off &gt;= len) &#123; rs.append(base64_code[c1 &amp; 0x3f]); break; &#125; c2 = d[off++] &amp; 0xff; c1 |= (c2 &gt;&gt; 4) &amp; 0x0f; rs.append(base64_code[c1 &amp; 0x3f]); c1 = (c2 &amp; 0x0f) &lt;&lt; 2; if (off &gt;= len) &#123; rs.append(base64_code[c1 &amp; 0x3f]); break; &#125; c2 = d[off++] &amp; 0xff; c1 |= (c2 &gt;&gt; 6) &amp; 0x03; rs.append(base64_code[c1 &amp; 0x3f]); rs.append(base64_code[c2 &amp; 0x3f]); &#125; &#125; static byte[] decode_base64(String s, int maxolen) throws IllegalArgumentException &#123; ByteArrayOutputStream out = new ByteArrayOutputStream(maxolen); int off = 0, slen = s.length(), olen = 0; byte c1, c2, c3, c4, o; if (maxolen &lt;= 0) &#123; throw new IllegalArgumentException("Invalid maxolen"); &#125; while (off &lt; slen - 1 &amp;&amp; olen &lt; maxolen) &#123; c1 = char64(s.charAt(off++)); c2 = char64(s.charAt(off++)); if (c1 == -1 || c2 == -1) &#123; break; &#125; o = (byte) (c1 &lt;&lt; 2); o |= (c2 &amp; 0x30) &gt;&gt; 4; out.write(o); if (++olen &gt;= maxolen || off &gt;= slen) &#123; break; &#125; c3 = char64(s.charAt(off++)); if (c3 == -1) &#123; break; &#125; o = (byte) ((c2 &amp; 0x0f) &lt;&lt; 4); o |= (c3 &amp; 0x3c) &gt;&gt; 2; out.write(o); if (++olen &gt;= maxolen || off &gt;= slen) &#123; break; &#125; c4 = char64(s.charAt(off++)); o = (byte) ((c3 &amp; 0x03) &lt;&lt; 6); o |= c4; out.write(o); ++olen; &#125; return out.toByteArray(); &#125; private static byte char64(char x) &#123; if (x &gt; index_64.length) &#123; return -1; &#125; return index_64[x]; &#125; public static String gensalt(int log_rounds, SecureRandom random) &#123; if (log_rounds &lt; 4 || log_rounds &gt; 31) &#123; throw new IllegalArgumentException("Bad number of rounds"); &#125; StringBuilder rs = new StringBuilder(); byte rnd[] = new byte[BCRYPT_SALT_LEN]; random.nextBytes(rnd); rs.append("$2a$"); if (log_rounds &lt; 10) &#123; rs.append("0"); &#125; rs.append(log_rounds); rs.append("$"); encode_base64(rnd, rnd.length, rs); return rs.toString(); &#125; public static String hashpw(String password, String salt) &#123; String real_salt; byte passwordb[], saltb[], hashed[]; char minor = (char) 0; int rounds, off = 0; StringBuilder rs = new StringBuilder(); int saltLength = salt.length(); if (saltLength &lt; 28) &#123; throw new IllegalArgumentException("Invalid salt"); &#125; if (salt.charAt(0) != '$' || salt.charAt(1) != '2') &#123; throw new IllegalArgumentException("Invalid salt version"); &#125; if (salt.charAt(2) == '$') &#123; off = 3; &#125; else &#123; minor = salt.charAt(2); if (minor != 'a' || salt.charAt(3) != '$') &#123; throw new IllegalArgumentException("Invalid salt revision"); &#125; off = 4; &#125; if (saltLength - off &lt; 25) &#123; throw new IllegalArgumentException("Invalid salt"); &#125; // Extract number of rounds if (salt.charAt(off + 2) &gt; '$') &#123; throw new IllegalArgumentException("Missing salt rounds"); &#125; rounds = Integer.parseInt(salt.substring(off, off + 2)); real_salt = salt.substring(off + 3, off + 25); try &#123; passwordb = (password + (minor &gt;= 'a' ? "\000" : "")).getBytes("UTF-8"); &#125; catch (UnsupportedEncodingException uee) &#123; throw new AssertionError("UTF-8 is not supported"); &#125; saltb = decode_base64(real_salt, BCRYPT_SALT_LEN); hashed = crypt_raw(passwordb, saltb, rounds); rs.append("$2"); if (minor &gt;= 'a') &#123; rs.append(minor); &#125; rs.append("$"); if (rounds &lt; 10) &#123; rs.append("0"); &#125; rs.append(rounds); rs.append("$"); encode_base64(saltb, saltb.length, rs); encode_base64(hashed, bf_crypt_ciphertext.length * 4 - 1, rs); return rs.toString(); &#125; private static byte[] crypt_raw(byte password[], byte salt[], int log_rounds) &#123; int cdata[] = (int[]) bf_crypt_ciphertext.clone(); int clen = cdata.length; byte ret[]; long rounds = roundsForLogRounds(log_rounds); init_key(); ekskey(salt, password); for (long i = 0; i &lt; rounds; i++) &#123; key(password); key(salt); &#125; for (int i = 0; i &lt; 64; i++) &#123; for (int j = 0; j &lt; (clen &gt;&gt; 1); j++) &#123; encipher(cdata, j &lt;&lt; 1); &#125; &#125; ret = new byte[clen * 4]; for (int i = 0, j = 0; i &lt; clen; i++) &#123; ret[j++] = (byte) ((cdata[i] &gt;&gt; 24) &amp; 0xff); ret[j++] = (byte) ((cdata[i] &gt;&gt; 16) &amp; 0xff); ret[j++] = (byte) ((cdata[i] &gt;&gt; 8) &amp; 0xff); ret[j++] = (byte) (cdata[i] &amp; 0xff); &#125; return ret; &#125; static long roundsForLogRounds(int log_rounds) &#123; if (log_rounds &lt; 4 || log_rounds &gt; 31) &#123; throw new IllegalArgumentException("Bad number of rounds"); &#125; return 1L &lt;&lt; log_rounds; &#125; private static void ekskey(byte data[], byte key[]) &#123; int i; int koffp[] = &#123; 0 &#125;, doffp[] = &#123; 0 &#125;; int lr[] = &#123; 0, 0 &#125;; int plen = P.length, slen = S.length; for (i = 0; i &lt; plen; i++) &#123; P[i] = P[i] ^ streamtoword(key, koffp); &#125; for (i = 0; i &lt; plen; i += 2) &#123; lr[0] ^= streamtoword(data, doffp); lr[1] ^= streamtoword(data, doffp); encipher(lr, 0); P[i] = lr[0]; P[i + 1] = lr[1]; &#125; for (i = 0; i &lt; slen; i += 2) &#123; lr[0] ^= streamtoword(data, doffp); lr[1] ^= streamtoword(data, doffp); encipher(lr, 0); S[i] = lr[0]; S[i + 1] = lr[1]; &#125; &#125; private static int streamtoword(byte data[], int offp[]) &#123; int i; int word = 0; int off = offp[0]; for (i = 0; i &lt; 4; i++) &#123; word = (word &lt;&lt; 8) | (data[off] &amp; 0xff); off = (off + 1) % data.length; &#125; offp[0] = off; return word; &#125; private static final void encipher(int lr[], int off) &#123; int i, n, l = lr[off], r = lr[off + 1]; l ^= P[0]; for (i = 0; i &lt;= BLOWFISH_NUM_ROUNDS - 2;) &#123; // Feistel substitution on left word n = S[(l &gt;&gt; 24) &amp; 0xff]; n += S[0x100 | ((l &gt;&gt; 16) &amp; 0xff)]; n ^= S[0x200 | ((l &gt;&gt; 8) &amp; 0xff)]; n += S[0x300 | (l &amp; 0xff)]; r ^= n ^ P[++i]; // Feistel substitution on right word n = S[(r &gt;&gt; 24) &amp; 0xff]; n += S[0x100 | ((r &gt;&gt; 16) &amp; 0xff)]; n ^= S[0x200 | ((r &gt;&gt; 8) &amp; 0xff)]; n += S[0x300 | (r &amp; 0xff)]; l ^= n ^ P[++i]; &#125; lr[off] = r ^ P[BLOWFISH_NUM_ROUNDS + 1]; lr[off + 1] = l; &#125; private static void key(byte key[]) &#123; int i; int koffp[] = &#123; 0 &#125;; int lr[] = &#123; 0, 0 &#125;; int plen = P.length, slen = S.length; for (i = 0; i &lt; plen; i++) &#123; P[i] = P[i] ^ streamtoword(key, koffp); &#125; for (i = 0; i &lt; plen; i += 2) &#123; encipher(lr, 0); P[i] = lr[0]; P[i + 1] = lr[1]; &#125; for (i = 0; i &lt; slen; i += 2) &#123; encipher(lr, 0); S[i] = lr[0]; S[i + 1] = lr[1]; &#125; &#125; public static boolean matches(CharSequence rawPassword, String encodedPassword) &#123; if (encodedPassword == null || encodedPassword.length() == 0) &#123; return false; &#125; if (!BCRYPT_PATTERN.matcher(encodedPassword).matches()) &#123; return false; &#125; return checkpw(rawPassword.toString(), encodedPassword); &#125; public static boolean checkpw(String plaintext, String hashed) &#123; return equalsNoEarlyReturn(hashed, hashpw(plaintext, hashed)); &#125; static boolean equalsNoEarlyReturn(String a, String b) &#123; char[] caa = a.toCharArray(); char[] cab = b.toCharArray(); if (caa.length != cab.length) &#123; return false; &#125; byte ret = 0; for (int i = 0; i &lt; caa.length; i++) &#123; ret |= caa[i] ^ cab[i]; &#125; return ret == 0; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[现在有10个随机数，随机数的范围在1到100之间。现在要求写出一种算法，将1到100之间没有在随机数中的数求出来]]></title>
      <url>%2F2017%2FAlgorithm-Random%2F</url>
      <content type="text"><![CDATA[摘要:代码如下： 正文:12345678910111213141516171819202122232425262728293031package test;import java.util.Random;public class TestRandom &#123; public static void main(String[] args) &#123; test(); &#125; static void test()&#123; int[] randomNums = new int[10]; Random random = new Random(); for (int i = 0, length = randomNums.length; i &lt; length; i++) &#123; randomNums[i] = random.nextInt(100); &#125; long start = System.currentTimeMillis(); boolean[] bitArray = new boolean[100]; for (int i = 0, length = randomNums.length; i &lt; length; i++) &#123; bitArray[randomNums[i]] = true; &#125; for (int i = 0, length = bitArray.length; i &lt; length; i++) &#123; if (bitArray[i]) &#123; continue; &#125;else&#123; System.out.println(i); &#125; &#125; long end = System.currentTimeMillis(); System.out.println("Spend milliseconds: " + (end - start)); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java同步器AQS分析]]></title>
      <url>%2F2017%2Fjavase-AQS%2F</url>
      <content type="text"><![CDATA[摘要:AQS(AbstractQueuedSynchronizer)提供了一个基于FIFO(first in first out,先进先出)队列，可以用于构建锁或者其他相关同步装置的基础框架。 正文:常用的java.util.concurrent.locks包中有很多的Lock实现类，如ReadWriteLock、ReentrantLock内部实现都是依赖于AQS类，下面来看AQS类的具体源码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235/** * translate by itliusir(水平有限...) * 提供一个实现阻塞锁相关的框架 * 先进先出(first in first out)等待序列 * 这个类依赖原子性&#123;@code int&#125;的值来表示状态是 * 大多数同步的基础，子类必须定义更改此状态的受保护方法 * 子类通过继承同步器并需要实现它的方法来管理其状态，管理的方式就是 * 通过类似acquire和release的方式来操纵状态。 * 然而多线程环境中对状态的操纵必须确保原子性，因此子类对于状态的把握， * 需要使用这个同步器提供的以下三个方法对状态进行操作： * java.util.concurrent.locks.AbstractQueuedSynchronizer.getState() * java.util.concurrent.locks.AbstractQueuedSynchronizer.setState(int) * java.util.concurrent.locks.AbstractQueuedSynchronizer.compareAndSetState(int, int) * * &lt;p&gt;子类应定义未非公共内部辅助类，用于实现其内部属性 * 类&#123;@code AbstractQueuedSynchronizer&#125; 不实现任何同步接口，相反，它定义了如 * &#123;@link #acquireInterruptibly&#125; 的方法可以通过具体的锁和同步器来适当的调用他们实现 * their public methods. * * &lt;p&gt;这类支持或默认独占模式和共享模式，在独占模式时，其他线程对其的获取就被阻止， * ，而共享模式对于多个线程获取都可以成功。当一个共享模式获得成功，下一个等待线程 * (如果有的话)也必须确定它是否可以获得，线程在不同模式下共用相同的FIFO队列。 * 通常，实现子类只支持这些模式之一，但是都能在&#123;@link ReadWriteLock&#125; 中发挥作用。 * 仅支持独占或共享的子类不需要去定义支持未使用模式的方法 * * &lt;p&gt;该类定义了一个嵌套的 &#123;@link ConditionObject&#125; 类，可以支持独占模式的子类 * 用作 &#123;@link Condition&#125; 实现。&#123;@link #isHeldExclusively&#125;报告是否针对当前线程专门保留同步。 * 使用当前&#123;@ #getState&#125;值调用的方法&#123;@link #release&#125;完全释放此对象, 并且 &#123;@link #acquire&#125; * 给定此保存的状态值，最终将此对象恢复到先前获取的状态。否则&#123;@code AbstractQueuedSynchronizer&#125; * 方法将创建此类条件，因此如果不能满足此约束，请勿使用，&#123;@link ConditionObject&#125; 的行为当然取决于其同步器 * 实现的semantics * * &lt;p&gt;该类为内部队列提供检查，检测和监控方法以及条件对象的类似方法，根据需要可以使用 &#123;@code AbstractQueuedSynchronizer&#125; * 进行类同步导出 * * &lt;p&gt;此类的序列化仅存储底层原子整数维持状态，因此反序列化具有空线程队列。 * 需要可序列化的子类定义过一个&#123;@code readObject&#125; 方法，可以在反序列化的时将其恢复到已知的初始状态 * * &lt;h3&gt;Usage&lt;/h3&gt; * * &lt;p&gt;要使用此类作为同步,请通过使用 &#123;@link #getState&#125;, &#123;@link * #setState&#125; and/or &#123;@link #compareAndSetState&#125;检查 and/or 修改同步状态(如适用) * redefine the following methods： * * &lt;ul&gt; * &lt;li&gt; &#123;@link #tryAcquire&#125; * &lt;li&gt; &#123;@link #tryRelease&#125; * &lt;li&gt; &#123;@link #tryAcquireShared&#125; * &lt;li&gt; &#123;@link #tryReleaseShared&#125; * &lt;li&gt; &#123;@link #isHeldExclusively&#125; * &lt;/ul&gt; * * 这些方法默认抛出 &#123;@link UnsupportedOperationException&#125;.这些方法的实现必须是线程安全的, * 定义这些方法是支持使用这个类的方式。所有其他方法都被声明为&#123;@code final&#125;,因为它们不能独立变化。 * * &lt;p&gt;您还可以从 &#123;@link AbstractOwnableSynchronizer&#125; 中找到继承的方法. 用于跟踪拥有独占同步器的线程。 * 建议您使用它们-这样可以使监控和诊断工具帮助用户确定哪些线程持有锁定。 * * &lt;p&gt;即使这个类基于内部FIFO队列，它也不会自动执行FIFO获取策略(这句话翻译的我自己都感觉不顺) * 独占同步的核心采用以下形式： * * &lt;pre&gt; * Acquire: * while (!tryAcquire(arg)) &#123; * //入队线程，如果尚未排队可能会阻塞当前线程 * &lt;em&gt;enqueue thread if it is not already queued&lt;/em&gt;; * &lt;em&gt;possibly block current thread&lt;/em&gt;; * &#125; * * Release: * if (tryRelease(arg)) * //解除阻塞第一个排队的线程 * &lt;em&gt;unblock the first queued thread&lt;/em&gt;; * &lt;/pre&gt; * * (Shared mode is similar but may involve cascading signals.) * * &lt;p id="barging"&gt;因为获取中的检查在进入之前被调用，所以新获取的线程可能先于被阻塞和排队的其他线程 * 但是，如果需要，您可以通过内部调用一个或多个检查方法来定义 &#123;@code tryAcquire&#125; and/or * &#123;@code tryAcquireShared&#125; 来禁用"barging"，从而提供一个公平的FIFO获取顺序。特别的如果 * &#123;@link #hasQueuedPredecessors&#125; (一个专门设计为被公平同步器使用的方法) 返回&#123;@code true&#125;. * 其他变化是可能的。 * * // 额... * &lt;p&gt;Throughput and scalability are generally highest for the * default barging (also known as &lt;em&gt;greedy&lt;/em&gt;, * &lt;em&gt;renouncement&lt;/em&gt;, and &lt;em&gt;convoy-avoidance&lt;/em&gt;) strategy. * While this is not guaranteed to be fair or starvation-free, earlier * queued threads are allowed to recontend before later queued * threads, and each recontention has an unbiased chance to succeed * against incoming threads. Also, while acquires do not * &amp;quot;spin&amp;quot; in the usual sense, they may perform multiple * invocations of &#123;@code tryAcquire&#125; interspersed with other * computations before blocking. This gives most of the benefits of * spins when exclusive synchronization is only briefly held, without * most of the liabilities when it isn't. If so desired, you can * augment this by preceding calls to acquire methods with * "fast-path" checks, possibly prechecking &#123;@link #hasContended&#125; * and/or &#123;@link #hasQueuedThreads&#125; to only do so if the synchronizer * is likely not to be contended. * * &lt;p&gt;这个类提供了一个高效、可扩展的基础同步 ，它们可以依赖&#123;@code int&#125; state, acquire, * and release parameters, and an internal FIFO wait queue. 当着并不满足, * you can build synchronizers from a lower level using * &#123;@link java.util.concurrent.atomic atomic&#125; classes, your own custom * &#123;@link java.util.Queue&#125; classes, and &#123;@link LockSupport&#125; blocking * support. * * &lt;h3&gt;Usage Examples&lt;/h3&gt; * * &lt;p&gt;这是一个不可重入的互斥锁类，它使用0值来表示解锁状态，1表示锁定状态。 * 虽然不可重入锁不严格要求记录当前的所有者线程，但是这样做无论如何使得 * 使用更容易监视。它还支持条件并公开其中一个测量方法。 * * &lt;pre&gt; &#123;@code * class Mutex implements Lock, java.io.Serializable &#123; * * // Our internal helper class * private static class Sync extends AbstractQueuedSynchronizer &#123; * // Reports whether in locked state * protected boolean isHeldExclusively() &#123; * return getState() == 1; * &#125; * * // Acquires the lock if state is zero * public boolean tryAcquire(int acquires) &#123; * assert acquires == 1; // Otherwise unused * if (compareAndSetState(0, 1)) &#123; * setExclusiveOwnerThread(Thread.currentThread()); * return true; * &#125; * return false; * &#125; * * // Releases the lock by setting state to zero * protected boolean tryRelease(int releases) &#123; * assert releases == 1; // Otherwise unused * if (getState() == 0) throw new IllegalMonitorStateException(); * setExclusiveOwnerThread(null); * setState(0); * return true; * &#125; * * // Provides a Condition * Condition newCondition() &#123; return new ConditionObject(); &#125; * * // Deserializes properly * private void readObject(ObjectInputStream s) * throws IOException, ClassNotFoundException &#123; * s.defaultReadObject(); * setState(0); // reset to unlocked state * &#125; * &#125; * * // The sync object does all the hard work. We just forward to it. * private final Sync sync = new Sync(); * * public void lock() &#123; sync.acquire(1); &#125; * public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; * public void unlock() &#123; sync.release(1); &#125; * public Condition newCondition() &#123; return sync.newCondition(); &#125; * public boolean isLocked() &#123; return sync.isHeldExclusively(); &#125; * public boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads(); &#125; * public void lockInterruptibly() throws InterruptedException &#123; * sync.acquireInterruptibly(1); * &#125; * public boolean tryLock(long timeout, TimeUnit unit) * throws InterruptedException &#123; * return sync.tryAcquireNanos(1, unit.toNanos(timeout)); * &#125; * &#125;&#125;&lt;/pre&gt; * * &lt;p&gt;Here is a latch class that is like a * &#123;@link java.util.concurrent.CountDownLatch CountDownLatch&#125; * except that it only requires a single &#123;@code signal&#125; to * fire. Because a latch is non-exclusive, it uses the &#123;@code shared&#125; * acquire and release methods. * * &lt;pre&gt; &#123;@code * class BooleanLatch &#123; * * private static class Sync extends AbstractQueuedSynchronizer &#123; * boolean isSignalled() &#123; return getState() != 0; &#125; * * protected int tryAcquireShared(int ignore) &#123; * return isSignalled() ? 1 : -1; * &#125; * * protected boolean tryReleaseShared(int ignore) &#123; * setState(1); * return true; * &#125; * &#125; * * private final Sync sync = new Sync(); * public boolean isSignalled() &#123; return sync.isSignalled(); &#125; * public void signal() &#123; sync.releaseShared(1); &#125; * public void await() throws InterruptedException &#123; * sync.acquireSharedInterruptibly(1); * &#125; * &#125;&#125;&lt;/pre&gt; * * @since 1.5 * @author Doug Lea */ public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; private static final long serialVersionUID = 7373984972572414691L; /** * Creates a new &#123;@code AbstractQueuedSynchronizer&#125; instance * with initial synchronization state of zero. */ protected AbstractQueuedSynchronizer() &#123; &#125;/** * Head of the wait queue, lazily initialized. Except for * initialization, it is modified only via method setHead. Note: * If head exists, its waitStatus is guaranteed not to be * CANCELLED. */ private transient volatile Node head; /** * Tail of the wait queue, lazily initialized. Modified only via * method enq to add new wait node. */ private transient volatile Node tail; /** * The synchronization state. */ private volatile int state; .... 同步器的开始提到了其实现依赖于一个FIFO队列，那么队列中的元素Node就是保存着线程引用和线程状态的容器，每个线程对同步器的访问，都可以看做是队列中的一个节点。Node的主要包含以下成员变量：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748static final class Node &#123; /** Marker to indicate a node is waiting in shared mode */ static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ static final Node EXCLUSIVE = null; /** waitStatus value to indicate thread has cancelled */ static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking */ static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ static final int PROPAGATE = -3; /** * 表示节点的状态。其中包含的状态有：: * SIGNAL: 值为-1，表示当前节点的后继节点包含的线程需要运行，也就是unpark； * CANCELLED: 值为1，表示当前的线程被取消； * CONDITION: 值为-2，表示当前节点在等待condition，也就是在condition队列中； * PROPAGATE: 值为-3，表示当前场景下后续的acquireShared能够得以执行； * 0: 值为0，表示当前节点在sync队列中，等待着获取锁。 */ volatile int waitStatus; /** * 前驱节点，比如当前节点被取消，那就需要前驱节点和后继节点来完成连接。 */ volatile Node prev; /** * 后继节点。 */ volatile Node next; /** * 入队列时的当前线程。 */ volatile Thread thread; /** * 存储condition队列中的后继节点。 */ Node nextWaiter; ... 节点成为sync队列和condition队列构建的基础，在同步器中就包含了sync队列。同步器拥有三个成员变量：sync队列的头结点head、sync队列的尾节点tail和状态state。对于锁的获取，请求形成节点，将其挂载在尾部，而锁资源的转移（释放再获取）是从头部开始向后进行。对于同步器维护的状态state，多个线程对其的获取将会产生一个链式的结构。 head节点，其实是一个空节点，我觉得可以理解成代表当前持有锁的线程，每当有线程竞争失败，都是插入到队列的尾节点，tail节点始终指向队列中的最后一个元素。 每个节点中， 除了存储了当前线程，前后节点的引用以外，还有一个waitStatus变量，用于描述节点当前的状态。多线程并发执行时，队列中会有多个节点存在，这个waitStatus其实代表对应线程的状态：有的线程可能获取锁因为某些原因放弃竞争；有的线程在等待满足条件，满足之后才能执行等等。一共有4中状态： CANCELLED 取消状态 SIGNAL 等待触发状态 CONDITION 等待条件状态 PROPAGATE 状态需要向后传播等待队列是FIFO先进先出，只有前一个节点的状态为SIGNAL时，当前节点的线程才能被挂起。 API说明实现自定义同步器时，需要使用同步器提供的getState()、setState()和compareAndSetState()方法来操纵状态的变迁。 实现这些方法必须是非阻塞而且是线程安全的，推荐使用该同步器的父类java.util.concurrent.locks.AbstractOwnableSynchronizer来设置当前的线程。开始提到同步器内部基于一个FIFO队列，对于一个独占锁的获取和释放有以下伪码可以表示。 获取一个排他锁。12345678910while(获取锁) &#123; if (获取到) &#123; 退出while循环 &#125; else &#123; if(当前线程没有入队列) &#123; 那么入队列 &#125; 阻塞当前线程 &#125;&#125; 释放一个排他锁。1234if (释放成功) &#123;删除头结点激活原头结点的后继节点&#125; 实现分析12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;amp;&amp;amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 上述逻辑主要包括： 尝试获取（调用tryAcquire更改状态，需要保证原子性）；在tryAcquire方法中使用了同步器提供的对state操作的方法，利用compareAndSet保证只有一个线程能够对状态进行成功修改，而没有成功修改的线程将进入sync队列排队。 如果获取不到，将当前线程构造成节点Node并加入sync队列；进入队列的每个线程都是一个节点Node，从而形成了一个双向队列，类似CLH队列，这样做的目的是线程间的通信会被限制在较小规模（也就是两个节点左右）。 再次尝试获取，如果没有获取到那么将当前线程从线程调度器上摘下，进入等待状态。 123456789101112131415161718192021222324252627282930private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125;private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; 上述逻辑主要包括： 使用当前线程构造Node；对于一个节点需要做的是将当节点前驱节点指向尾节点（current.prev = tail），尾节点指向它（tail = current），原有的尾节点的后继节点指向它（t.next = current）而这些操作要求是原子的。上面的操作是利用尾节点的设置来保证的，也就是compareAndSetTail来完成的。 先行尝试在队尾添加；如果尾节点已经有了，然后做如下操作：(1)分配引用T指向尾节点；(2)将节点的前驱节点更新为尾节点（current.prev = tail）；(3)如果尾节点是T，那么将当尾节点设置为该节点（tail = current，原子更新）；(4)T的后继节点指向当前节点（T.next = current）。注意第3点是要求原子的。这样可以以最短路径O(1)的效果来完成线程入队，是最大化减少开销的一种方式。 如果队尾添加失败或者是第一个入队的节点。如果是第1个节点，也就是sync队列没有初始化，那么会进入到enq这个方法，进入的线程可能有多个，或者说在addWaiter中没有成功入队的线程都将进入enq这个方法。可以看到enq的逻辑是确保进入的Node都会有机会顺序的添加到sync队列中，而加入的步骤如下：(1)如果尾节点为空，那么原子化的分配一个头节点，并将尾节点指向头节点，这一步是初始化；(2)然后是重复在addWaiter中做的工作，但是在一个while(true)的循环中，直到当前节点入队为止。进入sync队列之后，接下来就是要进行锁的获取，或者说是访问控制了，只有一个线程能够在同一时刻继续的运行，而其他的进入等待状态。而每个线程都是一个独立的个体，它们自省的观察，当条件满足的时候（自己的前驱是头结点并且原子性的获取了状态），那么这个线程能够继续运行。 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 上述逻辑主要包括： 获取当前节点的前驱节点；需要获取当前节点的前驱节点，而头结点所对应的含义是当前站有锁且正在运行。 当前驱节点是头结点并且能够获取状态，代表该当前节点占有锁；如果满足上述条件，那么代表能够占有锁，根据节点对锁占有的含义，设置头结点为当前节点。 否则进入等待状态。如果没有轮到当前节点运行，那么将当前线程从线程调度器上摘下，也就是进入等待状态。 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; 上述逻辑主要包括： 尝试释放状态；tryRelease能够保证原子化的将状态设置回去，当然需要使用compareAndSet来保证。如果释放状态成功过之后，将会进入后继节点的唤醒过程。 唤醒当前节点的后继节点所包含的线程。通过LockSupport的unpark方法将休眠中的线程唤醒，让其继续acquire状态。 12345678910111213141516171819202122232425//线程释放锁过程private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * 获取当前节点的后继节点，如果满足状态，那么进行唤醒操作 * 如果没有满足状态，从尾部开始找寻符合要求的节点并将其唤醒 */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread); &#125; 上述逻辑主要包括： 该方法取出了当前节点的next引用，然后对其线程(Node)进行了唤醒，这时就只有一个或合理个数的线程被唤醒，被唤醒的线程继续进行对资源的获取与争夺。回顾整个资源的获取和释放过程：在获取时，维护了一个sync队列，每个节点都是一个线程在进行自旋，而依据就是自己是否是首节点的后继并且能够获取资源；在释放时，仅仅需要将资源还回去，然后通知一下后继节点并将其唤醒。这里需要注意，队列的维护（首节点的更换）是依靠消费者（获取时）来完成的，也就是说在满足了自旋退出的条件时的一刻，这个节点就会被设置成为首节点。 12345678910111213141516171819202122232425262728293031public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); &#125;private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; // 检测中断标志位 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 上述逻辑主要包括： 检测当前线程是否被中断；判断当前线程的中断标志位，如果已经被中断了，那么直接抛出异常并将中断标志位设置为false。 尝试获取状态；调用tryAcquire获取状态，如果顺利会获取成功并返回。 构造节点并加入sync队列；获取状态失败后，将当前线程引用构造为节点并加入到sync队列中。退出队列的方式在没有中断的场景下和acquireQueued类似，当头结点是自己的前驱节点并且能够获取到状态时，即可以运行，当然要将本节点设置为头结点，表示正在运行。 中断检测。在每次被唤醒时，进行中断检测，如果发现当前线程被中断，那么抛出InterruptedException并退出循环。 1234567891011121314151617181920212223242526272829303132private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; //计算时间，当前时间减去睡眠之前的时间得到睡眠的时间，然后被 //原有超时时间减去，得到了还应该睡眠的时间 nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 上述逻辑主要包括： 加入sync队列；将当前线程构造成为节点Node加入到sync队列中。 条件满足直接返回；退出条件判断，如果前驱节点是头结点并且成功获取到状态，那么设置自己为头结点并退出，返回true，也就是在指定的nanosTimeout之前获取了锁。 获取状态失败休眠一段时间；通过LockSupport.unpark来指定当前线程休眠一段时间。 计算再次休眠的时间；唤醒后的线程，计算仍需要休眠的时间，该时间表示为nanosTimeout = 原有nanosTimeout – now（当前时间）+ lastTime（睡眠之前记录的时间）。其中now – lastTime表示这次睡眠所持续的时间。 休眠时间的判定。唤醒后的线程，计算仍需要休眠的时间，并无阻塞的尝试再获取状态，如果失败后查看其nanosTimeout是否大于0，如果小于0，那么返回完全超时，没有获取到锁。 如果nanosTimeout小于等于1000L纳秒，则进入快速的自旋过程。那么快速自旋会造成处理器资源紧张吗？结果是不会，经过测算，开销看起来很小，几乎微乎其微。Doug Lea应该测算了在线程调度器上的切换造成的额外开销，因此在短时1000纳秒内就让当前线程进入快速自旋状态，如果这时再休眠相反会让nanosTimeout的获取时间变得更加不精确。上述过程可以如下图所示： 上述这个图中可以理解为在类似获取状态需要排队的基础上增加了一个超时控制的逻辑。每次超时的时间就是当前超时剩余的时间减去睡眠的时间，而在这个超时时间的基础上进行了判断，如果大于0那么继续睡眠（等待），可以看出这个超时版本的获取状态只是一个近似超时的获取状态，因此任何含有超时的调用基本结果就是近似于给定超时。 1234567891011121314151617181920212223242526272829303132public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125;private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 上述逻辑主要包括： 尝试获取共享状态；调用tryAcquireShared来获取共享状态，该方法是非阻塞的，如果获取成功则立刻返回，也就表示获取共享锁成功。 获取失败进入sync队列；在获取共享状态失败后，当前时刻有可能是独占锁被其他线程所把持，那么将当前线程构造成为节点（共享模式）加入到sync队列中。 循环内判断退出队列条件；如果当前节点的前驱节点是头结点并且获取共享状态成功，这里和独占锁acquire的退出队列条件类似。 获取共享状态成功；在退出队列的条件上，和独占锁之间的主要区别在于获取共享状态成功之后的行为，而如果共享状态获取成功之后会判断后继节点是否是共享模式，如果是共享模式，那么就直接对其进行唤醒操作，也就是同时激发多个线程并发的运行。 获取共享状态失败。通过使用LockSupport将当前线程从线程调度器上摘下，进入休眠状态。对于上述逻辑中，节点之间的通知过程如下图所示： example在上述对同步器AbstractQueuedSynchronizer进行了实现层面的分析之后，我们通过一个例子来加深对同步器的理解：设计一个同步工具，该工具在同一时刻，只能有两个线程能够并行访问，超过限制的其他线程进入阻塞状态。对于这个需求，可以利用同步器完成一个这样的设定，定义一个初始状态，为2，一个线程进行获取那么减1，一个线程释放那么加1，状态正确的范围在[0，1，2]三个之间，当在0时，代表再有新的线程对资源进行获取时只能进入阻塞状态（注意在任何时候进行状态变更的时候均需要以CAS作为原子性保障）。由于资源的数量多于1个，同时可以有两个线程占有资源，因此需要实现tryAcquireShared和tryReleaseShared方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119package test.locks;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.AbstractQueuedSynchronizer;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;public class TwinsLock implements Lock &#123; private final Sync sync = new Sync(2); private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -7889272986162341211L; Sync(int count) &#123; if (count &lt;= 0) &#123; throw new IllegalArgumentException("count must large than zero."); &#125; setState(count); &#125; public int tryAcquireShared(int reduceCount) &#123; for (;;) &#123; int current = getState(); int newCount = current - reduceCount; if (newCount &lt; 0 || compareAndSetState(current, newCount)) &#123; return newCount; &#125; &#125; &#125; public boolean tryReleaseShared(int returnCount) &#123; for (;;) &#123; int current = getState(); int newCount = current + returnCount; if (compareAndSetState(current, newCount)) &#123; return true; &#125; &#125; &#125; &#125; public void lock() &#123; sync.acquireShared(1); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; public boolean tryLock() &#123; return sync.tryAcquireShared(1) &gt;= 0; &#125; public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(time)); &#125; public void unlock() &#123; sync.releaseShared(1); &#125; @Override public Condition newCondition() &#123; return null; &#125;&#125;//测试类public class TwinsLockTest &#123; @Test public void test() &#123; final Lock lock = new TwinsLock(); class Worker extends Thread &#123; public void run() &#123; while (true) &#123; lock.lock(); try &#123; Thread.sleep(1000L); System.out.println(Thread.currentThread()); Thread.sleep(1000L); &#125; catch (Exception ex) &#123; &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; &#125; for (int i = 0; i &lt; 10; i++) &#123; Worker w = new Worker(); w.start(); &#125; new Thread() &#123; public void run() &#123; while (true) &#123; try &#123; Thread.sleep(200L); System.out.println(); &#125; catch (Exception ex) &#123; &#125; &#125; &#125; &#125;.start(); try &#123; Thread.sleep(20000L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 上述测试用例的逻辑主要包括：​1. 打印线程Worker在两次睡眠之间打印自身线程，如果一个时刻只能有两个线程同时访问，那么打印出来的内容将是成对出现。​2. 分隔线程不停的打印换行，能让Worker的输出看起来更加直观。该测试的结果是在一个时刻，仅有两个线程能够获得到锁，并完成打印，而表象就是打印的内容成对出现。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Builder模式]]></title>
      <url>%2F2017%2Fjavase-Builder%2F</url>
      <content type="text"><![CDATA[摘要:日常写代码有时候会遇到bean有很多的参数，也即是有多个构造器参数，这个时候我们可以考虑使用构建器。它既能保证像重叠构造器模式那样的安全性，也能保证像JavaBean模式那么好的可读性。这就是Builder模式。 正文:讲Builder模式之前，我们先来看一下日常使用构造器的方法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.bean.builder;public class Bean &#123; private int a; private int b; private int c; private int d; private int e; private int f; public Bean(int a, int b, int c, int d, int e, int f) &#123; super(); this.a = a; this.b = b; this.c = c; this.d = d; this.e = e; this.f = f; &#125; public Bean(int a, int b, int c, int d, int e) &#123; super(); this.a = a; this.b = b; this.c = c; this.d = d; this.e = e; &#125; public Bean(int a, int b, int c, int d) &#123; super(); this.a = a; this.b = b; this.c = c; this.d = d; &#125; // ....构造方法 public Bean() &#123; super(); &#125; //省略setter getter方法&#125; 由此可见,若想要灵活的new一个对象需要创建很多个重载的构造器，可读性和可维护性都不是很高。 使用构建器示例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.bean.builder;public class BuilderBean &#123; private final int a; private final int b; private final int c; private final int d; private final int e; private final int f; public static class Builder&#123; private final int a; private final int b; private int c = 0; private int d = 0; private int e = 0; private int f = 0; public Builder(int a,int b)&#123; this.a = a; this.b = b; &#125; public Builder c(int val)&#123; c = val; return this; &#125; public Builder d(int val)&#123; d = val; return this; &#125; public Builder e(int val)&#123; e = val; return this; &#125; public Builder f(int val)&#123; f = val; return this; &#125; public BuilderBean build()&#123; return new BuilderBean(this); &#125; &#125; private BuilderBean(Builder builder)&#123; a = builder.a; b = builder.b; c = builder.c; d = builder.d; e = builder.e; f = builder.f; &#125; &#125; 注意BuilderBean是不可变的，所有的默认参数值都单独放一个地方。builder的setter方法返回builder本身，以便后续继续调用别的方法。下面是客户端的代码12BuilderBean bb = new BuilderBean.Builder(10, 20). c(3).e(5).f(6).build(); 这样的客户端代码很容易编写，更重要的是易于阅读。与构造器相比，builder的微略优势在于，builder可以有多个可变的参数，构造器就像方法一样，只能有一个可变参数。 Builder模式的优点： 1.使用Builder模式必然会导致写两遍相关属性的代码和setter方法，看起来有点吃力不讨好。然而需要看到的是，客户端代码的可用性和可读性得到了大大提高。与此同时，构造函数的参数数量明显减少调用起来非常直观。 2.Builder模式十分灵活，可以利用单个builder构建多个对象，还可在创建期间进行调整根据对象的不同进行改变。 Builder模式的缺点： 1.为了创建对象，必须先创建它的构建器。虽然创建器的开销在实践中可能不那么明显，但是在某些十分注重性能的情况下，可能就成问题了。 2.Builder模式还比重叠构造器模式更加冗长，最好在4个或4个以上的参数才使用。 在我的Builder实现中，我会用Builder的构造函数而不是set方法传递客户需要的属性。这样做的好处在于，对象总是能被一次完整的实例化，而不是靠开发人员调用时用set方法补充额外的属性完成实例化。这也体现了不可变性带来的好处。然而，相应地也会造成自己设定的属性方法可读性降低。 总结：如果类的构造器或者静态工厂中具有多个参数，设计这种类时，Builder是种不错的选择，特别是当大多数参数都是可选的时候。与使用传统的重叠构造器模式相比，使用Builder模式的客户端代码更易于编写和阅读，构建器也比JavaBean更加安全。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Boot配置属性]]></title>
      <url>%2F2017%2FSpringboot4-SpringBoot-Configuration%2F</url>
      <content type="text"><![CDATA[摘要:springboot数据库连接池使用策略以及对应的配置属性 正文:springboot数据库连接池使用策略springboot官方文档介绍数据库连接池的使用策略如下： Production database connections can also be auto-configured using a pooling DataSource. Here’s the algorithm for choosing a specific implementation: We prefer the Tomcat pooling DataSource for its performance and concurrency, so if that is available we always choose it. If HikariCP is available we will use it. If Commons DBCP is available we will use it, but we don’t recommend it in production. Lastly, if Commons DBCP2 is available we will use it. If you use the spring-boot-starter-jdbc or spring-boot-starter-data-jpa ‘starter POMs’ you will automatically get a dependency to tomcat-jdbc. springboot会优先使用tomcat连接池，因为其性能和并发性很好，如果可用的话，将会优先使用。tomcat连接池，请查看： http://tomcat.apache.org/tomcat-8.0-doc/jdbc-pool.html 如果HikariCP可用，会选择使用 http://brettwooldridge.github.io/HikariCP/。 如果DBCP可用，会选择使用，但是不推荐在生产中使用它。 最后，如果使用DBCP2，会选择使用 如果在pom文件里有spring-boot-starter-jdbc 或者 spring-boot-starter-data-jpa 依赖项，那么，会自动获取tomcat-jdbc连接池。 springboot配置属性datasource spring.dao.exceptiontranslation.enabled是否开启PersistenceExceptionTranslationPostProcessor，默认为true spring.datasource.abandon-when-percentage-full设定超时被废弃的连接占到多少比例时要被关闭或上报 spring.datasource.allow-pool-suspension使用Hikari pool时，是否允许连接池暂停，默认为: false spring.datasource.alternate-username-allowed是否允许替代的用户名. spring.datasource.auto-commit指定updates是否自动提交. spring.datasource.catalog指定默认的catalog. spring.datasource.commit-on-return设置当连接被归还时，是否要提交所有还未完成的事务 spring.datasource.connection-init-sql指定连接被创建，再被添加到连接池之前执行的sql. spring.datasource.connection-init-sqls使用DBCP connection pool时，指定初始化时要执行的sql spring.datasource.connection-properties.[key]在使用DBCP connection pool时指定要配置的属性 spring.datasource.connection-test-query指定校验连接合法性执行的sql语句 spring.datasource.connection-timeout指定连接的超时时间，毫秒单位. spring.datasource.continue-on-error在初始化数据库时，遇到错误是否继续，默认false spring.datasource.data指定Data (DML)脚本 spring.datasource.data-source-class-name指定数据源的全限定名. spring.datasource.data-source-jndi指定jndi的地址 spring.datasource.data-source-properties.[key]使用Hikari connection pool时，指定要设置的属性 spring.datasource.db-properties使用Tomcat connection pool，指定要设置的属性 spring.datasource.default-auto-commit是否自动提交. spring.datasource.default-catalog指定连接默认的catalog. spring.datasource.default-read-only是否设置默认连接只读. spring.datasource.default-transaction-isolation指定连接的事务的默认隔离级别. spring.datasource.driver-class-name指定driver的类名，默认从jdbc url中自动探测. spring.datasource.fair-queue是否采用FIFO返回连接. spring.datasource.health-check-properties.[key]使用Hikari connection pool时，在心跳检查时传递的属性 spring.datasource.idle-timeout指定连接多久没被使用时，被设置为空闲，默认为10ms spring.datasource.ignore-exception-on-pre-load当初始化连接池时，是否忽略异常. spring.datasource.init-sql当连接创建时，执行的sql spring.datasource.initial-size指定启动连接池时，初始建立的连接数量 spring.datasource.initialization-fail-fast当创建连接池时，没法创建指定最小连接数量是否抛异常 spring.datasource.initialize指定初始化数据源，是否用data.sql来初始化，默认: true spring.datasource.isolate-internal-queries指定内部查询是否要被隔离，默认为false spring.datasource.jdbc-interceptors使用Tomcat connection - pool时，指定jdbc拦截器，分号分隔 spring.datasource.jdbc-url指定JDBC URL. spring.datasource.jmx-enabled是否开启JMX，默认为: false spring.datasource.jndi-name指定jndi的名称. spring.datasource.leak-detection-threshold使用Hikari connection pool时，多少毫秒检测一次连接泄露. spring.datasource.log-abandoned使用DBCP connection pool，是否追踪废弃statement或连接，默认为: false spring.datasource.log-validation-errors当使用Tomcat - connection pool是否打印校验错误. spring.datasource.login-timeout指定连接数据库的超时时间. spring.datasource.max-active指定连接池中最大的活跃连接数. spring.datasource.max-age指定连接池中连接的最大年龄 spring.datasource.max-idle指定连接池最大的空闲连接数量. spring.datasource.max-lifetime指定连接池中连接的最大生存时间，毫秒单位. spring.datasource.max-open-prepared-statements指定最大的打开的prepared statements数量. spring.datasource.max-wait指定连接池等待连接返回的最大等待时间，毫秒单位. spring.datasource.maximum-pool-size指定连接池最大的连接数，包括使用中的和空闲的连接. spring.datasource.min-evictable-idle-time-millis指定一个空闲连接最少空闲多久后可被清除. spring.datasource.min-idle指定必须保持连接的最小值(For DBCP and Tomcat connection pools) spring.datasource.minimum-idle指定连接维护的最小空闲连接数，当使用HikariCP时指定. spring.datasource.name指定数据源名. spring.datasource.num-tests-per-eviction-run指定运行每个idle object evictor线程时的对象数量 spring.datasource.password指定数据库密码. spring.datasource.platform指定schema要使用的Platform(schema-${platform}.sql)，默认为: all spring.datasource.pool-name指定连接池名字. spring.datasource.pool-prepared-statements指定是否池化statements. spring.datasource.propagate-interrupt-state在等待连接时，如果线程被中断，是否传播中断状态. spring.datasource.read-only当使用Hikari connection pool时，是否标记数据源只读 spring.datasource.register-mbeans指定Hikari connection pool是否注册JMX MBeans. spring.datasource.remove-abandoned指定当连接超过废弃超时时间时，是否立刻删除该连接. spring.datasource.remove-abandoned-timeout指定连接应该被废弃的时间. spring.datasource.rollback-on-return在归还连接时，是否回滚等待中的事务. spring.datasource.schema指定Schema (DDL)脚本. spring.datasource.separator指定初始化脚本的语句分隔符，默认: ; spring.datasource.sql-script-encoding指定SQL scripts编码. spring.datasource.suspect-timeout指定打印废弃连接前的超时时间. spring.datasource.test-on-borrow当从连接池借用连接时，是否测试该连接. spring.datasource.test-on-connect创建时，是否测试连接 spring.datasource.test-on-return在连接归还到连接池时是否测试该连接. spring.datasource.test-while-idle当连接空闲时，是否执行连接测试. spring.datasource.time-between-eviction-runs-millis指定空闲连接检查、废弃连接清理、空闲连接池大小调整之间的操作时间间隔 spring.datasource.transaction-isolation指定事务隔离级别，使用Hikari connection pool时指定 spring.datasource.url指定JDBC URL. spring.datasource.use-disposable-connection-facade是否对连接进行包装，防止连接关闭之后被使用. spring.datasource.use-equals比较方法名时是否使用String.equals()替换==. spring.datasource.use-lock是否对连接操作加锁 spring.datasource.username指定数据库名. spring.datasource.validation-interval指定多少ms执行一次连接校验. spring.datasource.validation-query指定获取连接时连接校验的sql查询语句. spring.datasource.validation-query-timeout指定连接校验查询的超时时间. spring.datasource.validation-timeout设定连接校验的超时时间，当使用Hikari connection pool时指定 spring.datasource.validator-class-name用来测试查询的validator全限定名. spring.datasource.xa.data-source-class-name指定数据源的全限定名. spring.datasource.xa.properties指定传递给XA data source的属性JPA spring.jpa.database指定目标数据库. spring.jpa.database-platform指定目标数据库的类型. spring.jpa.generate-ddl是否在启动时初始化schema，默认为false spring.jpa.hibernate.ddl-auto指定DDL mode (none, validate, update, create, create-drop). 当使用内嵌数据库时，默认是create-drop，否则为none. spring.jpa.hibernate.naming-strategy指定命名策略. spring.jpa.open-in-view是否注册OpenEntityManagerInViewInterceptor，绑定JPA EntityManager到请求线程中，默认为: true spring.jpa.properties添加额外的属性到JPA provider. spring.jpa.show-sql是否开启sql的log，默认为: falsejooq spring.jooq.sql-dialect指定JOOQ使用的SQLDialect，比如POSTGRES.h2 spring.h2.console.enabled是否开启控制台，默认为false spring.h2.console.path指定控制台路径，默认为: /h2-consoleJTA spring.jta.allow-multiple-lrc是否允许 multiple LRC，默认为: false spring.jta.asynchronous2-pc指定两阶段提交是否可以异步，默认为: false spring.jta.background-recovery-interval指定多少分钟跑一次recovery process，默认为: 1 spring.jta.background-recovery-interval-seconds指定多久跑一次recovery process，默认: 60 spring.jta.current-node-only-recovery是否过滤掉其他非本JVM的recovery，默认为: true spring.jta.debug-zero-resource-transaction是否追踪没有使用指定资源的事务，默认为: false spring.jta.default-transaction-timeout设定默认的事务超时时间，默认为60 spring.jta.disable-jmx是否禁用jmx，默认为false spring.jta.enabled是否开启JTA support，默认为: true spring.jta.exception-analyzer设置指定的异常分析类 spring.jta.filter-log-status使用Bitronix Transaction Manager时，是否写mandatory logs，开启的话，可以节省磁盘空间，但是调试会复杂写，默认为false spring.jta.force-batching-enabled使用Bitronix Transaction Manager时，是否批量写磁盘，默认为true. spring.jta.forced-write-enabled使用Bitronix Transaction Manager时，是否强制写日志到磁盘，默认为true spring.jta.graceful-shutdown-interval当使用Bitronix Transaction Manager，指定shutdown时等待事务结束的时间，超过则中断，默认为60 spring.jta.jndi-transaction-synchronization-registry-name当使用Bitronix Transaction Manager时，在JNDI下得事务同步registry，默认为: java:comp/TransactionSynchronizationRegistry spring.jta.jndi-user-transaction-name指定在JNDI使用Bitronix Transaction Manager的名称，默认:java:comp/UserTransaction spring.jta.journal当使用Bitronix Transaction Manager，指定The journal是否disk还是null还是一个类的全限定名，默认disk spring.jta.log-dirTransaction logs directory. spring.jta.log-part1-filename指定The journal fragment文件1的名字，默认: btm1.tlog spring.jta.log-part2-filename指定The journal fragment文件2的名字，默认: btm2.tlog spring.jta.max-log-size-in-mb指定journal fragments大小的最大值. 默认: 2M spring.jta.resource-configuration-filename指定Bitronix Transaction Manager配置文件名. spring.jta.server-id指定Bitronix Transaction Manager实例的id. spring.jta.skip-corrupted-logs是否忽略corrupted log files文件，默认为false. spring.jta.transaction-manager-id指定Transaction manager的唯一标识. spring.jta.warn-about-zero-resource-transaction当使用Bitronix Transaction Manager时，是否对没有使用指定资源的事务进行警告，默认为: true]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Boot中使用Swagger2构建强大的RESTful API文档]]></title>
      <url>%2F2017%2FSpringboot2-Swagger%2F</url>
      <content type="text"><![CDATA[摘要:Swagger2，它可以轻松的整合到Spring Boot中，并与Spring MVC程序配合组织出强大RESTful API文档。它既可以减少我们创建文档的工作量，同时说明内容又整合入实现代码中，让维护文档和修改代码整合为一体，可以让我们在修改代码逻辑的同时方便的修改文档说明。另外Swagger2也提供了强大的页面测试功能来调试每个RESTful API。 正文:具体效果如下图所示：下面来具体介绍，如何在Spring Boot中使用Swagger2。 添加Swagger2依赖在pom.xml中加入Swagger2的依赖1234567891011&lt;!-- Swagger2的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt; 创建Swagger2配置类在Application.java同级创建Swagger2的配置类Swagger2。1234567891011121314151617181920@Configuration@EnableSwagger2public class Swagger2 &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage("com.ysstech.micro.web")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title("Spring Boot中使用Swagger2构建RESTful APIs") .contact("ysstech") .version("1.0") .build(); &#125;&#125; 如上代码所示，通过@Configuration注解，让Spring来加载该类配置。再通过@EnableSwagger2注解来启用Swagger2。 再通过createRestApi函数创建Docket的Bean之后，apiInfo()用来创建该Api的基本信息（这些基本信息会展现在文档页面中）。select()函数返回一个ApiSelectorBuilder实例用来控制哪些接口暴露给Swagger来展现，本例采用指定扫描的包路径来定义，Swagger会扫描该包下所有Controller定义的API，并产生文档内容（除了被@ApiIgnore指定的请求）。 添加文档内容在完成了上述配置后，其实已经可以生产文档内容，但是这样的文档主要针对请求本身，而描述主要来源于函数等命名产生，对用户并不友好，我们通常需要自己增加一些说明来丰富文档内容。如下所示，我们通过@ApiOperation注解来给API增加说明、通过@ApiImplicitParams、@ApiImplicitParam注解来给参数增加说明。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879@RestController @RequestMapping(value="/user")/** * Spring Boot：约定优于配置 * Spring Boot构建RESTful API * */public class UserController &#123; @Autowired UsersService UsersService=null; @ApiOperation(value="获取用户列表",notes="") @RequestMapping(value="/", method=RequestMethod.GET) public ResponseInfo getUserList() throws Exception&#123; // 处理"/users/"的GET请求，用来获取用户列表 ResponseInfo resInfo = new ResponseInfo(); List&lt;Users&gt; list = new ArrayList&lt;Users&gt;(); resInfo.setResponseInfo(list); return resInfo; &#125; @ApiOperation(value="获取用户详细信息",notes="根据url的id来获取用户详细信息") @ApiImplicitParam(name="id",value="用户ID",required=true,dataType="int",paramType="path") @RequestMapping(value="/&#123;id&#125;", method=RequestMethod.GET) public ResponseInfo getUser(@PathVariable int id) throws Exception&#123; ResponseInfo resInfo = new ResponseInfo(); //List&lt;Users&gt; list = new ArrayList&lt;Users&gt;(); Users user =UsersService.selectByPrimaryKey(id); resInfo.setResponseInfo(user); return resInfo; &#125; @ApiOperation(value="创建用户",notes="根据User对象创建用户") @ApiImplicitParam(name="user",value="用户详细实体user",required=true) @RequestMapping(value="/", method=RequestMethod.POST) public ResponseInfo postUser(@RequestBody Users user) throws Exception&#123; // 处理"/users/"的POST请求，用来创建User ResponseInfo resInfo = new ResponseInfo(); UsersService.insert(user); return resInfo; &#125; @ApiOperation(value="更新用户详细信息", notes="根据url的id来指定更新对象，并根据传过来的user信息来更新用户详细信息") @ApiImplicitParams(&#123; @ApiImplicitParam(name = "id", value = "用户ID", required = true, dataType = "int",paramType="path"), @ApiImplicitParam(name = "user", value = "用户详细实体user", required = true, dataType = "User") &#125;) @RequestMapping(value="/&#123;id&#125;", method=RequestMethod.PUT) public ResponseInfo putUser(@PathVariable int id, @RequestBody Users user) throws Exception&#123; // 处理"/users/&#123;id&#125;"的PUT请求，用来更新User信息 ResponseInfo resInfo = new ResponseInfo(); List&lt;Users&gt; list = new ArrayList&lt;Users&gt;(); Users user1 = list.get(id); user1.setAge(user.getAge()); user1.setId(user.getId()); user1.setName(user.getName()); resInfo.setResponseInfo(list); return resInfo; &#125; @ApiOperation(value="删除用户", notes="根据url的id来指定删除对象") @ApiImplicitParam(name = "id", value = "用户ID", required = true, dataType = "int",paramType="path") @RequestMapping(value="/&#123;id&#125;", method=RequestMethod.DELETE) public ResponseInfo deleteUser(@PathVariable int id) throws Exception&#123; // 处理"/users/&#123;id&#125;"的DELETE请求，用来删除User ResponseInfo resInfo = new ResponseInfo(); List&lt;Users&gt; list = new ArrayList&lt;Users&gt;(); list.remove(id); resInfo.setResponseInfo(list); return resInfo; &#125; &#125; 完成上述代码添加上，启动Spring Boot程序，访问：http://localhost:8088/demojar/swagger-ui.html(加的有根目录demojar)。就能看到前文所展示的RESTful API的页面。我们可以再点开具体的API请求，以POST类型的/users请求为例，可找到上述代码中我们配置的Notes信息以及参数user的描述信息，如下图所示。 API文档访问与调试在上图请求的页面中，我们看到user的Value是个输入框？是的，Swagger除了查看接口功能外，还提供了调试测试功能，我们可以点击上图中右侧的Model Schema（黄色区域：它指明了User的数据结构），此时Value中就有了user对象的模板，我们只需要稍适修改，点击下方“Try it out！”按钮，即可完成了一次请求调用！ 此时，你也可以通过几个GET请求来验证之前的POST请求是否正确。 相比为这些接口编写文档的工作，我们增加的配置内容是非常少而且精简的，对于原有代码的侵入也在忍受范围之内。因此，在构建RESTful API的同时，加入swagger来对API文档进行管理，是个不错的选择。 下面说下在项目使用中遇到的问题：按照以上demo的配置访问swagger-ui.html是404状态(error:No mapping found for HTTP request with URI [/swagger-ui.html])，最后在github上提的Issues上找到了答案 链接：https://github.com/springfox/springfox/issues/776问题是15年提的，最后有解决办法，不知道我项目是没配置对还是什么情况用的最新版本的jar没有加载到。解决办法是在Swagger2类加上@EnableWebMv或者继承WebMvcConfigurationSupport然后重写addResourceHandlers()方法解决了加载不到404问题123456789101112131415161718192021222324252627282930313233@Configuration@EnableSwagger2/** * 继承是加路径是无奈之举 默认是不需要继承 * */public class Swagger2 extends WebMvcConfigurationSupport &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors .basePackage("com.ysstech.micro.web")) .paths(PathSelectors.any()).build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title("Spring Boot中使用Swagger2构建RESTful APIs") .contact("ysstech").version("1.0").build(); &#125; @Override protected void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler("/swagger-ui.html").addResourceLocations( "classpath:/META-INF/resources/"); registry.addResourceHandler("/webjars/**").addResourceLocations( "classpath:/META-INF/resources/webjars/"); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Boot 静态资源处理]]></title>
      <url>%2F2017%2FSpringboot3-Static-Resources%2F</url>
      <content type="text"><![CDATA[摘要:spring Boot 默认的处理方式就已经足够了，默认情况下Spring Boot 使用WebMvcAutoConfiguration中配置的各种属性。但是如果你想要自己配置一些项目的设置，你可以在@Configuration注解的配置类上增加@EnableWebMvc或者继承WebMvcConfigurationSupport和WebMvcConfigurationAdapter 正文:首先解析@EnableWebMvc 、WebMvcConfigurationSupport和WebMvcConfigurerAdapter #在spring-boot+spring mvc 的项目中，有些时候我们需要自己配置一些项目的设置，就会涉及到这三个，那么，他们之间有什么关系呢？首先，@EnableWebMvc=WebMvcConfigurationSupport，使用了@EnableWebMvc注解等于扩展了WebMvcConfigurationSupport但是没有重写任何方法，所以有以下几种使用方式： @EnableWebMvc+extends WebMvcConfigurerAdapter，在扩展的类中重写父类的方法即可，这种方式会屏蔽springboot的@EnableAutoConfiguration中的设置 extends WebMvcConfigurationSupport，在扩展的类中重写父类的方法即可，这种方式会屏蔽springboot的@EnableAutoConfiguration中的设置 extends WebMvcConfigurerAdapter，在扩展的类中重写父类的方法即可，这种方式依旧使用springboot的@EnableAutoConfiguration中的设置 具体哪种方法适合，看个人对于项目的需求和要把控的程度，在WebMvcConfigurationSupport（@EnableWebMvc）和@EnableAutoConfiguration这两种方式都有一些默认的设定，而WebMvcConfigurationAdapter则是一个abstract class。具体如何类内如何进行个性化的设置，可以参考以下文章： Spring Boot：定制HTTP消息转换器 EnableWebMvc官方文档 然后重写addResourceHandlers方法12345678//例如对Swagger资源处理@Overridepublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler("/swagger-ui.html").addResourceLocations( "classpath:/META-INF/resources/"); registry.addResourceHandler("/webjars/**").addResourceLocations( "classpath:/META-INF/resources/webjars/");&#125; 至于是继承WebMvcConfigurationSupport还是WebMvcConfigurerAdapter看个人需求。 Swagger路径问题在使用Swagger时候是正常可以访问的在加入Security后发现若不排除Swagger-ui.html则资源权限不足401的问题，最后发现路径并不是springfox-swagger-ui.jar下的webjar/xxx，而是/swagger-resources/xx和/v2/xx:这样就可以正常访问Swagger的ui界面啦]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于Java变量的可见性问题]]></title>
      <url>%2F2017%2Fjavase-Java-volatile%2F</url>
      <content type="text"><![CDATA[摘要:关于java变量在工作内存和主存中的可见性问题 正文:123456789101112131415161718192021222324252627282930313233343536373839package com.test;import java.util.concurrent.TimeUnit; public class test1 &#123; private static boolean is = true; public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; int i = 0; while(test1.is)&#123; i++; //synchronized (this) &#123; &#125; 会强制刷新主内存的变量值到线程栈? //System.out.println("1"); println 是synchronized 的,会强制刷新主内存的变量值到线程栈? //sleep 会从新load主内存的值? // try &#123; // TimeUnit.MICROSECONDS.sleep(1); // &#125;catch (InterruptedException e) &#123; // e.printStackTrace(); // &#125; &#125; &#125; &#125;).start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; new Thread(new Runnable() &#123; @Override public void run() &#123; is = false; //设置is为false，使上面的线程结束while循环 &#125; &#125;).start(); &#125;&#125; 问： 为什么整个程序不会终止？ 为什么取消注释中的任何一个代码块(1，2，3)，程序才会终止？synchronized 会强制刷新住内存的变量值到线程栈? sleep 会干什么呢？涉及知识解释 volatile：此关键字保证了变量在线程的可见性，所有线程访问由volatile修饰的变量，都必须从主存中读取后操作，并在工作内存修改后立即写回主存，保证了其他线程的可见性，同样效果的关键字还有final。 synchronized：所有同步操作都必须保证 1、原子性 2、可见性，所以在同步块中发生的变化会立马写回主存 sleep：此方法只会让出CPU执行时间，并不会释放锁。 问题分析Q1：为什么注释代码后程序不会终止？ A1：因为 boolean is=true 的变量值被前面线程（简称线程A）加载到自己的工作内存，在后面的线程（简称线程B）改变 boolean is=false 之后不一定会立马写入主存(不过这道题中应该会马上写入主存，因为线程执行完 is=false之后线程就要退出了)，即便立马写入了主存后线程A也不一定马上load到工作内存中，所以程序一直不会终止？这个是我们大多数人想到的，但其实JVM针对现在的硬件水平已经做了很大程度的优化，基本上很大程度的保障了工作内存和主内存的及时同步，相当于默认使用了volatile。但只是最大程度！在CPU资源一直被占用的时候，工作内存与主内存中间的同步，也就是变量的可见性就会不那么及时！后面会验证结论。 Q2：为什么取消注释中的任何一个代码块(1，2，3)，程序才会终止？ A2：行号为1、2的代码有一个共同特点，就是都涉及到了synchronized 同步锁，那么是否像提问作者猜想的那样synchronized会强制刷新主内存的变量值到线程栈？，以及sleep方法也会刷新主存的变量值到线程栈呢？，事实上我们前面说了synchronized只会保证在同步块中的变量的可见性，而is变量并不在该同步块中，所以显然不是这个导致的。接下来我们在代码i++;后面加上以下代码： 123for(int k=0;k&lt;100000;k++)&#123; new Object();&#125; 再Run，程序立刻终止！为什么？在上面的 A1 中我们已经说了即便有JVM的优化，但当CPU一直被占用的时候，数据的可见性得不到很好的保证，就像上面的程序一直循环做i++;运算占用CPU，而为什么加上上面的代码后程序就会停止呢？因为对于大量new Object()操作来说，CPU已经不是主要占时间的操作，真正的耗时应该在内存的分配上（因为CPU的处理速度明显快过内存，不然也不会有CPU的寄存器了），所以CPU空闲后会遵循JVM优化基准，尽可能快的保证数据的可见性，从而从主存同步is变量到工作内存，最终导致程序结束，这也是为什么sleep()方法虽然没有涉及同步操作，但是依然可以使程序终止，因为sleep()方法会释放CPU，但不释放锁！ 结束]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL5.7安装常见问题]]></title>
      <url>%2F2017%2Fdatabase-mysql-install%2F</url>
      <content type="text"><![CDATA[摘要:从MySQL 5.7开始没有data文件夹，如果不进行初始化的话，mysql服务是无法启动的 正文:MySQL的安装 去官网下载zip格式的Mysql Server的压缩包（绿色版），根据个人电脑选择x86或者x64版本，点击最下面的跳过登录下载。 解压，复制my-dafault.ini到bin目录下，重命名为my.ini。可以根据需要复制以下内容： 12345678910111213141516[mysql]# 设置mysql客户端默认字符集default-character-set=utf8 [mysqld]#设置3306端口port = 3306 # 设置mysql的安装目录basedir=D:\mysql\mysql-5.6.35-winx64# 设置mysql数据库的数据的存放目录datadir=D:\mysql\mysql-5.6.35-winx64\data# 允许最大连接数max_connections=200# 服务端使用的字符集默认为8比特编码的latin1字符集character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB 从MySQL5.7开始，MySQL没有5.6那么易用，没有data文件夹使网上很多配置方法都会失效，如果不进行初始化的话，mysql服务是无法启动的 以管理员身份运行cmd，cd到mysql的bin目录下，执行命令：mysqld –initialize –user=mysql –console 该命令会去创建data目录与数据库，生成root用户和临时密码，在执行后的最后一行：localhost: xxxxxx 配置环境变量，将bin所在的文件夹路径添加到path的最后，例如： path=..xxx；D:\mysql\mysql-5.6.35-winx64\bin\my.ini 运行cmd，输入net start mysql启动mysql服务，再输入mysql -u root -p,然后输入临时密码。修改密码：set password=password(‘新密码’);，然后回车，注意分号不要忽略。卸载 关闭服务以管理员身份运行cmd，执行： 1net stop mysql 卸载 1mysqld -remove [服务名] 删除文件 删除注册表信息清除注册表中的该MySQL服务，有几个地方:a、HKEY_LOCAL_MACHINE\SYSTEM\ControlSet001\Services\Eventlog\Application\MySQL 目录删除b、HKEY_LOCAL_MACHINE\SYSTEM\ControlSet002\Services\Eventlog\Application\MySQL 目录删除c、HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Eventlog\Application\MySQL 目录删除注册表中的ControlSet001、ControlSet002不一定是001和002，可能是ControlSet005、006之类，删除的时候都删除就可以 。常见问题 data文件错误MySQL服务正在启动..MySQL服务无法启动。 服务没有报告任何错误。原因：原因：一般初始化之前已存在data文件就会出现这个错误，或者data文件缺少了某些文件 解决：先执行mysqld -remove，然后把data文件删除，如果删除不了重启一下就可以了，之后重新进行安装就没问题了。如果想保留之前的data文件，可以先把data文件拷贝到其他地方，安装好之后再将原data文件中多的文件拷贝进去就行了 密码错误（Error password Error 1045…Access denied）原因1：使用mysqld –initialize方法安装会生成一个随机字符串组成的密码，这个密码在错误日志D:\mysql\mysql-5.6.35-winx64\data\xxx.err（xxx是用户名）可以找到。原因2：忘记密码解决：如果忘记密码或找不到随机密码，可以通过以下方法跳过权限修改密码以管理员身份运行cmd，执行以下命令： 12net stop mysql//关闭服务mysqld --skip-grant-tables;//设置mysql登录--skip-grant-tables模式 打开一个新的cmd 1234mysql//直接登录mysql update mysql.user set authentication_string=password(&apos;123456&apos;) where user=&apos;root&apos; and Host = &apos;localhost&apos;;//修改密码 //特别提醒注意的一点是，新版的mysql数据库下的user表中已经没有Password字段了，而是将加密后的用户密码存储于authentication_string字段 flush privileges;//刷新权限，退出--skip-grant-tables模式，很重要！ 重启电脑，然后mysql就可以连接了但是此时操作似乎功能不完全，还要在登录状态下修改一次密码12345alter user &apos;root&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;还可以这样：set password for &apos;root&apos;@&apos;localhost&apos;=password(&apos;123456&apos;)；或这样：set password=password(&apos;123456&apos;); 其实mysql的安装卸载过程很简单，一般出了问题之后，把data文件备份后重装，然后把原data中的数据库文件拷贝回来就可以了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringMVC源码剖析（四）- DispatcherServlet请求转发的实现]]></title>
      <url>%2F2017%2Fframe-springmvc4%2F</url>
      <content type="text"><![CDATA[摘要:SpringMVC完成初始化流程之后，就进入Servlet标准生命周期的第二个阶段，即“service”阶段。在“service”阶段中，每一次Http请求到来，容器都会启动一个请求线程，通过service()方法，委派到doGet()或者doPost()这些方法，完成Http请求的处理。 正文:在初始化流程中，SpringMVC巧妙的运用依赖注入读取参数，并最终建立一个与容器上下文相关联的Spring子上下文。这个子上下文，就像Struts2中xwork容器一样，为接下来的Http处理流程中各种编程元素提供了容身之所。如果说将Spring上下文关联到Servlet容器中，是SpringMVC框架的第一个亮点，那么在请求转发流程中，SpringMVC对各种处理环节编程元素的抽象，就是另外一个独具匠心的亮点。 Struts2采取的是一种完全和Web容器隔离和解耦的事件机制。诸如Action对象、Result对象、Interceptor对象，这些都是完全脱离Servlet容器的编程元素。Struts2将数据流和事件处理完全剥离开来，从Http请求中读取数据后，下面的事件处理流程就只依赖于这些数据，而完全不知道有Web环境的存在。 反观SpringMVC，无论HandlerMapping对象、HandlerAdapter对象还是View对象，这些核心的接口所定义的方法中，HttpServletRequest和HttpServletResponse对象都是直接作为方法的参数出现的。这也就意味着，框架的设计者，直接将SpringMVC框架和容器绑定到了一起。或者说，整个SpringMVC框架，都是依托着Servlet容器元素来设计的。下面就来看一下，源码中是如何体现这一点的。 1.请求转发的入口 就像任何一个注册在容器中的Servlet一样，DispatcherServlet也是通过自己的service()方法来接收和转发Http请求到具体的doGet()或doPost()这些方法的。以一次典型的GET请求为例，经过HttpServlet基类中service()方法的委派，请求会被转发到doGet()方法中。doGet()方法，在DispatcherServlet的父类FrameworkServlet类中被覆写。123456@Overrideprotected final void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response);&#125; 可以看到，这里只是简单的转发到processRequest()这个方法。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869protected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; long startTime = System.currentTimeMillis(); Throwable failureCause = null; // Expose current LocaleResolver and request as LocaleContext. LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext(); LocaleContextHolder.setLocaleContext(buildLocaleContext(request), this.threadContextInheritable); // Expose current RequestAttributes to current thread. RequestAttributes previousRequestAttributes = RequestContextHolder.getRequestAttributes(); ServletRequestAttributes requestAttributes = null; if (previousRequestAttributes == null || previousRequestAttributes.getClass().equals(ServletRequestAttributes.class)) &#123; requestAttributes = new ServletRequestAttributes(request); RequestContextHolder.setRequestAttributes(requestAttributes, this.threadContextInheritable); &#125; if (logger.isTraceEnabled()) &#123; logger.trace("Bound request context to thread: " + request); &#125; try &#123; doService(request, response); &#125; catch (ServletException ex) &#123; failureCause = ex; throw ex; &#125; catch (IOException ex) &#123; failureCause = ex; throw ex; &#125; catch (Throwable ex) &#123; failureCause = ex; throw new NestedServletException("Request processing failed", ex); &#125; finally &#123; // Clear request attributes and reset thread-bound context. LocaleContextHolder.setLocaleContext(previousLocaleContext, this.threadContextInheritable); if (requestAttributes != null) &#123; RequestContextHolder.setRequestAttributes(previousRequestAttributes, this.threadContextInheritable); requestAttributes.requestCompleted(); &#125; if (logger.isTraceEnabled()) &#123; logger.trace("Cleared thread-bound request context: " + request); &#125; if (logger.isDebugEnabled()) &#123; if (failureCause != null) &#123; this.logger.debug("Could not complete request", failureCause); &#125; else &#123; this.logger.debug("Successfully completed request"); &#125; &#125; if (this.publishEvents) &#123; // Whether or not we succeeded, publish an event. long processingTime = System.currentTimeMillis() - startTime; this.webApplicationContext.publishEvent( new ServletRequestHandledEvent(this, request.getRequestURI(), request.getRemoteAddr(), request.getMethod(), getServletConfig().getServletName(), WebUtils.getSessionId(request), getUsernameForRequest(request), processingTime, failureCause)); &#125; &#125;&#125; 代码有点长，理解的要点是以doService()方法为区隔，前一部分是将当前请求的Locale对象和属性，分别设置到LocaleContextHolder和RequestContextHolder这两个抽象类中的ThreadLocal对象中，也就是分别将这两个东西和请求线程做了绑定。在doService()处理结束后，再恢复回请求前的LocaleContextHolder和RequestContextHolder，也即解除线程绑定。每次请求处理结束后，容器上下文都发布了一个ServletRequestHandledEvent事件，你可以注册监听器来监听该事件。 可以看到，processRequest()方法只是做了一些线程安全的隔离，真正的请求处理，发生在doService()方法中。点开FrameworkServlet类中的doService()方法。 protected abstract void doService(HttpServletRequest request, HttpServletResponse response) throws Exception;又是一个抽象方法，这也是SpringMVC类设计中的惯用伎俩：父类抽象处理流程，子类给予具体的实现。真正的实现是在DispatcherServlet类中。 让我们接着看DispatcherServlet类中实现的doService()方法。12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Overrideprotected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; if (logger.isDebugEnabled()) &#123; String requestUri = urlPathHelper.getRequestUri(request); logger.debug("DispatcherServlet with name '" + getServletName() + "' processing " + request.getMethod() + " request for [" + requestUri + "]"); &#125; // Keep a snapshot of the request attributes in case of an include, // to be able to restore the original attributes after the include. Map&lt;String, Object&gt; attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) &#123; logger.debug("Taking snapshot of request attributes before include"); attributesSnapshot = new HashMap&lt;String, Object&gt;(); Enumeration&lt;?&gt; attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) &#123; String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith("org.springframework.web.servlet")) &#123; attributesSnapshot.put(attrName, request.getAttribute(attrName)); &#125; &#125; &#125; // Make framework objects available to handlers and view objects. request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); try &#123; doDispatch(request, response); &#125; finally &#123; // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) &#123; restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125;&#125; 几个requet.setAttribute()方法的调用，将前面在初始化流程中实例化的对象设置到http请求的属性中，供下一步处理使用，其中有容器的上下文对象、本地化解析器等SpringMVC特有的编程元素。不同于Struts2中的ValueStack，SpringMVC的数据并没有从HttpServletRequest对象中抽离出来再存进另外一个编程元素，这也跟SpringMVC的设计思想有关。因为从一开始，SpringMVC的设计者就认为，不应该将请求处理过程和Web容器完全隔离。 所以，你可以看到，真正发生请求转发的方法doDispatch()中，它的参数是HttpServletRequest和HttpServletResponse对象。这给我们传递的意思也很明确，从request中能获取到一切请求的数据，从response中，我们又可以往服务器端输出任何响应，Http请求的处理，就应该围绕这两个对象来设计。我们不妨可以将SpringMVC这种设计方案，是从Struts2的过度设计中吸取教训，而向Servlet编程的一种回归和简化。 2.请求转发的抽象描述 接下来让我们看看doDispatch()这个整个请求转发流程中最核心的方法。DispatcherServlet所接收的Http请求，经过层层转发，最终都是汇总到这个方法中来进行最后的请求分发和处理。doDispatch()这个方法的内容，就是SpringMVC整个框架的精华所在。它通过高度抽象的接口，描述出了一个MVC（Model-View-Controller）设计模式的实现方案。Model、View、Controller三种层次的编程元素，在SpringMVC中都有大量的实现类，各种处理细节也是千差万别。但是，它们最后都是由，也都能由doDispatch()方法来统一描述，这就是接口和抽象的威力，万变不离其宗。 先来看一下doDispatch()方法的庐山真面目。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; int interceptorIndex = -1; try &#123; ModelAndView mv; boolean errorView = false; try &#123; processedRequest = checkMultipart(request); // Determine handler for the current request. mappedHandler = getHandler(processedRequest, false); if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = "GET".equals(method); if (isGet || "HEAD".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) &#123; String requestUri = urlPathHelper.getRequestUri(request); logger.debug("Last-Modified value for [" + requestUri + "] is: " + lastModified); &#125; if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; // Apply preHandle methods of registered interceptors. HandlerInterceptor[] interceptors = mappedHandler.getInterceptors(); if (interceptors != null) &#123; for (int i = 0; i &lt; interceptors.length; i++) &#123; HandlerInterceptor interceptor = interceptors[i]; if (!interceptor.preHandle(processedRequest, response, mappedHandler.getHandler())) &#123; triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, null); return; &#125; interceptorIndex = i; &#125; &#125; // Actually invoke the handler. mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); // Do we need view name translation? if (mv != null &amp;&amp; !mv.hasView()) &#123; mv.setViewName(getDefaultViewName(request)); &#125; // Apply postHandle methods of registered interceptors. if (interceptors != null) &#123; for (int i = interceptors.length - 1; i &gt;= 0; i--) &#123; HandlerInterceptor interceptor = interceptors[i]; interceptor.postHandle(processedRequest, response, mappedHandler.getHandler(), mv); &#125; &#125; &#125; catch (ModelAndViewDefiningException ex) &#123; logger.debug("ModelAndViewDefiningException encountered", ex); mv = ex.getModelAndView(); &#125; catch (Exception ex) &#123; Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); mv = processHandlerException(processedRequest, response, handler, ex); errorView = (mv != null); &#125; // Did the handler return a view to render? if (mv != null &amp;&amp; !mv.wasCleared()) &#123; render(mv, processedRequest, response); if (errorView) &#123; WebUtils.clearErrorRequestAttributes(request); &#125; &#125; else &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Null ModelAndView returned to DispatcherServlet with name '" + getServletName() + "': assuming HandlerAdapter completed request handling"); &#125; &#125; // Trigger after-completion for successful outcome. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, null); &#125; catch (Exception ex) &#123; // Trigger after-completion for thrown exception. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, ex); throw ex; &#125; catch (Error err) &#123; ServletException ex = new NestedServletException("Handler processing failed", err); // Trigger after-completion for thrown exception. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, ex); throw ex; &#125; finally &#123; // Clean up any resources used by a multipart request. if (processedRequest != request) &#123; cleanupMultipart(processedRequest); &#125; &#125;&#125; 真是千呼万唤始出来，犹抱琵琶半遮面。我们在第一篇《SpringMVC源码剖析（一）- 从抽象和接口说起》中所描述的各种编程元素，依次出现在该方法中。HandlerMapping、HandlerAdapter、View这些接口的设计，我们在第一篇中已经讲过。现在我们来重点关注一下HandlerExecutionChain这个对象。 从上面的代码中，很明显可以看出一条线索，整个方法是围绕着如何获取HandlerExecutionChain对象，执行HandlerExecutionChain对象得到相应的视图对象，再对视图进行渲染这条主线来展开的。HandlerExecutionChain对象显得异常重要。 因为Http请求要进入SpringMVC的处理体系，必须由HandlerMapping接口的实现类映射Http请求，得到一个封装后的HandlerExecutionChain对象。再由HandlerAdapter接口的实现类来处理这个HandlerExecutionChain对象所包装的处理对象，来得到最后渲染的视图对象。 视图对象是用ModelAndView对象来描述的，名字已经非常直白，就是数据和视图，其中的数据，由HttpServletRequest的属性得到，视图就是由HandlerExecutionChain封装的处理对象处理后得到。当然HandlerExecutionChain中的拦截器列表HandlerInterceptor，会在处理过程的前后依次被调用，为处理过程留下充足的扩展点。 所有的SpringMVC框架元素，都是围绕着HandlerExecutionChain这个执行链来发挥效用。我们来看看，HandlerExecutionChain类的代码。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package org.springframework.web.servlet;import java.util.ArrayList;import java.util.Arrays;import java.util.List;import org.springframework.util.CollectionUtils;public class HandlerExecutionChain &#123; private final Object handler; private HandlerInterceptor[] interceptors; private List&lt;HandlerInterceptor&gt; interceptorList; public HandlerExecutionChain(Object handler) &#123; this(handler, null); &#125; public HandlerExecutionChain(Object handler, HandlerInterceptor[] interceptors) &#123; if (handler instanceof HandlerExecutionChain) &#123; HandlerExecutionChain originalChain = (HandlerExecutionChain) handler; this.handler = originalChain.getHandler(); this.interceptorList = new ArrayList&lt;HandlerInterceptor&gt;(); CollectionUtils.mergeArrayIntoCollection(originalChain.getInterceptors(), this.interceptorList); CollectionUtils.mergeArrayIntoCollection(interceptors, this.interceptorList); &#125; else &#123; this.handler = handler; this.interceptors = interceptors; &#125; &#125; public Object getHandler() &#123; return this.handler; &#125; public void addInterceptor(HandlerInterceptor interceptor) &#123; initInterceptorList(); this.interceptorList.add(interceptor); &#125; public void addInterceptors(HandlerInterceptor[] interceptors) &#123; if (interceptors != null) &#123; initInterceptorList(); this.interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; private void initInterceptorList() &#123; if (this.interceptorList == null) &#123; this.interceptorList = new ArrayList&lt;HandlerInterceptor&gt;(); &#125; if (this.interceptors != null) &#123; this.interceptorList.addAll(Arrays.asList(this.interceptors)); this.interceptors = null; &#125; &#125; public HandlerInterceptor[] getInterceptors() &#123; if (this.interceptors == null &amp;&amp; this.interceptorList != null) &#123; this.interceptors = this.interceptorList.toArray(new HandlerInterceptor[this.interceptorList.size()]); &#125; return this.interceptors; &#125; @Override public String toString() &#123; if (this.handler == null) &#123; return "HandlerExecutionChain with no handler"; &#125; StringBuilder sb = new StringBuilder(); sb.append("HandlerExecutionChain with handler [").append(this.handler).append("]"); if (!CollectionUtils.isEmpty(this.interceptorList)) &#123; sb.append(" and ").append(this.interceptorList.size()).append(" interceptor"); if (this.interceptorList.size() &gt; 1) &#123; sb.append("s"); &#125; &#125; return sb.toString(); &#125;&#125; 一个拦截器列表，一个执行对象，这个类的内容十分的简单，它蕴含的设计思想，却十分的丰富。 拦截器组成的列表，在执行对象被调用的前后，会依次执行。这里可以看成是一个的AOP环绕通知，拦截器可以对处理对象随心所欲的进行处理和增强。这里明显是吸收了Struts2中拦截器的设计思想。这种AOP环绕式的扩展点设计，也几乎成为所有框架必备的内容。 实际的处理对象，即handler对象，是由Object对象来引用的。 private final Object handler;之所以要用一个java世界最基础的Object对象引用来引用这个handler对象，是因为连特定的接口也不希望绑定在这个handler对象上，从而使handler对象具有最大程度的选择性和灵活性。 我们常说，一个框架最高层次的抽象是接口，但是这里SpringMVC更进了一步。在最后的处理对象上面，SpringMVC没有对它做任何的限制，只要是java世界中的对象，都可以用来作为最后的处理对象，来生成视图。极端一点来说，你甚至可以将另外一个MVC框架集成到SpringMVC中来，也就是为什么SpringMVC官方文档中，居然还有集成其他表现层框架的内容。这一点，在所有表现层框架中，是独领风骚，冠绝群雄的。 3.结语 SpringMVC的成功，源于它对开闭原则的运用和遵守。也正因此，才使得整个框架具有如此强大的描述和扩展能力。这也许和SpringMVC出现和兴起的时间有关，正是经历了Struts1到Struts2这些Web开发领域MVC框架的更新换代，它的设计者才能站在前人的肩膀上。知道了如何将事情做的糟糕之后，你或许才知道如何将事情做得好。 希望在这个系列里面分享的SpringMVC源码阅读经验，能帮助读者们从更高的层次来审视SpringMVC框架的设计，也希望这里所描述的一些基本设计思想，能在你更深入的了解SpringMVC的细节时，对你有帮助。哲学才是唯一的、最终的武器，在一个框架的设计上，尤其是如此。经常地体会一个框架设计者的设计思想，对你更好的使用它，是有莫大的益处的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringMVC源码剖析（五）-消息转换器HttpMessageConverter]]></title>
      <url>%2F2017%2Fframe-springmvc5%2F</url>
      <content type="text"><![CDATA[摘要:在SpringMVC中，可以使用@RequestBody和@ResponseBody两个注解，分别完成请求报文到对象和对象到响应报文的转换，底层这种灵活的消息转换机制，就是Spring3.x中新引入的HttpMessageConverter即消息转换器机制。 正文:Http请求的抽象 还是回到请求-响应，也就是解析请求体，然后返回响应报文这个最基本的Http请求过程中来。我们知道，在servlet标准中，可以用javax.servlet.ServletRequest接口中的以下方法： public ServletInputStream getInputStream() throws IOException;来得到一个ServletInputStream。这个ServletInputStream中，可以读取到一个原始请求报文的所有内容。同样的，在javax.servlet.ServletResponse接口中，可以用以下方法： public ServletOutputStream getOutputStream() throws IOException;来得到一个ServletOutputStream，这个ServletOutputSteam，继承自java中的OutputStream，可以让你输出Http的响应报文内容。 让我们尝试着像SpringMVC的设计者一样来思考一下。我们知道，Http请求和响应报文本质上都是一串字符串，当请求报文来到java世界，它会被封装成为一个ServletInputStream的输入流，供我们读取报文。响应报文则是通过一个ServletOutputStream的输出流，来输出响应报文。 我们从流中，只能读取到原始的字符串报文，同样，我们往输出流中，也只能写原始的字符。而在java世界中，处理业务逻辑，都是以一个个有业务意义的对象为处理维度的，那么在报文到达SpringMVC和从SpringMVC出去，都存在一个字符串到java对象的阻抗问题。这一过程，不可能由开发者手工转换。我们知道，在Struts2中，采用了OGNL来应对这个问题，而在SpringMVC中，它是HttpMessageConverter机制。我们先来看两个接口。 HttpInputMessage 这个类是SpringMVC内部对一次Http请求报文的抽象，在HttpMessageConverter的read()方法中，有一个HttpInputMessage的形参，它正是SpringMVC的消息转换器所作用的受体“请求消息”的内部抽象，消息转换器从“请求消息”中按照规则提取消息，转换为方法形参中声明的对象。12345678910package org.springframework.http;import java.io.IOException;import java.io.InputStream;public interface HttpInputMessage extends HttpMessage &#123; InputStream getBody() throws IOException;&#125; HttpOutputMessage 这个类是SpringMVC内部对一次Http响应报文的抽象，在HttpMessageConverter的write()方法中，有一个HttpOutputMessage的形参，它正是SpringMVC的消息转换器所作用的受体“响应消息”的内部抽象，消息转换器将“响应消息”按照一定的规则写到响应报文中。12345678910package org.springframework.http;import java.io.IOException;import java.io.OutputStream;public interface HttpOutputMessage extends HttpMessage &#123; OutputStream getBody() throws IOException;&#125; HttpMessageConverter 对消息转换器最高层次的接口抽象，描述了一个消息转换器的一般特征，我们可以从这个接口中定义的方法，来领悟Spring3.x的设计者对这一机制的思考过程。123456789101112131415161718192021222324package org.springframework.http.converter;import java.io.IOException;import java.util.List;import org.springframework.http.HttpInputMessage;import org.springframework.http.HttpOutputMessage;import org.springframework.http.MediaType;public interface HttpMessageConverter&lt;T&gt; &#123; boolean canRead(Class&lt;?&gt; clazz, MediaType mediaType); boolean canWrite(Class&lt;?&gt; clazz, MediaType mediaType); List&lt;MediaType&gt; getSupportedMediaTypes(); T read(Class&lt;? extends T&gt; clazz, HttpInputMessage inputMessage) throws IOException, HttpMessageNotReadableException; void write(T t, MediaType contentType, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException;&#125; HttpMessageConverter接口的定义出现了成对的canRead()，read()和canWrite()，write()方法，MediaType是对请求的Media Type属性的封装。举个例子，当我们声明了下面这个处理方法。1234@RequestMapping(value="/string", method=RequestMethod.POST)public @ResponseBody String readString(@RequestBody String string) &#123; return "Read string '" + string + "'";&#125; 在SpringMVC进入readString方法前，会根据@RequestBody注解选择适当的HttpMessageConverter实现类来将请求参数解析到string变量中，具体来说是使用了StringHttpMessageConverter类，它的canRead()方法返回true，然后它的read()方法会从请求中读出请求参数，绑定到readString()方法的string变量中。 当SpringMVC执行readString方法后，由于返回值标识了@ResponseBody，SpringMVC将使用StringHttpMessageConverter的write()方法，将结果作为String值写入响应报文，当然，此时canWrite()方法返回true。 RequestResponseBodyMethodProcessor 将上述过程集中描述的一个类是org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor，这个类同时实现了HandlerMethodArgumentResolver和HandlerMethodReturnValueHandler两个接口。前者是将请求报文绑定到处理方法形参的策略接口，后者则是对处理方法返回值进行处理的策略接口。两个接口的源码如下：1234567891011121314151617package org.springframework.web.method.support;import org.springframework.core.MethodParameter;import org.springframework.web.bind.WebDataBinder;import org.springframework.web.bind.support.WebDataBinderFactory;import org.springframework.web.context.request.NativeWebRequest;public interface HandlerMethodArgumentResolver &#123; boolean supportsParameter(MethodParameter parameter); Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception;&#125; 123456789101112131415package org.springframework.web.method.support;import org.springframework.core.MethodParameter;import org.springframework.web.context.request.NativeWebRequest;public interface HandlerMethodReturnValueHandler &#123; boolean supportsReturnType(MethodParameter returnType); void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception;&#125; RequestResponseBodyMethodProcessor这个类，同时充当了方法参数解析和返回值处理两种角色。我们从它的源码中，可以找到上面两个接口的方法实现。 对HandlerMethodArgumentResolver接口的实现：1234567891011121314151617181920public boolean supportsParameter(MethodParameter parameter) &#123; return parameter.hasParameterAnnotation(RequestBody.class);&#125;public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception &#123; Object argument = readWithMessageConverters(webRequest, parameter, parameter.getGenericParameterType()); String name = Conventions.getVariableNameForParameter(parameter); WebDataBinder binder = binderFactory.createBinder(webRequest, argument, name); if (argument != null) &#123; validate(binder, parameter); &#125; mavContainer.addAttribute(BindingResult.MODEL_KEY_PREFIX + name, binder.getBindingResult()); return argument;&#125; 对HandlerMethodReturnValueHandler接口的实现12345678910111213public boolean supportsReturnType(MethodParameter returnType) &#123; return returnType.getMethodAnnotation(ResponseBody.class) != null;&#125; public void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws IOException, HttpMediaTypeNotAcceptableException &#123; mavContainer.setRequestHandled(true); if (returnValue != null) &#123; writeWithMessageConverters(returnValue, returnType, webRequest); &#125;&#125; 看完上面的代码，整个HttpMessageConverter消息转换的脉络已经非常清晰。因为两个接口的实现，分别是以是否有@RequestBody和@ResponseBody为条件，然后分别调用HttpMessageConverter来进行消息的读写。 如果你想问，怎么样跟踪到RequestResponseBodyMethodProcessor中，请你按照前面几篇博文的思路，然后到这里spring-mvc-showcase下载源码回来，对其中HttpMessageConverter相关的例子进行debug，只要你肯下功夫，相信你一定会有属于自己的收获的。 思考 张小龙在谈微信的本质时候说：“微信只是个平台，消息在其中流转”。在我们对SpringMVC源码分析的过程中，我们可以从HttpMessageConverter机制中领悟到类似的道理。在SpringMVC的设计者眼中，一次请求报文和一次响应报文，分别被抽象为一个请求消息HttpInputMessage和一个响应消息HttpOutputMessage。 处理请求时，由合适的消息转换器将请求报文绑定为方法中的形参对象，在这里，同一个对象就有可能出现多种不同的消息形式，比如json和xml。同样，当响应请求时，方法的返回值也同样可能被返回为不同的消息形式，比如json和xml。 在SpringMVC中，针对不同的消息形式，我们有不同的HttpMessageConverter实现类来处理各种消息形式。但是，只要这些消息所蕴含的“有效信息”是一致的，那么各种不同的消息转换器，都会生成同样的转换结果。至于各种消息间解析细节的不同，就被屏蔽在不同的HttpMessageConverter实现类中了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringMVC源码剖析（三）- DispatcherServlet的初始化流程]]></title>
      <url>%2F2017%2Fframe-springmvc3%2F</url>
      <content type="text"><![CDATA[摘要:在我们第一次学Servlet编程，学java web的时候，还没有那么多框架。我们开发一个简单的功能要做的事情很简单，就是继承HttpServlet，根据需要重写一下doGet，doPost方法，跳转到我们定义好的jsp页面。Servlet类编写完之后在web.xml里注册这个Servlet类。 正文:除此之外，没有其他了。我们启动web服务器，在浏览器中输入地址，就可以看到浏览器上输出我们写好的页面。为了更好的理解上面这个过程，你需要学习关于Servlet生命周期的三个阶段，就是所谓的“init-service-destroy”。 以上的知识，我觉得对于你理解SpringMVC的设计思想，已经足够了。SpringMVC当然可以称得上是一个复杂的框架，但是同时它又遵循Servlet世界里最简单的法则，那就是“init-service-destroy”。我们要分析SpringMVC的初始化流程，其实就是分析DispatcherServlet类的init()方法，让我们带着这种单纯的观点，打开DispatcherServlet的源码一窥究竟吧。 1.配置元素读取 用Eclipse IDE打开DispatcherServlet类的源码，ctrl+T看一下。 DispatcherServlet类的初始化入口方法init()定义在HttpServletBean这个父类中，HttpServletBean类作为一个直接继承于HttpServlet类的类，覆写了HttpServlet类的init()方法，实现了自己的初始化行为。123456789101112131415161718192021222324252627@Override public final void init() throws ServletException &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Initializing servlet '" + getServletName() + "'"); &#125; // Set bean properties from init parameters. try &#123; PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties); BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, this.environment)); initBeanWrapper(bw); bw.setPropertyValues(pvs, true); &#125; catch (BeansException ex) &#123; logger.error("Failed to set bean properties on servlet '" + getServletName() + "'", ex); throw ex; &#125; // Let subclasses do whatever initialization they like. initServletBean(); if (logger.isDebugEnabled()) &#123; logger.debug("Servlet '" + getServletName() + "' configured successfully"); &#125; &#125; 这里的initServletBean()方法在HttpServletBean类中是一个没有任何实现的空方法，它的目的就是留待子类实现自己的初始化逻辑，也就是我们常说的模板方法设计模式。SpringMVC在此生动的运用了这个模式，init()方法就是模版方法模式中的模板方法，SpringMVC真正的初始化过程，由子类FrameworkServlet中覆写的initServletBean()方法触发。 再看一下init()方法内被try,catch块包裹的代码，里面涉及到BeanWrapper，PropertyValues，ResourceEditor这些Spring内部非常底层的类。要深究具体代码实现上面的细节，需要对Spring框架源码具有相当深入的了解。我们这里先避繁就简，从代码效果和设计思想上面来分析这段try,catch块内的代码所做的事情： 注册一个字符串到资源文件的编辑器，让Servlet下面的配置元素可以使用形如“classpath:”这种方式指定SpringMVC框架bean配置文件的来源。将web.xml中在DispatcherServlet这个Servlet下面的配置元素利用JavaBean的方式（即通过setter方法）读取到DispatcherServlet中来。这两点，我想通过下面一个例子来说明一下。 我在web.xml中注册的DispatcherServlet配置如下：123456789101112131415&lt;!-- springMVC配置开始 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;appServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/spring-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;appServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- springMVC配置结束 --&gt; 可以看到，我注册了一个名为contextConfigLocation的元素，其值为“classpath:spring/spring-servlet.xml”，这也是大家常常用来指定SpringMVC配置文件路径的方法。上面那段try,catch块包裹的代码发挥的作用，一个是将“classpath:spring/spring-servlet.xml”这段字符串转换成classpath路径下的一个资源文件，供框架初始化读取配置元素。在我的工程中是在spring文件夹下面的配置文件spring-servlet.xml。 另外一个作用，就是将contextConfigLocation的值读取出来，然后通过setContextConfigLocation()方法设置到DispatcherServlet中，这个setContextConfigLocation()方法是在FrameworkServlet类中定义的，也就是上面继承类图中DispatcherServlet的直接父类。 我们在setContextConfigLocation()方法上面打上一个断点，启动web工程，就可以看到其classpath。 HttpServletBean类的作者是大名鼎鼎的Spring之父Rod Johnson。作为POJO编程哲学的大师，他在HttpServletBean这个类的设计中，运用了依赖注入思想完成了配置元素的读取。他抽离出HttpServletBean这个类的目的也在于此，就是“以依赖注入的方式来读取Servlet类的配置信息”，而且这里很明显是一种setter注入。 明白了HttpServletBean类的设计思想，我们也就知道可以如何从中获益。具体来说，我们继承HttpServletBean类（就像DispatcherServlet做的那样），在类中定义一个属性，为这个属性加上setter方法后，我们就可以在元素中为其定义值。在类被初始化后，值就会被注入进来，我们可以直接使用它，避免了样板式的getInitParameter()方法的使用，而且还免费享有Spring中资源编辑器的功能，可以在web.xml中，通过“classpath:”直接指定类路径下的资源文件。 注意，虽然SpringMVC本身为了后面初始化上下文的方便，使用了字符串来声明和设置contextConfigLocation参数，但是将其声明为Resource类型，同样能够成功获取。鼓励读者们自己继承HttpServletBean写一个测试用的Servlet类，并设置一个参数来调试一下，这样能够帮助你更好的理解获取配置参数的过程。 2.容器上下文的建立 上一篇文章中提到过，SpringMVC使用了Spring容器来容纳自己的配置元素，拥有自己的bean容器上下文。在SpringMVC初始化的过程中，非常关键的一步就是要建立起这个容器上下文，而这个建立上下文的过程，发生在FrameworkServlet类中，由上面init()方法中的initServletBean()方法触发。 123456789101112131415161718192021222324252627@Override protected final void initServletBean() throws ServletException &#123; getServletContext().log("Initializing Spring FrameworkServlet '" + getServletName() + "'"); if (this.logger.isInfoEnabled()) &#123; this.logger.info("FrameworkServlet '" + getServletName() + "': initialization started"); &#125; long startTime = System.currentTimeMillis(); try &#123; this.webApplicationContext = initWebApplicationContext(); initFrameworkServlet(); &#125; catch (ServletException ex) &#123; this.logger.error("Context initialization failed", ex); throw ex; &#125; catch (RuntimeException ex) &#123; this.logger.error("Context initialization failed", ex); throw ex; &#125; if (this.logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; this.logger.info("FrameworkServlet '" + getServletName() + "': initialization completed in " + elapsedTime + " ms"); &#125; &#125; initFrameworkServlet()方法是一个没有任何实现的空方法，除去一些样板式的代码，那么这个initServletBean()方法所做的事情已经非常明白： this.webApplicationContext = initWebApplicationContext();这一句简单直白的代码，道破了FrameworkServlet这个类，在SpringMVC类体系中的设计目的，它是 用来抽离出建立 WebApplicationContext 上下文这个过程的。initWebApplicationContext()方法，封装了建立Spring容器上下文的整个过程，方法内的逻辑如下： 获取由ContextLoaderListener初始化并注册在ServletContext中的根上下文，记为rootContext如果webApplicationContext已经不为空，表示这个Servlet类是通过编程式注册到容器中的（Servlet 3.0+中的ServletContext.addServlet() ），上下文也由编程式传入。若这个传入的上下文还没被初始化，将rootContext上下文设置为它的父上下文，然后将其初始化，否则直接使用。通过wac变量的引用是否为null，判断第2步中是否已经完成上下文的设置（即上下文是否已经用编程式方式传入），如果wac==null成立，说明该Servlet不是由编程式注册到容器中的。此时以contextAttribute属性的值为键，在ServletContext中查找上下文，查找得到，说明上下文已经以别的方式初始化并注册在contextAttribute下，直接使用。检查wac变量的引用是否为null，如果wac==null成立，说明2、3两步中的上下文初始化策略都没成功，此时调用createWebApplicationContext(rootContext)，建立一个全新的以rootContext为父上下文的上下文，作为SpringMVC配置元素的容器上下文。大多数情况下我们所使用的上下文，就是这个新建的上下文。以上三种初始化上下文的策略，都会回调onRefresh(ApplicationContext context)方法（回调的方式根据不同策略有不同），onRefresh方法在DispatcherServlet类中被覆写，以上面得到的上下文为依托，完成SpringMVC中默认实现类的初始化。最后，将这个上下文发布到ServletContext中，也就是将上下文以一个和Servlet类在web.xml中注册名字有关的值为键，设置为ServletContext的一个属性。你可以通过改变publishContext的值来决定是否发布到ServletContext中，默认为true。以上面6点跟踪FrameworkServlet类中的代码，可以比较清晰的了解到整个容器上下文的建立过程，也就能够领会到FrameworkServlet类的设计目的，它是用来建立一个和Servlet关联的Spring容器上下文，并将其注册到ServletContext中的。跳脱开SpringMVC体系，我们也能通过继承FrameworkServlet类，得到与Spring容器整合的好处，FrameworkServlet和HttpServletBean一样，是一个可以独立使用的类。整个SpringMVC设计中，处处体现开闭原则，这里显然也是其中一点。 3.初始化SpringMVC默认实现类 初始化流程在FrameworkServlet类中流转，建立了上下文后，通过onRefresh(ApplicationContext context)方法的回调，进入到DispatcherServlet类中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Override protected void onRefresh(ApplicationContext context) &#123; initStrategies(context); &#125;DispatcherServlet类覆写了父类FrameworkServlet中的onRefresh(ApplicationContext context)方法，提供了SpringMVC各种编程元素的初始化。当然这些编程元素，都是作为容器上下文中一个个bean而存在的。具体的初始化策略，在initStrategies()方法中封装。protected void initStrategies(ApplicationContext context) &#123; initMultipartResolver(context); initLocaleResolver(context); initThemeResolver(context); initHandlerMappings(context); initHandlerAdapters(context); initHandlerExceptionResolvers(context); initRequestToViewNameTranslator(context); initViewResolvers(context); initFlashMapManager(context); &#125;我们以其中initHandlerMappings(context)方法为例，分析一下这些SpringMVC编程元素的初始化策略，其他的方法，都是以类似的策略初始化的。private void initHandlerMappings(ApplicationContext context) &#123; this.handlerMappings = null; if (this.detectAllHandlerMappings) &#123; // Find all HandlerMappings in the ApplicationContext, including ancestor contexts. Map&lt;String, HandlerMapping&gt; matchingBeans = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerMapping.class, true, false); if (!matchingBeans.isEmpty()) &#123; this.handlerMappings = new ArrayList&lt;HandlerMapping&gt;(matchingBeans.values()); // We keep HandlerMappings in sorted order. OrderComparator.sort(this.handlerMappings); &#125; &#125; else &#123; try &#123; HandlerMapping hm = context.getBean(HANDLER_MAPPING_BEAN_NAME, HandlerMapping.class); this.handlerMappings = Collections.singletonList(hm); &#125; catch (NoSuchBeanDefinitionException ex) &#123; // Ignore, we'll add a default HandlerMapping later. &#125; &#125; // Ensure we have at least one HandlerMapping, by registering // a default HandlerMapping if no other mappings are found. if (this.handlerMappings == null) &#123; this.handlerMappings = getDefaultStrategies(context, HandlerMapping.class); if (logger.isDebugEnabled()) &#123; logger.debug("No HandlerMappings found in servlet '" + getServletName() + "': using default"); &#125; &#125; &#125; detectAllHandlerMappings变量默认为true，所以在初始化HandlerMapping接口默认实现类的时候，会把上下文中所有HandlerMapping类型的Bean都注册在handlerMappings这个List变量中。如果你手工将其设置为false，那么将尝试获取名为handlerMapping的Bean，新建一个只有一个元素的List，将其赋给handlerMappings。如果经过上面的过程，handlerMappings变量仍为空，那么说明你没有在上下文中提供自己HandlerMapping类型的Bean定义。此时，SpringMVC将采用默认初始化策略来初始化handlerMappings。 点进去getDefaultStrategies看一下。123456789101112131415161718192021222324252627282930@SuppressWarnings("unchecked") protected &lt;T&gt; List&lt;T&gt; getDefaultStrategies(ApplicationContext context, Class&lt;T&gt; strategyInterface) &#123; String key = strategyInterface.getName(); String value = defaultStrategies.getProperty(key); if (value != null) &#123; String[] classNames = StringUtils.commaDelimitedListToStringArray(value); List&lt;T&gt; strategies = new ArrayList&lt;T&gt;(classNames.length); for (String className : classNames) &#123; try &#123; Class&lt;?&gt; clazz = ClassUtils.forName(className, DispatcherServlet.class.getClassLoader()); Object strategy = createDefaultStrategy(context, clazz); strategies.add((T) strategy); &#125; catch (ClassNotFoundException ex) &#123; throw new BeanInitializationException( "Could not find DispatcherServlet's default strategy class [" + className + "] for interface [" + key + "]", ex); &#125; catch (LinkageError err) &#123; throw new BeanInitializationException( "Error loading DispatcherServlet's default strategy class [" + className + "] for interface [" + key + "]: problem with class file or dependent class", err); &#125; &#125; return strategies; &#125; else &#123; return new LinkedList&lt;T&gt;(); &#125; &#125; 它是一个范型的方法，承担所有SpringMVC编程元素的默认初始化策略。方法的内容比较直白，就是以传递类的名称为键，从defaultStrategies这个Properties变量中获取实现类，然后反射初始化。 需要说明一下的是defaultStrategies变量的初始化，它是在DispatcherServlet的静态初始化代码块中加载的。1234567891011121314private static final Properties defaultStrategies; static &#123; // Load default strategy implementations from properties file. // This is currently strictly internal and not meant to be customized // by application developers. try &#123; ClassPathResource resource = new ClassPathResource(DEFAULT_STRATEGIES_PATH, DispatcherServlet.class); defaultStrategies = PropertiesLoaderUtils.loadProperties(resource); &#125; catch (IOException ex) &#123; throw new IllegalStateException("Could not load 'DispatcherServlet.properties': " + ex.getMessage()); &#125; &#125; private static final String DEFAULT_STRATEGIES_PATH = “DispatcherServlet.properties”;这个DispatcherServlet.properties里面，以键值对的方式，记录了SpringMVC默认实现类，它在spring-webmvc-3.1.3.RELEASE.jar这个jar包内，在org.springframework.web.servlet包里面。123456789101112131415161718192021222324# Default implementation classes for DispatcherServlet's strategy interfaces.# Used as fallback when no matching beans are found in the DispatcherServlet context.# Not meant to be customized by application developers.org.springframework.web.servlet.LocaleResolver=org.springframework.web.servlet.i18n.AcceptHeaderLocaleResolverorg.springframework.web.servlet.ThemeResolver=org.springframework.web.servlet.theme.FixedThemeResolverorg.springframework.web.servlet.HandlerMapping=org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping,\ org.springframework.web.servlet.mvc.annotation.DefaultAnnotationHandlerMappingorg.springframework.web.servlet.HandlerAdapter=org.springframework.web.servlet.mvc.HttpRequestHandlerAdapter,\ org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter,\ org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapterorg.springframework.web.servlet.HandlerExceptionResolver=org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerExceptionResolver,\ org.springframework.web.servlet.mvc.annotation.ResponseStatusExceptionResolver,\ org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolverorg.springframework.web.servlet.RequestToViewNameTranslator=org.springframework.web.servlet.view.DefaultRequestToViewNameTranslatororg.springframework.web.servlet.ViewResolver=org.springframework.web.servlet.view.InternalResourceViewResolverorg.springframework.web.servlet.FlashMapManager=org.springframework.web.servlet.support.SessionFlashMapManager 至此，我们分析完了initHandlerMappings(context)方法的执行过程，其他的初始化过程与这个方法非常类似。所有初始化方法执行完后，SpringMVC正式完成初始化，静静等待Web请求的到来。 4.总结 回顾整个SpringMVC的初始化流程，我们看到，通过HttpServletBean、FrameworkServlet、DispatcherServlet三个不同的类层次，SpringMVC的设计者将三种不同的职责分别抽象，运用模版方法设计模式分别固定在三个类层次中。其中HttpServletBean完成的是配置元素的依赖注入，FrameworkServlet完成的是容器上下文的建立，DispatcherServlet完成的是SpringMVC具体编程元素的初始化策略。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker镜像的删除]]></title>
      <url>%2F2017%2FDocker-images-rm%2F</url>
      <content type="text"><![CDATA[摘要:很多人碰到过种种原因无法删除docker镜像，以下是关于删除镜像的顺序： 正文:1.停止所有的container，这样才能够删除其中的images 1docker stop $(docker ps -a -q) 2.查看当前有些什么images 1docker images 3.删除所有containers 1docker rm $(docker ps -a -q) 4.查看containers 1docker ps -a 5.删除某个镜像 12docker rmi 你的imageid或者docker rmi 你的imagename]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringMVC源码剖析（一）- 从抽象和接口说起]]></title>
      <url>%2F2017%2Fframe-springmvc1%2F</url>
      <content type="text"><![CDATA[摘要:SpringMVC作为Struts2之后异军突起的一个表现层框架，正越来越流行，相信javaee的开发者们就算没使用过SpringMVC，也应该对其略有耳闻。我试图通过对SpringMVC的设计思想和源码实现的剖析，从抽象意义上的设计层面和实现意义上的代码层面两个方面，逐一揭开SpringMVC神秘的面纱，本文的代码，都是基于Spring的 3.1.3RELEASE版本。 正文:任何一个框架，都有自己特定的适用领域，框架的设计和实现，必定是为了应付该领域内许多通用的，烦琐的、基础的工作而生。SpringMVC作为一个表现层框架，也必须直面Web开发领域中表现层中的几大课题，并给出自己的回答： URL到框架的映射。http请求参数绑定http响应的生成和输出这三大课题，组成一个完整的web请求流程，每一个部分都具有非常广阔的外延。SpringMVC框架对这些课题的回答又是什么呢？ 学习一个框架，首要的是要先领会它的设计思想。从抽象、从全局上来审视这个框架。其中最具有参考价值的，就是这个框架所定义的核心接口。核心接口定义了框架的骨架，也在最抽象的意义上表达了框架的设计思想。 下面我以一个web请求流程为载体，依次介绍SpringMVC的核心接口和类。 用户在浏览器中，输入了http://www.xxxx.com/aaa/bbb.ccc的地址，回车后，浏览器发起一个http请求。请求到达你的服务器后，首先会被SpringMVC注册在web.xml中的前端转发器DispatcherServlet接收，DispatcherServlet是一个标准的Servlet，它的作用是接受和转发web请求到内部框架处理单元。 下面看一下第一个出现在你面前的核心接口，它是在org.springframework.web.servlet包中定义的HandlerMapping接口：12345678910111213141516171819package org.springframework.web.servlet;import javax.servlet.http.HttpServletRequest;public interface HandlerMapping &#123; String PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE = HandlerMapping.class.getName() + ".pathWithinHandlerMapping"; String BEST_MATCHING_PATTERN_ATTRIBUTE = HandlerMapping.class.getName() + ".bestMatchingPattern"; String INTROSPECT_TYPE_LEVEL_MAPPING = HandlerMapping.class.getName() + ".introspectTypeLevelMapping"; String URI_TEMPLATE_VARIABLES_ATTRIBUTE = HandlerMapping.class.getName() + ".uriTemplateVariables"; String PRODUCIBLE_MEDIA_TYPES_ATTRIBUTE = HandlerMapping.class.getName() + ".producibleMediaTypes"; HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception;&#125; 为了阅读方便，我去掉了源码中的注释，但是我强烈建议你一定要记得去阅读它，这样你才能从框架的设计者口中得到最准确的关于这个类或者接口的设计说明。类中定义的几个常量，我们先不去管它。关键在于这个接口中唯一的方法： HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception;这个方法就算对于一个java初学者来说，也很容易理解：它只有一个类型为HttpServletRequest的参数，throws Exception的声明表示它不处理任何类型的异常，HandlerExecutionChain是它的返回类型。 回到DispatcherServlet的处理流程，当DispatcherServlet接收到web请求后，由标准Servlet类处理方法doGet或者doPost，经过几次转发后，最终注册在DispatcherServlet类中的HandlerMapping实现类组成的一个List（有点拗口）会在一个循环中被遍历。以该web请求的HttpServletRequest对象为参数，依次调用其getHandler方法，第一个不为null的调用结果，将被返回。DispatcherServlet类中的这个遍历方法不长，贴一下，让大家有更直观的了解。12345678910111213141516171819/** * Return the HandlerExecutionChain for this request. * &lt;p&gt;Tries all handler mappings in order. * @param request current HTTP request * @return the HandlerExecutionChain, or &lt;code&gt;null&lt;/code&gt; if no handler could be found */ protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; for (HandlerMapping hm : this.handlerMappings) &#123; if (logger.isTraceEnabled()) &#123; logger.trace( "Testing handler map [" + hm + "] in DispatcherServlet with name '" + getServletName() + "'"); &#125; HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) &#123; return handler; &#125; &#125; return null; &#125; 是的，第一步处理就这么简单的完成了。一个web请求经过处理后，会得到一个HandlerExecutionChain对象，这就是SpringMVC对URl映射给出的回答。需要留意的是，HandlerMapping接口的getHandler方法参数是HttpServletRequest，这意味着，HandlerMapping的实现类可以利用HttpServletRequest中的 所有信息来做出这个HandlerExecutionChain对象的生成”决策“。这包括，请求头、url路径、cookie、session、参数等等一切你从一个web请求中可以得到的任何东西（最常用的是url路径）。 SpirngMVC的第一个扩展点，就出现在这里。我们可以编写任意的HandlerMapping实现类，依据任何策略来决定一个web请求到HandlerExecutionChain对象的生成。可以说，从第一个核心接口的声明开始，SpringMVC就把自己的灵活性和野心暴露无疑：哥玩的就是”Open-Closed“。 HandlerExecutionChain这个类，就是我们下一个要了解的核心类。从名字可以直观的看得出，这个对象是一个执行链的封装。熟悉Struts2的都知道，Action对象也是被层层拦截器包装，这里可以做个类比，说明SpringMVC确实是吸收了Struts2的部分设计思想。 HandlerExecutionChain类的代码不长，它定义在org.springframework.web.servlet包中，为了更直观的理解，先上代码。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package org.springframework.web.servlet;import java.util.ArrayList;import java.util.Arrays;import java.util.List;import org.springframework.util.CollectionUtils;public class HandlerExecutionChain &#123; private final Object handler; private HandlerInterceptor[] interceptors; private List&lt;HandlerInterceptor&gt; interceptorList; public HandlerExecutionChain(Object handler) &#123; this(handler, null); &#125; public HandlerExecutionChain(Object handler, HandlerInterceptor[] interceptors) &#123; if (handler instanceof HandlerExecutionChain) &#123; HandlerExecutionChain originalChain = (HandlerExecutionChain) handler; this.handler = originalChain.getHandler(); this.interceptorList = new ArrayList&lt;HandlerInterceptor&gt;(); CollectionUtils.mergeArrayIntoCollection(originalChain.getInterceptors(), this.interceptorList); CollectionUtils.mergeArrayIntoCollection(interceptors, this.interceptorList); &#125; else &#123; this.handler = handler; this.interceptors = interceptors; &#125; &#125; public Object getHandler() &#123; return this.handler; &#125; public void addInterceptor(HandlerInterceptor interceptor) &#123; initInterceptorList(); this.interceptorList.add(interceptor); &#125; public void addInterceptors(HandlerInterceptor[] interceptors) &#123; if (interceptors != null) &#123; initInterceptorList(); this.interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; private void initInterceptorList() &#123; if (this.interceptorList == null) &#123; this.interceptorList = new ArrayList&lt;HandlerInterceptor&gt;(); &#125; if (this.interceptors != null) &#123; this.interceptorList.addAll(Arrays.asList(this.interceptors)); this.interceptors = null; &#125; &#125; public HandlerInterceptor[] getInterceptors() &#123; if (this.interceptors == null &amp;&amp; this.interceptorList != null) &#123; this.interceptors = this.interceptorList.toArray(new HandlerInterceptor[this.interceptorList.size()]); &#125; return this.interceptors; &#125; @Override public String toString() &#123; if (this.handler == null) &#123; return "HandlerExecutionChain with no handler"; &#125; StringBuilder sb = new StringBuilder(); sb.append("HandlerExecutionChain with handler [").append(this.handler).append("]"); if (!CollectionUtils.isEmpty(this.interceptorList)) &#123; sb.append(" and ").append(this.interceptorList.size()).append(" interceptor"); if (this.interceptorList.size() &gt; 1) &#123; sb.append("s"); &#125; &#125; return sb.toString(); &#125;&#125; 乱七八糟一大堆，相信你也没全看完，也没必要全看。其实只需要看两行足矣。private final Object handler; private HandlerInterceptor[] interceptors; 不出我们所料，一个实质执行对象，还有一堆拦截器。这不就是Struts2中的实现么，SpringMVC没有避嫌，还是采用了这种封装。得到HandlerExecutionChain这个执行链（execution chain）之后，下一步的处理将围绕其展开。 HandlerInterceptor也是SpringMVC的核心接口，定义如下：12345678910111213141516171819package org.springframework.web.servlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public interface HandlerInterceptor &#123; boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; void postHandle( HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception; void afterCompletion( HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception;&#125; 至此，HandlerExecutionChain整个执行脉络也就清楚了：在真正调用其handler对象前，HandlerInterceptor接口实现类组成的数组将会被遍历，其preHandle方法会被依次调用，然后真正的handler对象将被调用。 handler对象被调用后，就生成了需要的响应数据，在将处理结果写到HttpServletResponse对象之前（SpringMVC称为渲染视图），其postHandle方法会被依次调用。视图渲染完成后，最后afterCompletion方法会被依次调用，整个web请求的处理过程就结束了。 在一个处理对象执行之前，之后利用拦截器做文章，这已经成为一种经典的框架设计套路。Struts2中的拦截器会做诸如参数绑定这类复杂的工作，那么SpringMVC的拦截器具体做些什么呢？我们暂且不关心，虽然这是很重要的细节，但细节毕竟是细节，我们先来理解更重要的东西。 HandlerInterceptor，是SpringMVC的第二个扩展点的暴露，通过自定义拦截器，我们可以在一个请求被真正处理之前、请求被处理但还没输出到响应中、请求已经被输出到响应中之后这三个时间点去做任何我们想要做的事情。Struts2框架的成功，就是源于这种拦截器的设计，SpringMVC吸收了这种设计思想，并推陈出新，更合理的划分了三个不同的时间点，从而给web请求处理这个流程，提供了更大的扩展性。 这个HandlerExecutionChain类中以Object引用所声明的handler对象，到底是个什么东东？它是怎么被调用的？ 回答这些问题之前，先看SpringMVC中的又一个核心接口，HandlerAdapter：1234567891011121314package org.springframework.web.servlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public interface HandlerAdapter &#123; boolean supports(Object handler); ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; long getLastModified(HttpServletRequest request, Object handler);&#125; 在DispatcherServlet中，除了HandlerMapping实现类的列表，同样也注册了一个HandlerAdapter实现类组成的列表，有代码为证。123456789101112131415161718192021222324/** List of HandlerMappings used by this servlet */ private List&lt;HandlerMapping&gt; handlerMappings; /** List of HandlerAdapters used by this servlet */ private List&lt;HandlerAdapter&gt; handlerAdapters;接下来，我们再以DispatcherServlet类中另外一段代码来回答上述的问题：/** * Return the HandlerAdapter for this handler object. * @param handler the handler object to find an adapter for * @throws ServletException if no HandlerAdapter can be found for the handler. This is a fatal error. */ protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &#123; for (HandlerAdapter ha : this.handlerAdapters) &#123; if (logger.isTraceEnabled()) &#123; logger.trace("Testing handler adapter [" + ha + "]"); &#125; if (ha.supports(handler)) &#123; return ha; &#125; &#125; throw new ServletException("No adapter for handler [" + handler + "]: Does your handler implement a supported interface like Controller?"); &#125; 这段代码已经很明显了，HandlerExecutionChain中的handler对象会被作为参数传递进去，在DispatcherServlet类中注册的HandlerAdapter实现类列表会被遍历，然后返回第一个supports方法返回true的HandlerAdapter对象，用这个HandlerAdapter实现类中的handle方法处理handler对象，并返回ModelAndView这个包含了视图和数据的对象。HandlerAdapter就是SpringMVC提供的第三个扩展点，你可以提供自己的实现类来处理handler对象。 ModelAndView对象的代码就不贴了，它是SpringMVC中对视图和数据的一个聚合类。其中的视图，就是由SpringMVC的最后一个核心接口View所抽象：123456789101112131415161718package org.springframework.web.servlet;import java.util.Map;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public interface View &#123; String RESPONSE_STATUS_ATTRIBUTE = View.class.getName() + ".responseStatus"; String PATH_VARIABLES = View.class.getName() + ".pathVariables"; String getContentType(); void render(Map&lt;String, ?&gt; model, HttpServletRequest request, HttpServletResponse response) throws Exception;&#125; 所有的数据，最后会作为一个Map对象传递到View实现类中的render方法，调用这个render方法，就完成了视图到响应的渲染。这个View实现类，就是来自HandlerAdapter中的handle方法的返回结果。当然从ModelAndView到真正的View实现类有一个解析的过程，ModelAndView中可以有真正的视图对象，也可以只是有一个视图的名字，SpringMVC会负责将视图名称解析为真正的视图对象。 至此，我们了解了一个典型的完整的web请求在SpringMVC中的处理过程和其中涉及到的核心类和接口。 在一个典型的SpringMVC调用中，HandlerExecutionChain中封装handler对象就是用@Controller注解标识的类的一个实例，根据类级别和方法级别的@RequestMapping注解，由默认注册的DefaultAnnotationHandlerMapping（3.1.3中更新为RequestMappingHandlerMapping类，但是为了向后兼容，DefaultAnnotationHandlerMapping也可以使用）生成HandlerExecutionChain对象，再由AnnotationMethodHandlerAdapter（3.1.3中更新为RequestMappingHandlerAdapter类，但是为了向后兼容，AnnotationMethodHandlerAdapter也可以使用）来执行这个HandlerExecutionChain对象，生成最终的ModelAndView对象后，再由具体的View对象的render方法渲染视图。 可以看到，作为一个表现层框架，SpringMVC没有像Struts2那样激进，并没有采用和Web容器完全解耦的设计思想，而是以原生的Servlet框架对象为依托，通过合理的抽象，制定了严谨的的处理流程。这样做的结果是，执行效率比Struts2要高，灵活性也上升了一个层次。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[No mapping found for HTTP request with URI… in Dis]]></title>
      <url>%2F2017%2Fframe-springmvc-bug%2F</url>
      <content type="text"><![CDATA[摘要:No mapping found for HTTP request with URI [json2.js] in DispatcherServlet with name ‘springmvc’ 正文:今天下午用ie8 使用json时候发现需要导入json官方包json2.js下载地址:http://download.csdn.net/detail/wqr1128/9042071导入后发现后台报错No mapping found for HTTP request with URI [json2.js] in DispatcherServlet with name ‘springmvc’网上找了一些方案都没解决 后来在 Stack Overflow上找到了解决办法：在springmvc-servlet.xml里加入就ok了|————————————————分割线——————————————————|在springMVC-servlet.xml中配置后，会在Spring MVC上下文中定义一个org.springframework.web.servlet.resource.DefaultServletHttpRequestHandler，它会像一个检查员，对进入DispatcherServlet的URL进行筛查，如果发现是静态资源的请求，就将该请求转由Web应用服务器默认的Servlet处理，如果不是静态资源的请求，才由DispatcherServlet继续处理。 一般Web应用服务器默认的Servlet名称是”default”，因此DefaultServletHttpRequestHandler可以找到它。如果你所有的Web应用服务器的默认Servlet名称不是”default”，则需要通过default-servlet-name属性显示指定： 这个标签主要还是为了适应REST风格]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringMVC源码剖析（二）- DispatcherServlet的前世今生]]></title>
      <url>%2F2017%2Fframe-springmvc2%2F</url>
      <content type="text"><![CDATA[摘要:上一篇文章《SpringMVC源码剖析（一）- 从抽象和接口说起》中，我介绍了一次典型的SpringMVC请求处理过程中，相继粉墨登场的各种核心类和接口。我刻意忽略了源码中的处理细节，只列出最简单的类甚至是接口类，目的就是让大家先从最高层次的抽象意义上来审视SpringMVC这个框架；我也刻意将SpringMVC和Struts2做对比，目的是让大家看到，SpringMVC究竟吸取了Sturts2设计思想中的哪些精华，又弥补了它的哪些遗憾。 正文:DispatcherServlet作为SpringMVC的核心之中的核心类，再怎么强调它的重要性也不为过。SpringMVC所有的核心类和接口，都密集地出现在DispatcherServlet的源码中，SpringMVC源码剖析，很大程度上可以说也是在剖析DispatcherServlet这一个类。这一篇文章里，我先说几点关于DispatcherServlet的前世今生，希望能帮助你更好的理解它。 1.对扩展开放，对修改封闭 SpringMVC是一个基于著名的Open-Closed，即开闭原则进行设计的框架。在Spring官方文档里面关于SpringMVC的介绍开宗明义地进行了说明： A key design principle in Spring Web MVC and in Spring in general is the “Open for extension,closed for modification” principle.开闭原则是一个很宽泛的原则，具体体现到DispatcherServlet的源码中，我们可以大致摸得到一些线索： 类中所有的变量声明，几乎都以接口的形式给出，并没有绑定在具体的实现类上。使用模版方法模式，在父类中对基础行为进行定义，让子类实现模版方法扩展行为。其中第一点，在一个框架的设计中尤为重要，也是贯彻开闭原则最重要的一点。因为当你通过一些高层次的接口或者抽象类，将一个类完成的逻辑或流程编写完成后（具体点说，是通过一个接口的引用调用接口方法），整个逻辑或流程的功能就被确实的在源码中固定下来了。可是这时，这些接口或抽象类的具体实现者是谁，还没有固定！这就给了你的系统或框架近乎无限的扩展性，因为你可以任意安排和实现这些类。 我认为，面向对象设计的精髓，是对现实世界中“行为和契约”的描述。这个“行为和契约”，体现在接口和抽象类的方法声明中。软件设计师要用面向对象的眼光去观察和抽象这个世界中的事物，这里的事物可以是一些商业逻辑、可以是一些处理流程，然后用高层次的接口去描述这些行为和契约。当你在越抽象的层次上将这些行为和契约描述清楚后，你所设计的系统就是越符合开闭原则的。 SpringMVC框架在面向对象设计上，做出了绝佳的示范。它通过高度抽象的接口，描述出了一次请求处理的流程，从而让整个框架从一开始就是符合开闭原则的。同时它也提供了这些接口的一系列默认实现类，让你不需要很复杂的配置，就能很好的使用SpringMVC进行开发。抽象的确是个利器，但是框架绝不能运行在空中楼阁中，SpringMVC提供的的这一系列默认实现类必须要有容身之所。聪明的你可能早已想到：Spring IOC容器。这就引出了我要说的第二点。 2.配置元素的对象化 所有的框架，都需要有这样一个功能，叫做：配置元素的对象化。因为几乎所有的框架，都将配置元素集中到外部的xml配置文件中，然后在框架的初始化流程中，对这些配置文件进行解析，再变成java世界中的一个个对象供框架使用，这整个过程，可以被称为配置元素的对象化。为什么要有配置文件呢？这个问题的回答也是很简单，因为没有人会想要使用一个配置散布在框架中各个java类源码里面的框架。框架也不允许使用者这样子做，因为框架在发布的时候，提供的是一个个jar包文件，jar包内是已经编译好的class文件。配置文件由使用者外部提供，框架对它进行解析，使用者能得到集中配置的好处，框架也乐于这样子，可以说是合情合理。 那么作为Spring产品族的新成员，SpringMVC在设计的时候，相信设计者们不做它想，这一个“配置元素的对象化”功能既然不可避免，那么使用Spring IOC容器，通过bean配置文件来配置SpringMVC，绝对是不二之选。不可能像Struts2一样，内部再搞一个别的容器，因为Spring容器本身已经是被高度设计，而且已经在java世界获得巨大成功。从推广的角度上来说，如果对spring容器的所有知识，都可以完整的应用到SpringMVC，那么对于开发者无疑是一个极大的吸引力。 剩下的问题就只有：到底该如何将Spring容器和SpringMVC的初始化过程整合起来呢？ 答案就是WebApplicationContext接口，更具体点说，是XmlWebApplicationContext这个Spring上下文实现类。SpringMVC也使用了这一个为了将Spring容器和Web环境整合而特意设计的Spring上下文类。我们打开WebApplicationContext的源码： 123456789101112131415161718192021222324252627package org.springframework.web.context;import javax.servlet.ServletContext;import org.springframework.context.ApplicationContext;public interface WebApplicationContext extends ApplicationContext &#123; String ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE = WebApplicationContext.class.getName() + ".ROOT"; String SCOPE_REQUEST = "request"; String SCOPE_SESSION = "session"; String SCOPE_GLOBAL_SESSION = "globalSession"; String SCOPE_APPLICATION = "application"; String SERVLET_CONTEXT_BEAN_NAME = "servletContext"; String CONTEXT_PARAMETERS_BEAN_NAME = "contextParameters"; String CONTEXT_ATTRIBUTES_BEAN_NAME = "contextAttributes"; ServletContext getServletContext(); &#125; 发现它是继承于ApplicationContext这个普通Spring容器所使用的上下文接口类，除了一些常量的声明，只多了一个可以获取到ServletContext的getServletContext()方法。回到上面提到的“行为和契约的描述”上，我们可以大胆的断言，Spring容器和Web环境的整合，是在ServletContext上做文章。 打开所有使用了Spring的Web项目的web.xml文件，必定有这样一段配置： 123&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; ContextLoaderListener实现了ServletContextListener接口，在Servlet容器启动的时候，会初始化一个WebApplicationContext的实现类，并将其作为ServletContext的一个属性设置到Servlet环境中，摘抄源码如下：1servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE的值，在上面WebApplicationContext的源码中的第一个常量中就被声明，是WebApplicationContext.class.getName() + “.ROOT”，更直接一点，它是“org.springframework.web.context.WebApplicationContext.ROOT”。ContextLoaderListener所初始化的这个Spring容器上下文，被称为根上下文。 SpringMVC在DispatcherServlet的初始化过程中，同样会初始化一个WebApplicationContext的实现类，作为自己独有的上下文，这个独有的上下文，会将上面的根上下文作为自己的父上下文，来存放SpringMVC的配置元素，然后同样作为ServletContext的一个属性，被设置到ServletContext中，只不过它的key就稍微有点不同，key和具体的DispatcherServlet注册在web.xml文件中的名字有关，从这一点也决定了，我们可以在web.xml文件中注册多个DispatcherServlet，因为Servlet容器中注册的Servlet名字肯定不一样，设置到Servlet环境中的key也肯定不同。 由于在Spring容器中，子上下文可以访问到所有父上下文中的信息，而父上下文访问不到子上下文的信息，这个根上下文，就很适合作为多个子上下文配置的集中点。 3.前端控制器 前端控制器，即所谓的Front Controller，体现的是设计模式中的前端控制器模式。前端控制器处理所有从用户过来的请求。所有用户的请求都要通过前端控制器。SpringMVC框架和其他请求驱动的表示层框架一样，也是围绕一个将请求分发到相应控制器的核心Servlet来设计的。DispatcherServlet和其他框架中的Servlet不一样的地方在于，它和Spring容器无缝整合在了一起，因此你可以在SpringMVC中使用Spring容器所有的特性。 整个流程可以被大致描述为：一个http请求到达服务器，被DispatcherServlet接收。DispatcherServlet将请求委派给合适的处理器Controller，此时处理控制权到达Controller对象。Controller内部完成请求的数据模型的创建和业务逻辑的处理，然后再将填充了数据后的模型即model和控制权一并交还给DispatcherServlet，委派DispatcherServlet来渲染响应。DispatcherServlet再将这些数据和适当的数据模版视图结合，向Response输出响应。 可以看到Model-View-Controller这三样东西协同合作，共同体现出MVC的设计理念，三个层次可以分别独立演化，整个系统架构又清晰又简洁。这是SpringMVC为我们描述的美好愿景，后面我们也将看到，SpringMVC为了实现这一承诺，究竟做出了什么样的努力。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java持久层框架mybatis如何防止sql注入]]></title>
      <url>%2F2017%2Fframe-mybatis-sql%2F</url>
      <content type="text"><![CDATA[摘要:sql注入大家都不陌生，是一种常见的攻击方式，攻击者在界面的表单信息或url上输入一些奇怪的sql片段，例如”or ‘1’=’1’”这样的语句，有可能入侵参数校验不足的应用程序。所以在我们的应用中需要做一些工作，来防备这样的攻击方式。 正文:sql注入大家都不陌生，是一种常见的攻击方式，攻击者在界面的表单信息或url上输入一些奇怪的sql片段，例如”or ‘1’=’1’”这样的语句，有可能入侵参数校验不足的应用程序。所以在我们的应用中需要做一些工作，来防备这样的攻击方式。在一些安全性很高的应用中，比如银行软件，经常使用将sql语句全部替换为存储过程这样的方式，来防止sql注入，这当然是一种很安全的方式，但我们平时开发中，可能不需要这种死板的方式。mybatis框架作为一款半自动化的持久层框架，其sql语句都要我们自己来手动编写，这个时候当然需要防止sql注入。其实Mybatis的sql是一个具有“输入+输出”功能，类似于函数的结构，如下：&lt;select id=”getBlogById” resultType=”Blog”parameterType=”int”&gt; select id,title,author,content from blog where id=#{id} &lt;/select&gt;这里，parameterType标示了输入的参数类型，resultType标示了输出的参数类型。回应上文，如果我们想防止sql注入，理所当然地要在输入参数上下功夫。上面代码中高亮部分即输入参数在sql中拼接的部分，传入参数后，打印出执行的sql语句，会看到sql是这样的：selectid,title,author,content from blog where id = ?不管输入什么参数，打印出的sql都是这样的。这是因为mybatis启用了预编译功能，在sql执行前，会先将上面的sql发送给数据库进行编译，执行时，直接使用编译好的sql，替换占位符“？”就可以了。因为sql注入只能对编译过程起作用，所以这样的方式就很好地避免了sql注入的问题。mybatis是如何做到sql预编译的呢？其实在框架底层，是jdbc中的PreparedStatement类在起作用，PreparedStatement是我们很熟悉的Statement的子类，它的对象包含了编译好的sql语句。这种“准备好”的方式不仅能提高安全性，而且在多次执行一个sql时，能够提高效率，原因是sql已编译好，再次执行时无需再编译。话说回来，是否我们使用mybatis就一定可以防止sql注入呢？当然不是，请看下面的代码：&lt;select id=”orderBlog” resultType=”Blog”parameterType=”map”&gt; select id,title,author,content from blog order by ${orderParam} &lt;/select&gt;仔细观察，内联参数的格式由”#{xxx}”变为了${xxx}。如果我们给参数”orderParam”赋值为”id”,将sql打印出来，是这样的：select id,title,author,content fromblog order by id 显然，这样是无法阻止sql注入的。在mybatis中，”${xxx}”这样格式的参数会直接参与sql编译，从而不能避免注入攻击。但涉及到动态表名和列名时，只能使用”${xxx}”这样的参数格式，所以，这样的参数需要我们在代码中手工进行处理来防止注入。 结论：在编写mybatis的映射语句时，尽量采用”#{xxx}”这样的格式。若不得不使用“${xxx}”这样的参数，要手工地做好过滤工作，来防止sql注入攻击。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ThreadLocal 内存泄漏问题分析]]></title>
      <url>%2F2017%2Fjavase-ThreadLocal%2F</url>
      <content type="text"><![CDATA[摘要:ThreadLocal 的作用是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。但是如果滥用ThreadLocal，就可能会导致内存泄漏。下面，我们将围绕三个方面来分析ThreadLocal 内存泄漏的问题 正文:ThreadLocal的实现是这样的：每个Thread 维护一个 ThreadLocalMap 映射表，这个映射表的 key 是 ThreadLocal实例本身，value 是真正需要存储的 Object。 也就是说 ThreadLocal 本身并不存储值，它只是作为一个 key 来让线程从 ThreadLocalMap 获取 value。值得注意的是图中的虚线，表示 ThreadLocalMap 是使用 ThreadLocal 的弱引用作为 Key 的，弱引用的对象在 GC 时会被回收。 #ThreadLocal为什么会内存泄漏 ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。 其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。 但是这些被动的预防措施并不能保证不会内存泄漏： 使用static的ThreadLocal，延长了ThreadLocal的生命周期，可能导致的内存泄漏。分配使用了ThreadLocal又不再调用get(),set(),remove()方法，那么就会导致内存泄漏。 ##为什么使用弱引用 从表面上看内存泄漏的根源在于使用了弱引用。网上的文章大多着重分析ThreadLocal使用了弱引用会导致内存泄漏，但是另一个问题也同样值得思考：为什么使用弱引用而不是强引用？ 我们先来看看官方文档的说法： To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys.为了应对非常大和长时间的用途，哈希表使用弱引用的 key。 下面我们分两种情况讨论： key 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除。比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。 因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。 #ThreadLocal 最佳实践 综合上面的分析，我们可以理解ThreadLocal内存泄漏的前因后果，那么怎么避免内存泄漏呢？ 每次使用完ThreadLocal，都调用它的remove()方法，清除数据。在使用线程池的情况下，没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java endorsed]]></title>
      <url>%2F2017%2Fjavase-endorsed%2F</url>
      <content type="text"><![CDATA[摘要:endorsed:可以的简单理解为-Djava.endorsed.dirs指定的目录面放置的jar文件，将有覆盖系统API的功能 正文:今天突然看到这样的一个面试题：能否自已写个类也叫java.lang.String？能否自已写个类也叫java.util.ArrayList？第一个问题，答案相对简单：自己定义java.lang.String类语法上没有错误，但由于JVM类加载器的父委托机制，JVM只会加载jre.jar中的java.lang.String。如果调用自定义String类中方法，会出现三种情况：1&gt;调用的方法在jdk中String类中存在，将不会报错也没有任务影响，并且执行的是jdk中的String类方法；2&gt;调用的方法在jdk中String类中不存在，但在自定义String中存在，将抛出java.lang.NoSuchMethodError异常。3&gt;调用的方法在jdk中String类中存在，但在自定义String中不存在，编辑出错，运行抛出java.lang.Error: Unresolved compilation problem 第二个问题，虽然也存在类加载的问题，但是java提供了endorsed技术：关于endorsed：可以的简单理解为-Djava.endorsed.dirs指定的目录面放置的jar文件，将有覆盖系统API的功能。可以牵强的理解为，将自己修改后的API打入到虚拟机指定的启动API中，取而代之。但是能够覆盖的类是有限制的，其中不包括java.lang包中的类。 注意：1&gt;endorsed目录：.[jdk安装目录]./jre/lib/endorsed，不是jdk/lib/endorsed，目录中放的是Jar包，不是.java或.class文件，哪怕只重写了一个类也要打包成jar包。2&gt;可以在dos模式查看修改后的效果(javac、java)，在eclipse需要将运行选项中的JRE栏设置为jre(若设置为jdk将看不到效果)。3&gt;重写的类必须满足jdk中的规范，例如：自定义的ArrayList类也必须实现List等接口。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java内存管理以及内存泄露]]></title>
      <url>%2F2017%2Fjavase-memory-leak%2F</url>
      <content type="text"><![CDATA[摘要:Java的一个重要优点就是通过垃圾收集器(Garbage Collection，GC)自动管理内存的回收，程序员不需要通过调用函数来释放内存。因此，很多程序员认为Java不存在内存泄漏问题，或者认为即使有内存泄漏也不是程序的责任，而是GC或JVM的问题。其实，这种想法是不正确的，因为Java也存在内存泄露，但它的表现与C++不同。 正文:java和c++相比重要优点就是通过垃圾收集器(Garbage Collection，GC)自动管理内存的回收，程序员不需要通过调用函数来释放内存。这样的优点也会害了一部分学而不精的人。因为，很多程序员认为Java有垃圾回收机制，因此不存在内存泄漏问题，或者认为即使有内存泄漏也不是程序的责任，而是GC或JVM的问题。其实，这种想法是不正确的，因为Java也存在内存泄露，但它的表现与C++不同。使用java开发的jsp，servlet等程序众多，成千上万的服务器在运行着java。而且这些程序都是长期运行的，因此内存泄露问题也就变得十分关键，即使每次运行少量泄漏，长期运行之后，系统也是面临崩溃的危险。Java的内存管理就是对象的分配和释放问题。内存的分配需要通过关键字new为每个对象申请内存空间 (基本类型除外)，所有的对象都在堆 (Heap)中分配空间。对象的释放是由GC决定和执行的。这样的设计确实简化了程序员的工作。但同时，它也加重了JVM的工作。这也是编写低劣的Java程序运行速度较慢大量消耗系统资源的原因之一。因为，GC为了能够正确释放对象，GC必须监控每一个对象的运行状态，包括对象的申请、引用、被引用、赋值等，GC都需要进行监控。监视对象状态是为了更加准确地、及时地释放对象，而释放对象的根本原则就是该对象不再被引用。java中内存泄露的对象有两个显著的特点。首先，这些对象是可达的，即在有向图中，存在通路可以与其相连；其次，这些对象是无用的，即程序以后不会再使用这些对象。如果对象满足这两个条件，这些对象就可以判定为Java中的内存泄漏，这些对象不会被GC所回收，然而它却占用内存。GC基本是透明的，不可见的。虽然我们可以运行GC的函数System.gc()，但是根据Java语言规范定义，该函数不保证JVM的垃圾收集器一定会执行。因为，不同的JVM实现者可能使用不同的算法管理GC。通常，GC的线程的优先级别较低。当前最为常见同时又容易被熟视无睹的Java应用内存泄露情景如下：在JDK1.6及以下版本中，如果存在如下类似的代码，那么你想也不要想，100%内存泄露，String str1=new String(“123456789”);str1=str1.subString(2);或String str1=”123456789”;str1=str1.substring(2);相类似上面这种对字符串对象的处理，在日常的应用开发中，可以说比比皆是，但是正是在这样的情况下，内存泄露却实实在在的隐蔽的发生了，这种情况通常在一个应用系统中会有很多，这些积累下来就会泄漏大量内存。不管你是通过对象定义也好、常量定义也好、还是通过方法调用获取一个字符串结果对象也好，只要你直接在这些对象上进行字符串截取，就发生了泄漏。泄漏内存的多少，取决于你的字符串的大小。为什么会这样，原因如下：在JDK1.6及以下版本中，String类的substring方法的实现中，最后在返回结果时的实现如下：return ((beginIndex==0)&amp;&amp;(endIndex==count))?this:new String(offset+beginIndex,endIndex-beginIndex,value);问题出在new String(offset+beginIndex,endIndex-beginIndex,value)的实现，如下：String(int offset,int count,char[] value){this.value=value;this.count=count;this.offset=offset;}String对象中的字符串在具体实现中，被存储在字符数组char[] value中，而在上述的实现中char[] value数组实际上被共享了，即我们对字符串对象的截取，都是通过移动存储字符串值的字符数据的索引下标和偏移量实现的，而字符数组是类变量，会对所有实例所有实例可达，那么在截取后，被截取的字符组成的部分字符数组以至于被共享的整体字符数组在JVM Heap中无法被释放，内存出现了泄漏。我想Java这样设计的初衷，是想通过字符数组共享，达到节省内存消耗的目的，但弄巧成拙出现了内存泄露，这也要引起个开发人员的注意，Sun的Java实现尚且如此，各位的开发实现更要小心加小心，Java并不是免费的午餐。这个问题在JDK1.6及以下版本中可以通过如下方式避免：String str1=new String(“123456789”);str1=new String(str1.subString(2));思路很简单，将截取后对象变成新对象，解除截取后对象对字符数组的共享依赖，进而避免内存泄漏。上述的问题直到JDK1.7才被彻底修复，也就是说，如果是JDK1.7之下的版本开发的应用系统，如果存在上述的写法，一定会内存泄漏，应该采用上面的策略修复；如果是JDK1.7及其之上的版本上述的问题写法是没有问题的。鉴于目前JDK1.6是主流JDK应用，上述问题我认为会大面积的存在。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker介绍]]></title>
      <url>%2F2017%2FDocker-info%2F</url>
      <content type="text"><![CDATA[摘要:Docker是一个用于开发、交付和运行应用的开放平台 正文:Docker概览Docker是一个用于开发、交付和运行应用的开放平台，Docker被设计用于更快地交付应用。Docker可以将应用程序和基础设施层隔离，并且可以将基础设施当作程序一样进行管理。使用Docker，可以更快地打包代码、测试以及部署，并且可以减少从编写到部署运行代码的周期。 Docker将内核容器特性（LXC）、工作流和工具集成，以帮助管理和部署应用。 什么是Docker核心是，Docker了一种在安全隔离的容器中运行近乎所有应用的方式，这种隔离性和安全性允许你在同一个主机上同时运行多个容器，而容器的这种轻量级特性，无需消耗运行hpervisor所需的额外负载，意味着你可以节省更多的硬件资源。 基于容器虚拟化的工具或平台可提供： 将应用（包括支撑组件）放入Docker容器中 分发和交付这些容器给团队，便于后续的开发和测试 将容器部署到生产环境中，生产环境可以是本地的数据中心，也可以在云端。 自从上世纪 90 年代硬件虚拟化被主流的技术广泛普及之后，对数据中心而言，发生的最大的变革莫过于容器和容器管理工具，例如：Docker。在过去的一年内，Docker 技术已经逐渐走向成熟，并且推动了大型初创公司例如 Twitter 和 Airbnb 的发展，甚至在银行、连锁超市、甚至 NASA 的数据中心都赢得了一席之地。当我几年前第一次直到 Docker 的时候，我还对 Docker 的未来持怀疑的态度，我认为他们是把以前的 Linux 容器的概念拿出来包装了一番推向市场。但是使用 Docker 成功进行了几个项目 例如 Spantree 之后，我改变了我的看法：Docker 帮助我们节省了大量的时间和经历，并且已经成为我们技术团队中不可或缺的工具。GitHub 上面每天都会催生出各式各样的工具、形态各异的语言和千奇百怪的概念。如果你和我一样，没有时间去把他们全部都测试一遍，甚至没有时间去亲自测试 Docker，那么你可以看一下我的这篇文章：我将会用我们在 Docker 中总结的经验来告诉你什么是 Docker、为什么 Docker 会这么火。 Docker 是容器管理工具Docker 是一个轻量级、便携式、与外界隔离的容器，也是一个可以在容器中很方便地构建、传输、运行应用的引擎。和传统的虚拟化技术不同的是，Docker 引擎并不虚拟出一台虚拟机，而是直接使用宿主机的内核和硬件，直接在宿主机上运行容器内应用。也正是得益于此，Docker 容器内运行的应用和宿主机上运行的应用性能差距几乎可以忽略不计。但是 Docker 本身并不是一个容器系统，而是一个基于原有的容器化工具 LXC 用来创建虚拟环境的工具。类似 LXC 的工具已经在生产环境中使用多年，Docker 则基于此提供了更加友好的镜像管理工具和部署工具。 Docker 不是虚拟化引擎Docker 第一次发布的时候，很多人都拿 Docker 和虚拟机 VMware、KVM 和 VirtualBox 比较。尽管从功能上看，Docker 和虚拟化技术致力于解决的问题都差不多，但是 Docker 却是采取了另一种非常不同的方式。虚拟机是虚拟出一套硬件，虚拟机的系统进行的磁盘操作，其实都是在对虚拟出来的磁盘进行操作。当运行 CPU 密集型的任务时，是虚拟机把虚拟系统里的 CPU 指令“翻译”成宿主机的CPU指令并进行执行。两个磁盘层，两个处理器调度器，两个操作系统消耗的内存，所有虚拟出的这些都会带来相当多的性能损失，一台虚拟机所消耗的硬件资源和对应的硬件相当，一台主机上跑太多的虚拟机之后就会过载。而 Docker 就没有这种顾虑。Docker 运行应用采取的是“容器”的解决方案：使用 namespace 和 CGroup 进行资源限制，和宿主机共享内核，不虚拟磁盘，所有的容器磁盘操作其实都是对 /var/lib/docker/ 的操作。简言之，Docker 其实只是在宿主机中运行了一个受到限制的应用程序。从上面不难看出，容器和虚拟机的概念并不相同，容器也并不能取代虚拟机。在容器力所不能及的地方，虚拟机可以大显身手。例如：宿主机是 Linux，只能通过虚拟机运行 Windows，Docker 便无法做到。再例如，宿主机是 Windows，Windows 并不能直接运行 Docker，Windows上的 Docker 其实是运行在 VirtualBox 虚拟机里的。 Docker 使用层级的文件系统前面提到过，Docker 和现有容器技术 LXC 等相比，优势之一就是 Docker 提供了镜像管理。对于 Docker 而言，镜像是一个静态的、只读的容器文件系统的快照。然而不仅如此，Docker 中所有的磁盘操作都是对特定的Copy-On-Write文件系统进行的。下面通过一个例子解释一下这个问题。例如我们要建立一个容器运行 JAVA Web 应用，那么我们应该使用一个已经安装了 JAVA 的镜像。在 Dockerfile（一个用于生成镜像的指令文件）中，应该指明“基于 JAVA 镜像”，这样 Docker 就会去 Docker Hub Registry 上下载提前构建好的 JAVA 镜像。然后再 Dockerfile 中指明下载并解压 Apache Tomcat 软件到 /opt/tomcat 文件夹中。这条命令并不会对原有的 JAVA 镜像产生任何影响，而仅仅是在原有镜像上面添加了一个改动层。当一个容器启动时，容器内的所有改动层都会启动，容器会从第一层中运行 /usr/bin/java 命令，并且调用另外一层中的 /opt/tomcat/bin 命令。实际上，Dockerfile 中每一条指令都会产生一个新的改动层，即便只有一个文件被改动。如果用过 Git 就能更清楚地认识这一点，每条指令就像是每次 commit，都会留下记录。但是对于 Docker 来说，这种文件系统提供了更大的灵活性，也可以更方便地管理应用程序。我们Spantree的团队有一个自己维护的含有 Tomcat 的镜像。发布新版本也非常简单：使用 Dockerfile 将新版本拷贝进镜像从而创建一个新镜像，然后给新镜像贴上版本的标签。不同版本的镜像的不同之处仅仅是一个 90 MB 大小的 WAR 文件，他们所基于的主镜像都是相同的。如果使用虚拟机去维护这些不同的版本的话，还要消耗掉很多不同的磁盘去存储相同的系统，而使用 Docker 就只需要很小的磁盘空间。即便我们同时运行这个镜像的很多实例，我们也只需要一个基础的 JAVA / TOMCAT 镜像。 Docker 可以节约时间很多年前我在为一个连锁餐厅开发软件时，仅仅是为了描述如何搭建环境都需要写一个 12 页的 Word 文档。例如本地 Oracle 数据库，特定版本的 JAVA，以及其他七七八八的系统工具和共享库、软件包。整个搭建过程浪费掉了我们团队每个人几乎一天的时间，如果用金钱衡量的话，花掉了我们上万美金的时间成本。虽然客户已经对这种事情习以为常，甚至认为这是引入新成员、让成员适应环境、让自己的员工适应我们的软件所必须的成本，但是相比较起来，我们宁愿把更多的时间花在为客户构建可以增进业务的功能上面。如果当时有 Docker，那么构建环境就会像使用自动化搭建工具 Puppet / Chef / Salt / Ansible 一样简单，我们也可以把整个搭建时间周期从一天缩短为几分钟。但是和这些工具不同的地方在于，Docker 可以不仅仅可以搭建整个环境，还可以将整个环境保存成磁盘文件，然后复制到别的地方。需要从源码编译 Node.js 吗？Docker 做得到。Docker 不仅仅可以构建一个 Node.js 环境，还可以将整个环境做成镜像，然后保存到任何地方。当然，由于 Docker 是一个容器，所以不用担心容器内执行的东西会对宿主机产生任何的影响。现在新加入我们团队的人只需要运行 docker-compose up 命令，便可以喝杯咖啡，然后开始工作了。 Docker 可以节省开销当然，时间就是金钱。除了时间外，Docker 还可以节省在基础设施硬件上的开销。高德纳和麦肯锡的研究表明，数据中心的利用率在 6% - 12% 左右。不仅如此，如果采用虚拟机的话，你还需要被动地监控和设置每台虚拟机的 CPU 硬盘和内存的使用率，因为采用了静态分区(static partitioning)所以资源并不能完全被利用。。而容器可以解决这个问题：容器可以在实例之间进行内存和磁盘共享。你可以在同一台主机上运行多个服务、可以不用去限制容器所消耗的资源、可以去限制资源、可以在不需要的时候停止容器，也不用担心启动已经停止的程序时会带来过多的资源消耗。凌晨三点的时候只有很少的人会去访问你的网站，同时你需要比较多的资源执行夜间的批处理任务，那么可以很简单的便实现资源的交换。虚拟机所消耗的内存、硬盘、CPU 都是固定的，一般动态调整都需要重启虚拟机。而用 Docker 的话，你可以进行资源限制，得益于 CGroup，可以很方便动态调整资源限制，让然也可以不进行资源限制。Docker 容器内的应用对宿主机而言只是两个隔离的应用程序，并不是两个虚拟机，所以宿主机也可以自行去分配资源。 注： 部分翻译自：https://docs.docker.com/engine/understanding-docker/ 部分参考：http://zhidao.baidu.com/link?url=4FOwNhnpVC3FP0hOxaC4vrl3fFG27lWRpDEaZ3KJBVL0E29C5O-ty4zqze1On52Uk4kcNrnPd3VEKpKvRs4pNEV-lgo78lmP1_FXffMerdG 参考文档Docker介绍：http://www.lupaworld.com/article-243555-1.html Docker介绍：http://www.docker.org.cn/book/docker/what-is-docker-16.html Docker官方文档：https://docs.docker.com/engine/understanding-docker/ Docker中文文档：http://git.oschina.net/widuu/chinese_docker Docker介绍：https://segmentfault.com/a/1190000002609286]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于SpringBoot bean无法注入的问题]]></title>
      <url>%2F2017%2FSpringboot1%2F</url>
      <content type="text"><![CDATA[摘要:Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程 正文:今天初次使用springboot搭建了Demo，联合mybatis时候(因为连接数据库需要创建vo层)出现bean无法导入的问题。网上谷歌了下后来找到了一个很容易忽视的原因。这个是我的包结构，注意Application的位置，刚开始我并没有放在现在这个位置，而是和bean以及接口UserMapper是平行的包下。然后就报了Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}这个错 关于SpringBoot bean无法注入的问题将Application放在了最外层的包才解决问题。 原因是：SpringBoot项目的Bean装配默认规则是根据Application类所在的包位置从上往下扫描！所以一定要放在最外层！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker在Ubuntu下私服搭建]]></title>
      <url>%2F2017%2FDocker-registry%2F</url>
      <content type="text"><![CDATA[摘要:docker同maven一样，虽然有中央仓库，但是都不是国内的下载速度较慢影响开发进度（当然maven可以配置阿里云的镜像速度很快）。 正文:一、我们希望构建和存储包含不想被公开的信息或数据的镜像。这个时候我们有以下两种选择：1.利用docker hub上的私有仓库。（下载速度较慢不适合企业开发）2.在防火墙后面运行自己的Registry(如开发环境的内网)。二、从Docker容器安装一个Registry非常简单，运行docker提供的容器即可。 1sudo docker run -p 5000:5000 registry:2 说明：若之前没有安装registry容器则会自动下载并启动一个registry容器，创建本地的私有仓库服 务。三、接下来需要为镜像打上标签：例如hello-world 1sudo docker tag hello-world localhost:5000/hello-world 然后doker images则会看到：localhost:5000/hello-world这个镜像四、随后我们将此镜像push到registry 1sudo docker push localhost:5000/hello-world 五、最后可以通过访问http://ip:port/v2/hello-world/tags/list来查看返回的json串是否存在hello-world六、同样，客户端则是通过： 1sudo docker pull ip:5000/hello-world来获取镜像到本地 以上是一个大概的安装过程，网上都有，重要的是一些碰到的bug需要配置一些东西（版本不同配置也不同，本人是docker version：1.12.1 registry version:v2）bug1：Error response from daemon: Get https://IP:5000/v1/_ping: http: server gave HTTP response to HTTPS client解决方案：echo ‘{ “insecure-registries”:[“你的IP:5000”] }’ /etc/docker/daemon.jsoncat /etc/docker/daemon.json { “insecure-registries”:[“你的IP:5000”] }然后重启daemon 1sodo /etc/init.d/docker restart 来获取镜像到本地随后会一直更新….]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker的安装]]></title>
      <url>%2F2017%2FDocker-install%2F</url>
      <content type="text"><![CDATA[摘要:Docker的安装 正文:Docker的安装是比较简单的，笔者原本不想过多提及；但是看到有不少读者对Docker的安装提出了疑问，故此进行一个安装的总结。 对于Linux用户可以借助其发行版的Linux包管理工具安装，对于Windows和MAC用户相对麻烦一些，笔者下面以Windows7系统为例，讲述安装过程。笔者强烈建议大家使用Linux系统进入本章的学习，第一是比较符合目前Docker的市场趋势，第二Docker本身就是基于Linux的LXC技术。 CentOS 7.0下Docker的安装 查看内核版本(Docker需要64位版本，同时内核版本在3.10以上，如果版本低于3.10，需要升级内核)： 1uname -r 更新yum包： 1yum update 添加yum仓库： 12345678sudo tee /etc/yum.repos.d/docker.repo &lt;&lt;-&apos;EOF&apos;[dockerrepo]name=Docker Repositorybaseurl=https://yum.dockerproject.org/repo/main/centos/7/enabled=1gpgcheck=1gpgkey=https://yum.dockerproject.org/gpgEOF 安装Docker 1yum install docker-engine 启动Docker 1service docker start 使用Docker国内镜像（为Docker镜像下载提速，非必须） 1curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://fe8a7d6e.m.daocloud.io 参考： 官方文档：https://docs.docker.com/engine/installation/linux/centos/ CentOS 6.5下Docker的安装Docker容器最早受到RHEL完善的支持是从最近的CentOS 7.0开始的，官方说明是只能运行于64位架构平台，内核版本为2.6.32-431及以上（即 &gt;= CentOS 6.5，运行docker时实际提示3.10.0及以上）。需要注意的是CentOS 6.5与7.0的安装是有一点点不同的，CentOS 6.x上Docker的安装包叫docker-io，并且来源于Fedora epel库，这个仓库维护了大量的没有包含在发行版中的软件，所以先要安装EPEL，而CentOS 7.x的Docker直接包含在官方镜像源的Extras仓库（CentOS-Base.repo下的[extras]节enable=1启用）。 下面就CentOS 6.5讲解Docker的安装过程，以下是软件版本： Linux版本 Docker版本 CentOS 6.5 X64（只能X64） 1.7.1 升级内核查看内核版本： 1uname -r 结果：2.6.32-431.el6.x86_64，不满足上文的需求，故此需要升级内核。 升级步骤： 导入公钥数字证书 1rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org 安装ELRepo 1rpm -ivh http://www.elrepo.org/elrepo-release-6-5.el6.elrepo.noarch.rpm 安装kernel长期版本 1yum --enablerepo=elrepo-kernel install kernel-lt -y # lt表示long-term的意思，长期维护版本，也可以将kernel-lt改为kernel-ml，安装主线版本 编辑grub.conf文件，修改Grub引导顺序，确认刚安装好的内核在哪个位置，然后设置default值（从0开始），一般新安装的内核在第一个位置，所以设置default=0。 12345678vim /etc/grub.conf# 以下是/etc/grub.conf的内容default=0 # 修改该值即可timeout=5splashimage=(hd0,0)/grub/splash.xpm.gzhiddenmenutitle CentOS (3.10.103-1.el6.elrepo.x86_64) 重启并查看内核版本，将会发现内核已经更新。 安装Docker 禁用selinux，因为selinux和LXC有冲突，故而需要禁用 1234567vim /etc/selinux/config的内容# 以下是/etc/selinux/config的内容# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=disabled # 将SELINUX设为disabled，注意修改后最好重启下机器。 安装 Fedora EPEL 1yum -y install http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm 安装Docker 1yum install -y docker-io 以守护模式运行Docker 1docker -d 如果不报错，那就是启动成功了，如果报以下异常： 12docker: relocation error: docker: symbol dm_task_get_info_with_deferred_remove, version Base not defined in file libdevmapper.so.1.02 with link time referenceINFO[0000] Listening for HTTP on unix (/var/run/docker.sock) 执行以下内容： 1yum upgrade device-mapper-libs 将Docker开机启动 1chkconfig docker on 重启机器 其他平台的安装请参考：https://docs.docker.com/engine/installation/ 参考文档 Windows：https://docs.docker.com/engine/installation/windows/ MAC： https://docs.docker.com/engine/installation/mac/ CentOS：https://docs.docker.com/engine/installation/linux/centos/]]></content>
    </entry>

    
  
  
</search>
