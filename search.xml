<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Spring IOC Notes-Obj Creation Process]]></title>
      <url>%2F2018%2FSpring-Study%20IOC%2F</url>
      <content type="text"><![CDATA[摘要: Spring IOC 学习笔记-对象创建过程 正文:对象创建过程Resource (xml annotation class properties/yml) -&gt; BeanDefinition -&gt; BeanWrapper -&gt; Object Resource –&gt; BeanDefinitionFor Xml12345678910&lt;bean id="user" class="com.itliusir.spring.entity.User" &gt; &lt;property name="id" value="1" /&gt; &lt;property name="name" value="杰克" /&gt; &lt;property name="classes" ref="aClass" /&gt;&lt;/bean&gt;&lt;bean id="aClass" class="com.itliusir.spring.entity.Class"&gt; &lt;property name="id" value="1" /&gt; &lt;property name="className" value="终极一班" /&gt;&lt;/bean&gt; 12345678910@Testpublic void testBean() &#123; ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext ("classpath:bean.xml"); User user = applicationContext.getBean(User.class); log.info(user.getName()); log.info(user.getClasses().getClassName()); Assert.assertEquals("杰克", user.getName()); Assert.assertEquals("终极一班", user.getClasses().getClassName());&#125; 1234567891011121314151617181920212223242526272829303132333435361. org.springframework.context.support.ClassPathXmlApplicationContext#ClassPathXmlApplicationContext(java.lang.String)2. org.springframework.context.support.AbstractApplicationContext#refresh3. org.springframework.context.support.AbstractApplicationContext#obtainFreshBeanFactory4. org.springframework.context.support.AbstractRefreshableApplicationContext#refreshBeanFactory5. org.springframework.context.support.AbstractXmlApplicationContext#loadBeanDefinitions(org.springframework.beans.factory.support.DefaultListableBeanFactory)6. org.springframework.context.support.AbstractXmlApplicationContext#loadBeanDefinitions(org.springframework.beans.factory.xml.XmlBeanDefinitionReader)7. org.springframework.beans.factory.support.AbstractBeanDefinitionReader#loadBeanDefinitions(org.springframework.core.io.Resource...)8. org.springframework.beans.factory.xml.XmlBeanDefinitionReader#loadBeanDefinitions(org.springframework.core.io.Resource)9. org.springframework.beans.factory.xml.XmlBeanDefinitionReader#loadBeanDefinitions(org.springframework.core.io.support.EncodedResource)10. org.springframework.beans.factory.xml.XmlBeanDefinitionReader#doLoadBeanDefinitions11. org.springframework.beans.factory.xml.XmlBeanDefinitionReader#registerBeanDefinitions12. org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader#registerBeanDefinitions13. org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader#doRegisterBeanDefinitions14. org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader#parseBeanDefinitions15. org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader#parseDefaultElement16. org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader#processBeanDefinition17. org.springframework.beans.factory.support.BeanDefinitionReaderUtils#registerBeanDefinition18. org.springframework.beans.factory.support.DefaultListableBeanFactory#registerBeanDefinition For Annotation123456@Data@Componentpublic class SimpleBean &#123; private String id = "sss"; private String name = "simpleBeans";&#125; 123456789@Testpublic void testBean() &#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext("com.itliusir.spring.beans.annotation"); SimpleBean simpleBean = applicationContext.getBean(SimpleBean.class); log.info(simpleBean.getId()); log.info(simpleBean.getName()); Assert.assertEquals("sss", simpleBean.getId()); Assert.assertEquals("simpleBeans", simpleBean.getName());&#125; 1234567891011121. org.springframework.context.annotation.AnnotationConfigApplicationContext#AnnotationConfigApplicationContext(java.lang.String...)2. org.springframework.context.annotation.AnnotationConfigApplicationContext#scan3. org.springframework.context.annotation.ClassPathBeanDefinitionScanner#scan4. org.springframework.context.annotation.ClassPathBeanDefinitionScanner#doScan5. org.springframework.context.annotation.ClassPathBeanDefinitionScanner#registerBeanDefinition6. org.springframework.beans.factory.support.BeanDefinitionReaderUtils#registerBeanDefinition BeanDefinition –&gt; Object123456789101. org.springframework.beans.factory.BeanFactory#getBean(java.lang.String)2. org.springframework.beans.factory.support.AbstractBeanFactory#doGetBean3. org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#createBean(java.lang.String, org.springframework.beans.factory.support.RootBeanDefinition, java.lang.Object[])4. org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#createBean(java.lang.String, org.springframework.beans.factory.support.RootBeanDefinition, java.lang.Object[])5. org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#doCreateBean CreateBeanInstance12341. org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#createBeanInstance2. org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#instantiateBean PopulateBean121. org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#populateBean InitializeBean121. org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#initializeBean(java.lang.String, java.lang.Object, org.springframework.beans.factory.support.RootBeanDefinition)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用Spring Event解耦业务开发]]></title>
      <url>%2F2018%2FSpring%20Boot-Spring%20Event%2F</url>
      <content type="text"><![CDATA[摘要: 使用Spring Event解耦业务开发 正文:使用Spring Event解耦业务开发事件驱动事件驱动模型通常被理解为观察者模式或者发布-订阅模型 Spring 事件是观察者模式的一种体现，对象间的一对多关系，被观察者发出信号时候会通知监听该事件的观察者；而发布-订阅模型往往需要一个调度中心，如消息队列等 业务场景 用户注册 发短信/确认邮件 送新人优惠券 送抽奖 …. 伪代码主流程 123456789101112//注册userMapper.saveUser(user);//发确认邮件sendEmail(String email);//发短信sendMessage(String mobile);//送优惠券sendCoupon(String userId);//送抽奖机会sendLottery(String userId);//各种活动...send...(); 尽管我们方法抽象的很好，但是当这种事件(注册后续操作)越来越多时，主方法就会显得很乱，并且随着业务需求的变化，这个维护起来也很麻烦 改进版主流程 1234//注册userMapper.saveUser(user);//发送注册成功事件publisher.publishEvent(new UserRegisterEvent(user)); 注册事件 1234567891011class UserRegisterEvent extends ApplicationEvent &#123; private static final long serialVersionUID = -4829855648590354032L; public UserRegisterEvent(User user) &#123; super(user); &#125; public User getUser() &#123; return (User) source; &#125;&#125; 不同监听 123456789101112131415//发短信监听class MessageListener implements ApplicationListener&lt;UserRegisterEvent&gt; &#123; @Override public void onApplicationEvent(UserRegisterEvent event) &#123; sendMessage(event.getUser().getMobile()); &#125;&#125;//发优惠券监听class CouponListener implements ApplicationListener&lt;UserRegisterEvent&gt; &#123; @Override public void onApplicationEvent(UserRegisterEvent event) &#123; sendCoupon(event.getUser().getId()); &#125;&#125;//...监听 同步 OR 异步Spring 事件既可以同步又可以异步，对于重要的业务最好采用同步方式，对于不重要的或不希望其阻塞主线程从而导致响应变慢可以采用异步方式 同步(default)监听会加入到主线程的事务中，可以通过Order来调整bean装配的优先级来实现监听的执行顺序 异步需要配置线程池来实现，顺序无法保证 综上所述，Spring 事件主要还是对代码层面的解耦 Spring Event 实现细节 Source: 4.2 以 publisher.publishEvent() 为入口 org.springframework.context.support.AbstractApplicationContext#publishEvent(java.lang.Object, org.springframework.core.ResolvableType) 12345678910111213141516171819202122protected void publishEvent(Object event, ResolvableType eventType) &#123; //如果是ApplicationEvent类型对象 if (event instanceof ApplicationEvent类型对象) &#123; applicationEvent = (ApplicationEvent) event; &#125; else &#123; //否则就new一个PayloadApplicationEvent applicationEvent = new PayloadApplicationEvent&lt;Object&gt;(this, event); if (eventType == null) &#123; eventType = ((PayloadApplicationEvent)applicationEvent).getResolvableType(); &#125; &#125; // Multicast right now if possible - or lazily once the multicaster is initialized if (this.earlyApplicationEvents != null) &#123; this.earlyApplicationEvents.add(applicationEvent); &#125; else &#123; //实际执行是委托给ApplicationEventMulticaster getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType); &#125;&#125; 同步or 异步org.springframework.context.event.SimpleApplicationEventMulticaster#multicastEvent(org.springframework.context.ApplicationEvent, org.springframework.core.ResolvableType) 123456789101112131415161718@Override public void multicastEvent(final ApplicationEvent event, ResolvableType eventType) &#123; ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); for (final ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; Executor executor = getTaskExecutor(); if (executor != null) &#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; invokeListener(listener, event); &#125; &#125;); &#125; else &#123; invokeListener(listener, event); &#125; &#125; &#125; 初始化org.springframework.context.support.AbstractApplicationContext#refresh 123456@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; ... initApplicationEventMulticaster(); ...&#125; org.springframework.context.support.AbstractApplicationContext#initApplicationEventMulticaster 123456789protected void initApplicationEventMulticaster() &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123; //手动实现了名称为applicationEventMulticaster的bean &#125; else &#123; //否则就默认自定义一个名称为SimpleApplicationEventMulticaster的监听器容器 &#125;&#125; DemoSpring-Event-Demo]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JMM学习笔记]]></title>
      <url>%2F2018%2Fjavase-JMM%2F</url>
      <content type="text"><![CDATA[摘要:JMM学习笔记 正文:Java Memory Model未同步的程序的行为 如上面例子所示 有 A B 两个共享变量，r1 r2 两个局部变量 要出现 May observer r2 == 2，r1 == 1 线程执行顺序应该是如下所示： Thread 1：B=1Thread 2：r1=BThread 2：A=2Thread 1：r2=A 而按照程序员视角看第一个原始指令与实际的结果，可能会感觉很困惑，其根本原因是Java 的语义允许编译器和微处理器进行优化，这则会影响未正确同步的代码的行为 (如上代码是未同步的)。 非正式语义看一个程序是否被正确的同步有两个关键概念 冲突访问 对共享元素存在数据竞争场景，如上文中的未同步程序的行为 Happens-Before 关系 happens-before 关系可以对两个动作进行排序，如果一个动作 happens-before 另一个动作，则第一个对第二个可见，且第一个排在第二个之前。必须强调的是，两个动作之间存在 happens-before 关系并不意味着这些动作在Java中必须以这种顺序发生。happens-before 关系主要用于强调两个有冲突的动作之间的顺序，以及定义数据争用的发生时机 如果某个动作A happens-before 动作B，且B happens-before 动作C，则有A happens-before C 顺序一致性顺序一致性是程序执行过程中可见性和顺序的强有力保证，在顺序一致性内存模型中，每个操作都必须是原子执行且对所有线程可见 final 字段声明为 final 的字段在 对象完全初始化后的时刻 值是不可变的，所以 final 字段也允许编程人员在不需要同步的情况下实现线程安全的不可变对象 什么是内存模型内存模型可以看做为一组规则，规定了一个线程的写操作何时会对另一个线程可见 定义Shared variables/Heap memory 能够在线程间共享的内存称为共享内存或堆内存，所有的实例字段，静态字段以及数组元素都存储在堆内存中，方法中的局部变量永远不会在线程间共享且不会被内存模型影响 Inter-thread Actions 线程间的动作是某一个线程执行的动作能被另一个线程探测或影响，比如lock某个管城、读写volatile变量 我们无需关心 Intra-thread 动作(线程内部) ，每个单线程需要遵守正确的 Intra-thread semantics Intra-thread semantics 线程内语义是单线程程序的标准语义，线程内语义决定着某个线程孤立的执行过程，当从堆中读取值时，值是由内存模型决定的 Synchronization Actions 同步动作包括锁、解锁、读写 volatile 变量等动作 近似模型在上文的非正式语义中描述了顺序一致性，在顺序一致性内存模型中，每个操作都必须是原子执行且对所有线程可见。其约束较严格，禁止了编译器和处理器优化，不适合做 Java 内存模型 Java中，共享变量(实例、静态、数组元素)存在堆内存中，堆内存在线程之间共享。非共享变量(局部变量、方法定义参数、异常处理参数)不会在线程之间共享，它们不会有内存可见性的问题 在JMM(Java Memory Model，java 内存模型)中，其]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一个feign使用不当的问题]]></title>
      <url>%2F2018%2FSpringCloud-Feign-Hystrix%2F</url>
      <content type="text"><![CDATA[摘要: 一个feign使用不当的问题 正文:一个错误的示例接口与回退逻辑 12345678910111213@FeignClient(name = "service-A",fallback=AServiceFallback.class )public interface AService &#123; @RequestMapping(value = "/aApi/getA", method = RequestMethod.GET) List&lt;AInfo&gt; getA();&#125;@Slf4jpublic class AServiceFallback implements AService&#123; @Override public List&lt;AInfo&gt; getA() &#123; log.error("进入回退方法：异常"); &#125;&#125; 配置文件 123456789101112hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 50000ribbon: ReadTimeout: 60000 ConnectTimeout: 60000 eureka: enabled: true 以上配置在不熟悉feign-hystrix 或者查看 Feign Hystrix Fallbacks 的可能感觉并没有问题，项目启动也是正常 正确使用方式接口与回退逻辑 1234567891011121314@FeignClient(name = "service-A",fallback=AServiceFallback.class )public interface AService &#123; @RequestMapping(value = "/aApi/getA", method = RequestMethod.GET) List&lt;AInfo&gt; getA();&#125;@Slf4j@Componentpublic class AServiceFallback implements AService&#123; @Override public List&lt;AInfo&gt; getA() &#123; log.error("进入回退方法：异常"); &#125;&#125; 配置文件 12345678910111213141516hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 50000ribbon: ReadTimeout: 60000 ConnectTimeout: 60000 eureka: enabled: truefeign: hystrix: enabled: true 可以看到，在配置文件中新增了feign.hystrix.enabled = true 进行激活，如果代码不变启动项目会报： 1Caused by: java.lang.IllegalStateException: No fallback instance of type class com.yss.xx.feign.fallback.AServiceFallback found for feign client service-A 可以参考Feign Hystrix Support ，也可以在回退逻辑接口的类上面使用Spring 通用模式装配注解@Component 对AServiceFallback进行装配]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Boot 核心特性之组件自动装配]]></title>
      <url>%2F2018%2FSpring%20Boot-AutoConfiguration%2F</url>
      <content type="text"><![CDATA[摘要: Spring Boot 核心特性之组件自动装配 正文:Spring Boot 核心特性之组件自动装配Spring Framework 手动装配模式注解装配 ex：@Component、@Service、@Configuration… 装配方式：&lt;context:componet-scan&gt;或@ComponentScan @Component是一种由Spring 容器托管的通用模式组件 Spring Framework 注解 场景 version @Repository 数据仓储模式注解 2.0 @Component 通用组件模式注解 2.5 @Service 服务模式注解 2.5 @Controller Web 控制器模式注解 2.5 @Configuration 配置类模式注解 3.0 自定义模式注解 “派生性”(“基注解”&lt;”派生注解”)，可以参考以上注解实现自定义注解： @Component&lt;@Repository&lt;CustomRepository @Enable 模块装配Spring Framework从3.1开始支持@Enable 模块驱动 ，模块是指具备相同领域的功能组件集合组合成为一个独立的单元 举例： @Enable 注解模块 模块说明 @EnableWebMvc Web MVC模块 @EnableAsync 异步处理模块 @EnableAutoConfiguration 自动配置模块 @EnableEurekaClient Eureka Client模块 注解驱动方式 version：3.0 举例： org.springframework.web.servlet.config.annotation.EnableWebMvc 12345@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc &#123;&#125; org.springframework.web.servlet.config.annotation.DelegatingWebMvcConfiguration 12@Configurationpublic class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport &#123;&#125; 接口编程方式 version：3.1 举例： org.springframework.boot.autoconfigure.EnableAutoConfiguration 12345@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123;&#125; org.springframework.boot.autoconfigure.EnableAutoConfigurationImportSelector 123456789public class EnableAutoConfigurationImportSelector extends AutoConfigurationImportSelector &#123;&#125;public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware,BeanFactoryAware, EnvironmentAware, Ordered &#123; @Override public String[] selectImports(AnnotationMetadata annotationMetadata) &#123;&#125;&#125; 条件装配Spring Framework从3.1开始支持在Bean 装配时增加前置条件判断 @Profile 配置化方式条件装配 version：3.1 举例： class 123456789101112131415@Configuration@Profile("development")public class StandaloneDataConfig &#123; @Bean public DataSource dataSource() &#123;&#125;&#125;@Configuration@Profile("production")public class JndiDataConfig &#123; @Bean public DataSource dataSource() throws Exception &#123;&#125;&#125; method 1234567891011@Configurationpublic class SomeConfig &#123; @Bean("dataSource") @Profile("development") public DataSource standaloneDataSource() &#123;&#125; @Bean("dataSource") @Profile("production") public DataSource jndiDataSource() throws Exception &#123;&#125;&#125; 激活 1234AnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext();ctx.getEnvironment().setActiveProfiles("development");ctx.register(SomeConfig.class, StandaloneDataConfig.class, JndiDataConfig.class);ctx.refresh(); @Conditional 编程方式条件装配 version：4.0 举例： 12345@Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Conditional(OnClassCondition.class)public @interface ConditionalOnClass &#123;&#125; Spring-Boot的@Conditional： ConditionalOnBean ConditionalOnMissingBean ConditionalOnClass ConditionalOnMissingClass ConditionalOnProperty ConditionalOnJava ConditionalOnWebApplication Spring Boot 自动装配 激活：@EnableAutoConfiguration Spring Boot 默认没有激活自动装配，存在@SpringBootApplication注解中 参考:org.springframework.boot.autoconfigure.AutoConfigurationImport Selector#getCandidateConfigurations 配置：/META-INF/spring.factories 规约文件，META-INFO指的是元信息目录，如spring.handlers、spring.schemas等 参考:org.springframework.core.io.support.SpringFactoriesLoader 实现：XxxAutoConfiguration ex: org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration Demo-Spring-Boot-StarterDemo-Spring-Boot-Starter 源码分析ImportSelector部分org.springframework.boot.autoconfigure.AutoConfigurationImportSelector#selectImports 1234567891011121314151617181920212223242526272829303132@Override public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; try &#123; //加载spring-boot-autoconfigure-1.5.6.RELEASE.jar!\META-INF\spring-autoconfigure-metadata.properties AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); //获取EnableAutoConfiguration里的exclude和excludeName--&gt;LinkedHashMap--&gt;AnnotationAttributes AnnotationAttributes attributes = getAttributes(annotationMetadata); //获取依赖里所有的xx.jar!\META-INF\spring.factories的value List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); //利用Set去重 configurations = removeDuplicates(configurations); //排序-&gt;先按照字母排序-&gt;再按照Order排序(ex:MessageSourceAutoConfiguration#@AutoConfigureOrder)-&gt;然后根据@AutoConfigureBefore @AutoConfigureAfter(ex:WebSocketAutoConfiguration#@AutoConfigureBefore)排序 configurations = sort(configurations, autoConfigurationMetadata); //对attributes封装与去重得到exclusions Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); //去掉exclusions里的XxAutoConf... configurations.removeAll(exclusions); //加载过滤器，对不满足ex:默认有一个OnClassCondition(org.springframework.boot.autoconfigure.AutoConfigurationImportSelector#getAutoConfigurationImportFilters()，见下图)的会排除掉() configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions); return configurations.toArray(new String[configurations.size()]); &#125; catch (IOException ex) &#123; throw new IllegalStateException(ex); &#125; &#125; 调用ImportSelector部分123456789101112org.springframework.context.support.PostProcessorRegistrationDelegate#invokeBeanFactoryPostProcessorsorg.springframework.context.annotation.ConfigurationClassPostProcessor#postProcessBeanDefinitionRegistryorg.springframework.context.annotation.ConfigurationClassPostProcessor#processConfigBeanDefinitionsorg.springframework.context.annotation.ConfigurationClassParser#parse(java.util.Set&lt;org.springframework.beans.factory.config.BeanDefinitionHolder&gt;)org.springframework.context.annotation.ConfigurationClassParser#processDeferredImportSelectorsString[] imports = deferredImport.getImportSelector().selectImports(configClass.getMetadata());processImports(configClass, asSourceClass(configClass), asSourceClasses(imports), false);]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker Notes-storage]]></title>
      <url>%2F2018%2FDocker%20Notes-storage%2F</url>
      <content type="text"><![CDATA[摘要: Docker Notes系列为学习Docker笔记，本文是Docker存储介绍 正文:Docker 存储管理Docker 镜像元数据管理由上篇文章的镜像管理可知Docker以分层形式存储镜像，元数据与镜像文件的存储也是完全隔离开来 repository 元数据repository 由具有某个功能的Docker镜像的所有迭代版本构成的镜像库，其本地持久化文件存放于/var/lib/docker/image/{Storage Driver}/repositories.json中，结构如下： 1234567891011121314151617[root@cf /]# docker info | grep 'Storage Driver'Storage Driver: overlay2[root@cf /]# cat /var/lib/docker/image/overlay2/repositories.json&#123; "Repositories": &#123; "busybox": &#123; "busybox:latest": "sha256:8c811b4aec35f259572d0f79207bc0678df4c736eeec50bc9fec37ed936a472a", "busybox:test": "sha256:357bb11d2c366a4c60bcb20580407694f2f66f091452c8680dadf2761dc3cba0", "busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47": "sha256:8c811b4aec35f259572d0f79207bc0678df4c736eeec50bc9fec37ed936a472a" &#125;, "centos": &#123; "centos:7": "sha256:49f7960eb7e4cb46f1a02c1f8174c6fac07ebf1eb6d8deffbcb5c695f1c9edd5", "centos@sha256:b67d21dfe609ddacf404589e04631d90a342921e81c40aeaf3391f6717fa5322": "sha256:49f7960eb7e4cb46f1a02c1f8174c6fac07ebf1eb6d8deffbcb5c695f1c9edd5" &#125; ... &#125;&#125; Docker 默认采用SHA256算法根据镜像元数据配置文件计算出镜像ID image 元数据image 元数据包括了如下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778[root@cf /]# cat /var/lib/docker/image/overlay2/imagedb/content/sha256/8c811b4aec35f25...&#123; "architecture": "amd64", "config": &#123; "Hostname": "", "Domainname": "", "User": "", "AttachStdin": false, "AttachStdout": false, "AttachStderr": false, "Tty": false, "OpenStdin": false, "StdinOnce": false, "Env": [ "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" ], "Cmd": [ "sh" ], "ArgsEscaped": true, "Image": "sha256:3e8a1c5213eb57c6ea8ddb27d86a241698741ce60d9053b641f57a7e455f6842", "Volumes": null, "WorkingDir": "", "Entrypoint": null, "OnBuild": null, "Labels": null &#125;, "container": "617bfbb850a66642161d4925e0c00f77caa46e22057409788207e7b2edb86c3e", "container_config": &#123; "Hostname": "617bfbb850a6", "Domainname": "", "User": "", "AttachStdin": false, "AttachStdout": false, "AttachStderr": false, "Tty": false, "OpenStdin": false, "StdinOnce": false, "Env": [ "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" ], "Cmd": [ "/bin/sh", "-c", "#(nop) ", "CMD [\"sh\"]" ], "ArgsEscaped": true, "Image": "sha256:3e8a1c5213eb57c6ea8ddb27d86a241698741ce60d9053b641f57a7e455f6842", "Volumes": null, "WorkingDir": "", "Entrypoint": null, "OnBuild": null, "Labels": &#123; &#125; &#125;, "created": "2018-05-23T21:19:31.132152818Z", "docker_version": "17.06.2-ce", "history": [ &#123; "created": "2018-05-23T21:19:30.902651601Z", "created_by": "/bin/sh -c #(nop) ADD file:5f0439d8328ab58c087cd067c91ce92765da98916d91b083df6590477b7b9f19 in / " &#125;, &#123; "created": "2018-05-23T21:19:31.132152818Z", "created_by": "/bin/sh -c #(nop) CMD [\"sh\"]", "empty_layer": true &#125; ], "os": "linux", "rootfs": &#123; "type": "layers", "diff_ids": [ "sha256:432b65032b9466b4dadcc5c7b11701e71d21c18400aae946b101ad16be62333a" ] &#125;&#125; layer元数据由上文可知layer负责与镜像层和容器层元数据有关的增删改查，并将其增删改查操作映射到实际存储镜像层文件系统的graphdriver模块。 用户在Docker宿主机上下载了某个镜像层之后，Docker会在宿主机上基于镜像层文件包和image元数据，构建本地的layer元数据，如diff、size等， 12[root@cf /]# cat /var/lib/docker/image/overlay2/layerdb/sha256/432b65032b9466b4d.../cache-id diff size tar-split.json.gz Docker 存储驱动为了支持镜像的分层(只读层、读写层)与写时复制等特性，Docker提供了存储驱动的接口。存储驱动根据操作系统底层的支持提供了针对某种文件系统的初始化操作以及对镜像层的增删改查和差异比较等操作 常用存储驱动 aufs aufs是一种支持联合挂载的文件系统，相当于讲不同目录挂载到同一目录下，这些目录的挂载是分层次的，每一层都是一个普通的文件系统 1[root@cf /]# cd /var/lib/docker/aufs device mapper device mapper是Linux 2.6内核中提供的一种从逻辑设备到物理设备的映射框架机制，用户可以很方便地根据自己的需要制定实现存储资源的管理策略 device mapper 本质功能就是根据映射关系描述IO处理规则，当映射设备接收到IO请求的时候，这个IO请求会根据映射表逐级转发，直到这个请求最终传到最底层的物理设备上 如上图所示，映射设备是内核向外提供的逻辑设备，而目标设备即可以是物理设备也可以同样是映射设备 1[root@cf /]# cd /var/lib/docker/devicemapper overlay overlayFS是一种新型联合文件系统，它允许用户将一个文件系统与另一个文件系统重叠(overlay)，在上层的文件系统中记录更改，而下层的文件系统保持不变 1234567[root@cf overlay2]# tree -L 2.├── 05f14d2b45bfa0ff20f...│ ├── diff│ ├── link│ ├── lower│ └── work]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker Notes-architecture]]></title>
      <url>%2F2018%2FDocker%20Notes-architecture%2F</url>
      <content type="text"><![CDATA[摘要: Docker Notes系列为学习Docker笔记，本文是Docker架构介绍 正文:Docker 架构Docker 使用了传统的CS架构模式，用户通过Docker client与Docker daemon建立通信，并将请求发送给后者 Docker clientDocker Client是Docker架构中用户用来与Docker Daemon建立通信的客户端，可以是命令行工具docker，也可以是任何遵循Docker API的客户端 Docker daemonDocker daemon 是Docker 架构中的主要接口，它提供了API Server用于接收Docker client的请求，然后根据不同请求分发给Docker daemon的不同模块执行相应的工作。 为了将这些系统调用抽象成为统一的操作接口方便调用者使用，Docker把这些操作分为了容器执行驱动、volume存储驱动、镜像存储驱动三种，对应下面3个模块： exec driver 对linux操作系统的namespaces、cgroups等容器运行所需的系统操作进行的二次封装，本质作用类似LXC(linux container)，但是功能要更全面，主要由Docker官方编写的libcontainer库实现 volume driver 负责volume数据卷的增删改查，统一不同底层驱动的接口，Docker中的默认实现是local，将文件存储在某个目录下，其他volume driver均是通过外部插件实现的 graph driver 用户对镜像的操作(见下文的 image management 中的 layer 模块)会被映射成对graph维护的目录文件操作，它也是所有与容器镜像相关操作的最终执行者 network 网络由libnetwork库独立维护，libnetwork抽象出了一个容器网络模型，并给调用者提供了一个统一的抽象接口 Docker image management由上图可知，镜像管理是通过多个模块来实现： distribution 负责与Docker registry交互，上传下载镜像以及存储相关的元数据等 registry 负责与Docker registry有关的身份认证、镜像查找、镜像验证、管理registry mirror等 image 负责与镜像元数据有关的存储、查找、镜像层的索引、tar导入导出等 reference 负责存储本地所有镜像的repository和tag名，并维护与ID之间的映射关系 layer 负责与镜像层和容器层元数据有关的增删改查，并将其增删改查操作映射到实际存储镜像层文件系统的graphdriver模块]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker Notes-introduction]]></title>
      <url>%2F2018%2FDocker%20Notes-introduction%2F</url>
      <content type="text"><![CDATA[摘要: Docker Notes系列为学习Docker笔记，本文是Docker总体介绍 正文:Docker 介绍Centents 容器介绍 Docker是什么 Docker 架构 Docker 镜像 Dockerfile Docker Hub 容器介绍没有规范指定容器应该是什么 LXC(Linux Container)是一种操作系统级虚拟化方法，用于使用单个Linux内核在主机上运行多个隔离的Linux系统（容器） Linux内核提供cgroups功能，允许限制和优先化资源（CPU，内存，块I / O，网络等），而无需启动任何虚拟机，以及允许完全隔离应用程序视图的命名空间隔离功能 操作环境，包括进程树，网络，用户ID和已安装的文件系统 namespacesDocker Engine在Linux上使用的一些命名空间是： namespace 系统调用参数 隔离内容 UTS CLONE_NEWUTC 主机名与域名 IPC CLONE_NEWIPC 信号量、消息队列、共享内存 PID CLONE_NEWPID 进程编号 Network CLONE_NEWNET 网络栈、端口 Mount CLONE_NEWNS 文件系统 cgroupscgroups可以限制、记录、隔离进程组所使用的物理资源（包括：CPU、memory、IO等），为容器实现虚拟化提供了基本保证，是构建Docker等一系列虚拟化管理工具的基石 cgroups现在全称是control groups，它为每种可以控制的资源定义了一个子系统 blkio 可以限制块设备的输入输出，如磁盘、USB cpu 可以限制进程的cpu 使用率 cpuacct 可以生成cpu 使用报告 cpuset 可以为cgroups中进程分配独立的CPU和内存 devices 可以控制进程对设备的访问 freezer 可以对进程进行挂起或恢复 memory 可以对进程的memory使用量进行限制，并生成内存资源使用情况报告 perf_event 可以对进程进行统一的性能测试 net_cls 可以使用classid标记网络包，然后Linux流量控制程序识别从具体cgroups中生成的数据包 Docker 是什么 Docker 是一个linux 容器引擎，其开源项目第一个版本是由dotcloud公司在2013年3月发布，使用golang，一开始是基于LXC来创建的，现在使用libcontainer。从使用上来讲就像一个虚拟机 Why Go? 静态编译 “go build”将嵌入你需要的一切(不需要安装别的东西以运行) 除了动态库，如果使用cgo(cgo 允许你使用任何c库) 除了libc(但谁没有libc？)，你可以有一个真正的静态二进制文件 更易于安装，更易于测试，更易于使用 符合我们的需求 优良的异步原语 大量的标准库和数据类型 完善的开发者环境 Docker 架构 Docker ClientDocker Client是Docker架构中用户用来与Docker Daemon建立通信的客户端 通信方式 tcp://host:port unix://path_to_socket fd://socketfd 请求参数 Docker程序运行时所需提供的参数，如-d Docker发送给Docker Server的实际请求参数，如 ps、pull xxx等 Docker DaemonDocker daemon 是Docker 架构中的主要接口，它提供了API Server用于接收Docker client的请求，然后根据不同请求分发给Docker daemon的不同模块执行相应的工作 Docker 镜像Docker 镜像是一个只读的Docker 容器模块，含有启动Docker容器所需的文件系统结构及其内容，是启动一个Docker 容器的基础，Docker 镜像是Docker容器的静态视角，Docker容器是Docker镜像的运行状态 Dockerfiledocker 可以根据Dockerfile来自动构建镜像，Dockerfile是一个文本文档，其中包含用户可以在命令行上调用的所有需要进行自动化构建的命令，如下是一个简单的springboot应用镜像的Dockerfile文件内容 example 12345FROM xxx.cn/jdk8:alpineVOLUME /tmpADD ./target/demo.war /app/CMD ["sh", "-c", "java $&#123;JAVA_OPTS&#125; -Djava.security.egd=file:/dev/./urandom -jar /app/demo.war $&#123;RUN_ARGS&#125;"]EXPOSE 8888 Docker Hubdocker hub是类似github(gayhub)的一个官方镜像仓库，可以根据需求pull自己需要的镜像，也可以push自己构建的镜像，在社会主义特色开发下企业往往使用自己搭建的私有镜像仓库，如harbor等 参考链接Docker源码分析 Introduction to Docker]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker Notes-cgroups]]></title>
      <url>%2F2018%2FDocker%20Notes-cgroups%2F</url>
      <content type="text"><![CDATA[摘要: Docker Notes系列为学习Docker笔记，本文是学习cgroups 资源限制的笔记 正文:上节我们了解了Docker背后的资源隔离技术namespace，本节介绍另一个内核工具cgroups。 cgroups作用cgroups可以限制、记录、隔离进程组所使用的物理资源（包括：CPU、memory、IO等），为容器实现虚拟化提供了基本保证，是构建Docker等一系列虚拟化管理工具的基石 cgroups提供： 资源限制 对进程组的资源使用限制，如对应用运行时使用内存的限制 优先级 通过分配CPU的时间片数量和磁盘IO带宽大小 资源统计 统计系统的资源使用量 控制 对进程组挂起、恢复、重启动等操作 cgroups子系统cgroups现在全称是control groups，它为每种可以控制的资源定义了一个子系统 blkio 可以限制块设备的输入输出，如磁盘、USB cpu 可以限制进程的cpu 使用率 cpuacct 可以生成cpu 使用报告 cpuset 可以为cgroups中进程分配独立的CPU和内存 devices 可以控制进程对设备的访问 freezer 可以对进程进行挂起或恢复 memory 可以对进程的memory使用量进行限制，并生成内存资源使用情况报告 perf_event 可以对进程进行统一的性能测试 net_cls 可以使用classid标记网络包，然后Linux流量控制程序识别从具体cgroups中生成的数据包 docker组的层级结构docker daemon会在每个子系统的控制组目录下创建一个叫docker的控制组，在这个组里为每一个容器创建一个容器id命名的容器控制组 如cpu子系统层级结构 12345678910111213141516171819202122232425262728293031[root@cf /]# tree /sys/fs/cgroup/cpu/docker/sys/fs/cgroup/cpu/docker├── 69aa00d7aa3b6654b63280e66b671f509a3019a032ec5a09e299b793b37c6775│ ├── cgroup.clone_children│ ├── cgroup.event_control│ ├── cgroup.procs│ ├── cpuacct.stat│ ├── cpuacct.usage│ ├── cpuacct.usage_percpu│ ├── cpu.cfs_period_us│ ├── cpu.cfs_quota_us│ ├── cpu.rt_period_us│ ├── cpu.rt_runtime_us│ ├── cpu.shares│ ├── cpu.stat│ ├── notify_on_release│ └── tasks├── cgroup.clone_children├── cgroup.event_control├── cgroup.procs├── cpuacct.stat├── cpuacct.usage├── cpuacct.usage_percpu├── cpu.cfs_period_us├── cpu.cfs_quota_us├── cpu.rt_period_us├── cpu.rt_runtime_us├── cpu.shares├── cpu.stat├── notify_on_release└── tasks 一些文件的作用 tasks 12345[root@cf 69aa00d7aa3b6654b63280e66b671f509a3019a032ec5a09e299b793b37c6775]# cat tasks 29001290582905929060 该文件罗列了所有在该groups中的进程id cgroup.procs 12[root@cf 69aa00d7aa3b6654b63280e66b671f509a3019a032ec5a09e299b793b37c6775]# cat cgroup.procs 29001 该文件罗列了所有在该groups中的进程组id(第一个进程的pid) notify_on_release 该文件默认0，表示cgroups是否在最后一个进程退出时通知运行release agent，0表示不运行 cpuacct.stat 123[root@cf 69aa00d7aa3b6654b63280e66b671f509a3019a032ec5a09e299b793b37c6775]# cat cpuacct.statuser 2435system 4548 该文件统计了该控制组中进程用户态和内核态的 cpu 使用量 cpuacct.usage&amp;cpuacct.usage_percpu 该文件统计了该控制组中进程消耗的cpu时间，单位是纳秒]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker Notes-namespace]]></title>
      <url>%2F2018%2FDocker%20Notes-namespace%2F</url>
      <content type="text"><![CDATA[摘要: Docker Notes系列为学习Docker笔记，本文是学习namespace 资源隔离的笔记 正文:对于开发者而言，Docker的大热让人们思考容器隔离的实现，如对主机名与域名的隔离、资源隔离、网络的隔离、进程间通信的隔离、用户权限的隔离、PID的隔离等。Linux内核中提供了以下6种namespace隔离的系统调用 namespace 系统调用参数 隔离内容 UTS CLONE_NEWUTC 主机名与域名 IPC CLONE_NEWIPC 信号量、消息队列、共享内存 PID CLONE_NEWPID 进程编号 Network CLONE_NEWNET 网络栈、端口 Mount CLONE_NEWNS 文件系统 User CLONE_NEWUSER 用户与用户组 namespace api 创建一个namespace一般使用clone()来创建，其API还包括setns()、unshare()、/proc目录下的一些文件 然后通过不同的参数来确定使用哪种隔离方式 clone() clone()是fork()的一种变种，fork()是一种创建自身进程副本的操作，clone()可以通过flags参数来控制使用多少功能 fork()在父进程中返回新创建子进程的进程ID，在子进程中返回0，出现错误返回负值 setns() 在使用Docker exec在运行的容器中执行一个新的命令就需要该方法，进程从原来的namespace加入到另一个namespace，通常会在setns()执行后使用clone()创建子进程继续执行命令，让原进程结束运行 加入namespace后可以通过引入execve()函数执行用户命令(调用/bin/bash 接收参数，运行起一个shell) unshare() unshare()与clone()很像，不同的是unshare()不需要启动一个新进程 UTS 通过在clone()方法的flags中选择CLONE_NEWUTS参数来实现隔离不同namespace下的主机名与域名 IPC 同上面一样，通过CLONE_NEWIPC参数来实现不同namespace下的进程间通信隔离(信号量、消息队列、共享内存)，下列的不同namespace不再重复介绍传参方式 PID PID namespace隔离非常实用会对进程PID重新编号，所以不同namespace下PID可以相同 1234567[root@cf proc]# docker exec -ti 69aa00d7aa3b /bin/bashroot@69aa00d7aa3b:/data# echo $$18root@69aa00d7aa3b:/data# exitexit[root@cf proc]# echo $$28512 Unix系统中，PID为1的进程是init，它是所有进程的父进程，负责维护进程表，因此若在Docker容器中运行多个进程，最先启动的进程应该是具有资源管理能力的，init进程还可以对信号进行捕捉，如Docker中接收容器结束信号后结束容器进程回收资源 在PID namespace下unshare()与setns()方法会有一些变化，其方法的调用者进程并不进入新的PID namespace，接下来的创建子进程才会在新的namespace。例如在docker中，docker exec会使用setns()加入一个已存在的namespace，但是最终还是会调用clone()函数 MOUNT MOUNT namespace是第一个Linux namespace，所以标识符并不是CLONE_NEWMOUNT而是CLONE_NEWNS。创建MOUNT namespace时，会把当前的文件结构复制给新的namespace，新的namespace中的mount操作只会影响自身的文件系统，然后通过挂载传播来决定挂载事件的传播到别的挂载对象 Network Network namespace主要是对网络资源的隔离，不同的Network namespace间可以通过创建veth pair(虚拟网络设备对，一端在新的namespace下，一端在原先的namespace中连接物理网络设备)来实现通信 在建立veth pair之前新旧namespace使用pipe(管道)来通信 User User namespace主要是对用户ID、root目录、特殊权限等的隔离]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Rest Notes-架构上的教训(论文部分完结)]]></title>
      <url>%2F2018%2FRest%20Notes-Experience%20and%20Evaluation3%2F</url>
      <content type="text"><![CDATA[摘要: 从现代Web架构和由REST识别出的问题中，可以总结出很多通用的架构上的教训 正文:架构上的教训基于网络的API的优势将现代Web与其他中间件相区分的是它使用HTTP作为一个基于网络的API，其实并非一向如此，早期的Web设计利用了一个程序库(CERN的libwww)作为所有的客户端和服务器端软件所使用的的单个协议实现库。CERN libwww提供了一个基于库的API来建造可互操作的Web组件 HTTP不是RPC人们常常错误地将HTTP称为一种远程调用(RPC)机制，仅仅是因为它也包括了请求和响应。 RPC是调用远程机器上的一个过程，在RPC协议中，调用方识别出过程并且传递一组固定的参数，然后等待在使用相同接口返回的一个消息中提供的回答。Java的RMI(远程方法调用)就很类似，差异仅仅是将过程标识为一个对象、方法的组合，而不是一个简单的服务过程。 当然，将HTTP与RPC区分开的并不是上面的语法和特性，其重要的区别是：HTTP是请求被定向到使用一个有标准语义的通用接口的资源，中间组件几乎完全相同的方式来解释这些语义，结果就是使得一个应用能够支持转换的分层和独立于信息来源的间接层，这对于一个满足互联网规模、多个组织、无法控制的可伸缩性需求的信息系统来说是非常有用的；RPC的机制是根据语言的API来定义的，而不是根据基于网络应用的需求来定义的 HTTP不是一种传输协议HTTP并非被设计为一种传输协议，它是一种移交协议 Web各组件都能理解HTTP语义，从而可以独自的完成HTTP的响应，而不必一定到达最终的源服务器，这也是为什么它是移交不是传输协议的原因 媒体类型的设计REST有一个对架构风格来说不同寻常的方面，那就是它对于Web架构中数据元素的定义影响程度 应用状态 应用的开发者经常违背的就是应用状态和无状态交互架构约束。将应用状态放错地方而造成架构不匹配并不仅限于上篇文章提到的Cookie，还有HTML中引入的frame，在一个子窗口中选择链接而导致的状态迁移与正常的状态迁移是无法区分的 作者认为frame和cookie的失败之处在于，用户代理无法管理或解释它们所提供的间接应用状态。替代的设计是将这些信息放到一个主要的表述中，并且告知用户代理如何去管理这个存放了指定的资源领域的工作区 Java VS JavaScript 通过使用REST，我们能够知道为何一些媒体类型与其他类型相比在Web架构中得到了更加广泛的接受，甚至这些类型并未取得开发者偏爱的情况下(例如Java Applet对抗JavaScript) 作者认为JavaScript在Web上比Java更成功体现在可见的交互性影响较少、复杂性比较小、用户感知的延迟 总结REST论文的阅读到此结束了，可以看出来REST主要是提供了一套指导原则，可以根据这些原则来识别架构中的缺陷，现代Web是REST架构风格的一个架构实例。在一个理想的世界里，软件系统的实现与它的设计有着精确的匹配，现代Web架构的一些功能确实完全符合它们在REST中的设计标准，例如通过URI标识资源，使用MediaTypes标识数据格式等 REST既贡献了现代Web软件架构背后的基础理论，也为我们上了重要的一课，展示了软件工程原则如何能够被系统地应用在一个真实的软件系统的设计与评估之中 接下来会去阅读网络协议与RestFul API最佳的设计等]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Rest Notes-将REST应用于HTTP]]></title>
      <url>%2F2018%2FRest%20Notes-Experience%20and%20Evaluation2%2F</url>
      <content type="text"><![CDATA[摘要: 超文本移交协议(HTTP)在Web架构中既作为在Web组件之间通信的主要的应用级协议，也作为特别为移交资源的表述而设计的唯一的协议(现在并不是唯一，还有COAP协议)。 正文:将REST应用于HTTP超文本移交协议(HTTP)在Web架构中既作为在Web组件之间通信的主要的应用级协议，也作为特别为移交资源的表述而设计的唯一的协议(现在并不是唯一，还有COAP协议)。 REST用来识别早期HTTP协议中的问题，并指定了一个可以和HTTP1.0互操作的协议子集，然后分析HTTP1.1的扩展提议，并最终诞生了HTTP1.1 可扩展性REST的主要目标之一是在一个已部署的架构中支持逐渐的和片段的修改 协议版本控制 通过主版本和次版本号来区分（1.0 1.1 2.0），其版本信息代表的是消息发送者对协议的支持能力 可扩展的协议元素 通过将解析和转发HTTP消息的规则与新的HTTP协议元素的相关语义分离开，解决了中间组件更新部署问题 扩大了响应码区间，100-599 升级 HTTP1.1新增了Upgrade头，用来再通信双方进行协商协议版本 自描述的信息REST要求组件之间消息是自描述的，以便支持中间组件对于交互的处理。然而早期HTTP协议的一些方面并不是自描述的(请求中缺乏主机标识、无法根据语法来区分消息控制数据和表述元数据等) Host(主机) 早期的HTTP请求中不会携带host头部信息，这导致了无法区分我访问的到底是服务器上的哪个站点 例如我们使用Github pages搭建静态博客时候，都将域名解析到Github的某个IP(192.30.252.154)，大家通过不同域名访问的却是不同页面。这个就是通过不同的Host来区分的 分层编码 HTTP为了描述表述的元数据，继承了多用途互联网邮件扩展(MIME)的语法,MIME没有定义分层的媒体类型 语义独立性 如上面可扩展的协议元素所述，HTTP消息的解析与其语义是相分离的 传输独立性 早期的HTTP协议包括大多数的HTTP/1.0的实现，使用底层的传输协议来表示响应消息的结束。服务器通过关闭TCP连接来表明响应消息的结束，但不幸的是则会导致：客户端没有办法区分一个完成的响应和因为某种故障异常而断开的响应。为了解决这个问题在HTTP/1.0中重新定义了Content-Length头信息字段，以表示消息体的字节长度，并且在HTTP/1.1中引入了“chunked”(分块)这个移交编码 chunked编码允许表述在其生成阶段的开始时尺寸是未知的，通过一系列分块来描述它的界限，每个分块的尺寸可在被发送之前单独设置 尺寸限制 对于应用层协议的灵活性而言，常见的障碍是在协议的参数上过度指定尺寸限制的倾向 在HTTP协议中并没有限制URI的长度、头信息字段的长度、表述的长度、任何由一列条目组成的字段值的长度 缓存控制 REST努力在高效率的、低效率的行为和其所期待的语义透明的缓存行为之间取得平衡，因此它允许由应用确定缓存需求，而不是将该需求硬编码在协议本身之中，这对于HTTP协议来说是至关重要的 HTTP/1.1通过添加Cache-Control、Age、Etag、Vary几个头信息字段来达到这个目标 性能 持久连接 早期的HTTP协议每个连接只能发送单个请求/响应，尽管实现起来简单，但是它对于底层TCP传输机制的使用非常低效。原因在于每次交互都要付出重新建立连接的开销 对于HTTP/1.0，通过使用在Connection头信息字段中的“keep-alive”指令来达到这个目标，但是如果转发给不理解该指令的中间组件会造成连接关闭，HTTP1.1最终把默认的持久连接作为了默认的选项，如果要关闭连接，则需要发送close的指令 直写式缓存 HTTP协议不支持回写式缓存，HTTP缓存不能假设通过它写入的消息与来自相同资源的后续请求可能获取的内容是相同的，因此它不能缓存一个PUT请求的消息体，并且将其内容重用于稍后的GET请求的响应 缺乏回写式缓存并不会对性能产生严重影响 这里的PUT请求是写入动作，幂等的，相当于对资源赋值操作 REST在HTTP中的不匹配在HTTP协议中存在一些架构不匹配，一些是由于标准过程之外部署的第三方扩展所导致的，其他的则是由于与已部署的HTTP/1.0组件保持兼容的必要性所导致的 区分非权威的响应 没有一致的机制来区分一个响应是来自于源服务器还是中间的某一个组件(走的缓存没有走来源服务器)，虽然HTTP1.1中定义了Warning消息头，但是在实践中并未广泛使用。 Cookie Cookie是不透明的数据，来源服务器通过将它包括在一个Set-Cookie响应头信息字段中，将它设置给一个用户代理，用户代理在所有将来的请求中包括这个相同的Cookie，直到被替换或者过期 Cookie违反了REST，因为它们允许数据在没有充分表明其语义的情况下对其进行传递，这会成为一个安全和隐私方面的关注点(结合使用Cookie和Referer头信息字段，有可能当用户多个站点浏览时对其进行跟踪) 响应与请求相匹配 当需要描述哪一个响应属于哪一个请求的时候，HTTP消息并不是自描述的 早期的HTTP协议并没有考虑到需要将响应与相关的请求绑定在一起的消息控制数据，因此请求的顺序决定了响应的顺序，这意味着HTTP依赖于传输层的连接来确定这一匹配]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Rest Notes-将REST应用于URI]]></title>
      <url>%2F2018%2FRest%20Notes-Experience%20and%20Evaluation1%2F</url>
      <content type="text"><![CDATA[摘要: 自1994年以来，REST架构风格就被用来指导现代Web架构的设计和开发，本篇描述了在创作超文本移交协议(HTTP)和统一资源标识符(URI)两个互联网规范的过程中，以及将这些技术部署在libwww-perl客户端库、Apache HTTP服务器项目、协议标准的其他实现的过程中，应用REST所学到的经验和教训 正文:将REST应用于URIWeb标准化开发REST的动机是为Web的运转方式创建一种架构模式，使之成为Web协议标准的指导框架。REST被用来描述期待的Web架构，帮助识别出现有的问题，对各种替代方案进行比较，并且保证协议的扩展不会违反使Web成功的那些核心架构约束。 行业内的压力不断增长，要求对Web接口协议的某个版本或某些版本进行标准化。Berners-Lee(Web之父)创建了W3C，将其作为Web架构的智库，并为Web编写规范以及实现相关所需的资源，但是标准化本身是由IETF及其URI、HTTP和HTML工作组来掌管的。由于作者在开发Web软件方面的经验被IETF选出来创作相对URL的规范，后来又与Henrik FrystykNielsen共同创作了HTTP/1.0规范，后来Fielding博士成了HTTP/1.1的主要架构师，并且最终创作了URI通用语法标准的URL规范的修订版 REST的第一版开发于1994年10月和1995年8月之间，起初是作者Fielding博士作为编写HTTP1.0的一种概念方法。在随后的5年中以迭代的方式不断改进，并且用于各种Web协议标准的修行版和扩展之中。REST最初被称作“HTTP对象模型”，很容易被误解为它使一个HTTP服务器的实现模型，而REST(表述性状态移交)是有意唤起人们对于一个设计良好的Web应用如何运转的印象：Web应用是一个由网页组成的网络（一个虚拟状态机），用户通过选择链接（状态迁移）在应用中前进，引导系统把下一个页面（代表应用的下一个状态）的数据移交给用户，并且呈现出来，以便用户使用。其中承载包含应用状态的部分是有超媒体来负责的，这也是为什么REST强调HATEOAS（Hypermedia As The Engine Of Application Statue）的原因所在 将REST应用于URIREST既被用来为URI规范定义“资源”这个术语，也被用来定义通过它们的表述来操作资源的通用接口的全部语义 重新定义资源早期Web架构将URI定义为文档的标识符，创作者往往是根据网络上一个文档的位置来定义标识符，然后就能够使用Web协议来获取那个文档 然而，这个定义并不是令人满意，首先，它暗示创作者正在标识所移交的内容，这意味着任何时候当内容改变了这个标识符都应该改变(后移)。其次，存在很多地址对应的一个服务，而不是一个文档；最后，可能有一段时间没有这个文档 REST对于“资源”的定义有一个前提：标识符应该尽可能的少改变，因为Web使用内嵌的标识符而不是链接服务器。创作者需要的是一个能够与通过超媒体引用来表达的语义紧密匹配的标识符，允许这个引用保持静态，甚至是在访问该引用的结果可能会随时间而变化的情况下，REST通过将一个资源定义为创作者想要标识的语义，而不是创建引用时那些语义的对应值。然后留给创作者来保证所选择的这个标识符确实真正标识出了他所想要表达的语义 表述把资源定义为URI标识的一个”概念”而不是具体文档，用户如何操作一个资源(“概念”)呢？ REST引入了“表述”这个中间层，即通过资源的表述来操作资源，而不是直接在资源本身上进行操作 资源和接口背后的实现细节都应该是被隐藏起来的，通过接口和表述这两个独立的概念来隔离接口和资源的这两者的具体实现，这也是REST的统一接口这个架构约束的动机。URI和HTTP组成了接口，HTML作为资源的表述， 使得来源服务器对接口和资源的具体实现得以统一化，例如基于URI和HTTP提供接口没变，服务端对应的语言变更或者架构变更对客户端来说并没有影响 将语义绑定到URI一个资源可以拥有多个标识符，或者说存在两个或更多的不同URI在访问服务端时具有相同的语义。 对于服务器或客户端不需要知道或理解URI的含义(如在网页点击一些按钮，对于Web层来说可能只是一个POST请求而已)，这个语义应该是由用户来解读 REST在URI中的不匹配就像大多数现实中系统一样，并非所有已部署的Web架构组件都服从Web架构设计给出的每一个架构约束。 REST既可以被用作改进架构的方法，也可以被用来识别架构不匹配的地方。尽管无法避免这种不匹配，但是可以识别出他们 尽管URI的设计和REST中标识符的概念相匹配，但是仅仅依靠URI的语法规则是不足以约束不匹配的行为的。其中的一种滥用就是在所有的URL中包括标识当前用户的信息，这样的办法可以用于维护服务器会话的状态，但是也会降低共享缓存的效率，也会降低服务器的可伸缩性，并且如果一个用户把这个URL发给其他的用户时，会得到不希望看到的结果(可能看到的就是别人的数据)。这其实时违反了REST的无状态的约束。另外一个便是把Web看作是一个分布式的文件系统的时候，因为文件系统其实是暴露了其实现细节]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Rest Notes-REST架构的视图]]></title>
      <url>%2F2018%2FRest%20Notes-REST%20Architectural%20Views%2F</url>
      <content type="text"><![CDATA[摘要: 上一篇我们已经孤立的了解了REST的架构元素，接下来我们可以使用架构视图来描述这些元素如何协作以形成一个架构。为了展示REST的设计原则，需要使用三种视图：过程视图、连接器视图、数据视图 正文:REST架构的视图过程视图(Process View)过程视图的主要作用是通过展示数据在系统中的流动路径，得出组件之间的交互关系。下图提供了一个基于REST的架构的过程视图 一个用户代理正在处理三个并行的交互(a、b、c)，用户代理的客户端连接器的缓存无法满足请求，因此它根据每个资源标识符的属性和客户端连接器的配置将每个请求转发到资源的来源服务器 请求a被发送到一个本地代理，然后代理通过DNS查找到了一个网关，该网关把这个请求发送到一个可以满足该请求的来源服务器 请求b被直接发送到了一个来源服务器 请求c被发送到了一个本地代理，它能够直接访问WAIS(一种与Web架构相分离的信息服务)，并将WAIS的响应翻译为一种通用的连接器接口能够识别的格式 REST通过强制要求消息具有自描述性来支持中间组件的处理，其具体体现为：请求之间的交互是无状态的、使用标准的方法和媒体类型来表达语义和交换信息、以及响应可以明确地表名其可缓存性 连接器视图(Connector View)连接器视图聚焦于组件之间的通信机制，客户连接器检查资源标识符，以便为每个请求选择一个合适的通信机制。例如标识符如果是一个本地资源，则连接到一个处理本地资源的代理组件 REST并不限制通信只能使用一种特殊的协议，比如上面过程视图中请求c将http转成了wais。尽管如此，与其他协议的服务的交互被限制为只能使用REST连接器的语义 数据视图(Data View)数据视图展示了信息在组件之间流动时的应用状态。因为REST被明确定位于分布式信息系统，它将应用看作是一种信息和控制的聚合体，用户可以通过这个聚合体执行它们想要完成的任务。 REST将所有的控制状态都集中在从交互的响应中接收到的表述之中，其目的是通过使服务器无需维护当前请求之外的客户端状态从而改善服务器的可伸缩性。 REST的模型应用是一个引擎，它通过检查和选择当前表述集合中的状态跃迁选项从一个状态移动到下一个状态。 前几篇文章介绍了REST的风格推导到REST架构元素和REST架构视图。作者描述了指导REST的软件工程原则和为支持这些原则而选择的交互约束，并将它们与其他架构的约束进行了对比 下一篇将介绍REST应用于现代Web架构的设计、规范、部署过程中的经验与教训以及对REST架构的评估]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Rest Notes-REST架构的元素]]></title>
      <url>%2F2018%2FRest%20Notes-REST%20Elements%2F</url>
      <content type="text"><![CDATA[摘要: 上篇文章是对REST的风格推导，本篇是对REST架构中元素做解释 正文:REST架构的元素数据元素(Data Elements)在分布式对象风格中，所有的数据被封装和隐藏在数据的处理组件之中。于分布式对象不同的是，REST的关键方面之一是架构的数据元素的性质和状态。在分布式超媒体的特性中，当用户选择了一个链接后，该链接所指向的信息需要从其存储地移动到其使用地。对于一个分布式超媒体系统的架构师而言，他只能在三种选项中做出选择： 在数据所在地对数据进行呈现，并向接收者发送一个固定格式的镜像； 把数据和呈现引擎封装起来，一起发送给接收者； 发送原始数据可一些描述数据类型的元数据，让接收者自己去呈现。 第一种选项对应于传统的客户-服务器风格，将与数据的自然特性有关的所有信息都被隐藏在数据发送者之中，简化了客户端的实现。但是也严重限制了接收者的功能，并且将大部分处理负担都放在了发送者这一边，从来导致伸缩性的问题 第二种对应于可移动对象风格，它支持对于信息的隐藏还可以通过唯一的呈现引擎来支持对于数据的专门处理。但是它将接收者的功能限制在引擎所能预测的范围之内，还大幅增加需要移交的数据量 第三种选项允许发送者保持简单性和可伸缩性，同时使得需要移交的数据最小化。但是它丧失了信息隐藏的优点，并且要求发送者和接收者都必须理解相同的数据类型 REST提供的是所有三种选项的一个混合体，通过以一种数据格式移交资源的表述来进行通信，可以基于接收者的能力和所期待的格式以及内容中动态的选择所使用的数据格式。至于表述是否与资源的原始格式相同，则被隐藏在了接口的背后 通过发送一个表述，可以获得近似于可移动对象风格的好处，这个表述由一个封装过的呈现引擎的标准数据格式中的指令组成。REST因此获得了客户-服务器风格的分离关注点的好处，而且不存在服务器的可伸缩性问题，它允许通过一个通用的接口来隐藏信息，从而支持封装和服务的进化，并且可以通过下载功能引擎来提供一组不同的功能 数据元素 现代Web实例 资源 一个超文本引用所指向的概念性目标 资源标识符 URL、URN 表述 HTML 文档、JPEG图片 表述元数据 媒体类型、最后修改时间 资源元数据 source link、alternates、vary 控制数据 if-modified-since、cache-control 资源和资源标识符REST对于信息的核心抽象是资源，任何能够被命名的信息都能够作为一个资源：一份文档、一张图片、北京的天气等 资源标识符则是对一个资源的唯一标识，由命名权威来为资源分配标识符，映射的语义同样由命名权威来负责 表述REST使用表述来描述资源的当前状态或预期状态，由数据、描述数据的元数据、以及(有时候存在的)描述元数据的元数据组成(通常用来验证消息的完整性) 元数据以名称-值对的形式出现，名称对应于一个定义值的结构和语义的标准。响应消息可以同时包括表述元数据和资源元数据 控制数据 定义了在组件之间移交的消息的用途，例如被请求的动作或响应的含义。也用于提供请求的参数，或覆盖某些连接元素的默认行为 表述的数据格式被称为媒体类型(media type)，发送者能够将一个表述包含在一个消息中发给接收者，接收者根据消息中的控制数据和媒体类型的性质对该消息进行处理。媒体类型有些是用来做自动处理，有些是用来呈现给用户查看的 媒体类型的设计能够直接影响到一个分布式超媒体系统的用户感知的性能。例如接收者对表述呈现之前需要接收一些数据造成的交互的延迟。在网络性能相同的情况下，增量会比整个文档全部接收的浏览器在用户感知层面更好 连接器(Connectors) 连接器 现代互联网实例 客户 libwww、libwww-perl 服务器 libwww、Apache API、NSAPI 缓存 浏览器缓存、Akamai缓存网络 解析器(resolver) 绑定(DNS查找库) 隧道(tunnel) SOCKS、HTTP CONNECT之后的SSL 如上列表所示，REST使用不同的连接器类型来对访问资源和移交资源表述的活动进行封装。连接器代表了一个组件通信的抽象接口，通过提供清晰的关注点分离、并且隐藏资源的底层实现和通信机制，改善了架构的简单性，接口的通用性也使得组件的可替换性变得可能。 所有的REST交互都是无状态的，这一限制得到了四个功能： 它使得连接器无须在请求之间保持应用的状态，改善了可伸缩性，降低了物理资源的消耗 它允许对交互进行并行处理，处理机制无须理解交互的语义 它允许中间件孤立的查看和理解一个请求，当对服务进行动态“编排”时这个是必须的 它强制每个请求都必须包含可能会影响到一个已缓存响应的可重用性的所有信息 上面列表的前两种都是很容易理解的，第三种缓存连接器可以位于客户或服务器连接器的接口处，以便保存当前交互的可缓存的响应； 第四种解析器负责将部分或完整的资源标识符翻译成创建组件间链接所需的网络地址信息(例如Web浏览器会从URI中提取出主机名并利用DNS解析器来获得该命名权威的互联网协议(IP)地址)； 第五种隧道，它简单地跨越连接的边界(如防火墙)对通信进行中继(例如当响应一个connect方法请求时，http代理会切换到一个隧道，从而允许其客户使用一种不同的协议来直接与不支持代理的远程服务器通信。当两端终止通信时隧道就会消失) 组件 组件 现代Web实例 来源服务器(origin server) Apache httpd、微软IIS 网关(gateway) Squid、CGI、反向代理 代理(proxy) CERN代理、Netscape代理、Gauntlet 用户代理(user agent) Netscape Navigator、Lynx、MOMspider 来源服务器使用服务器连接管理被请求资源的命名空间，每个来源服务器都以资源层次结构的形式，为期所暴露的服务提供一个通用的接口。资源的实现细节被隐藏在这一接口的背后 网关也叫反向代理，是由网络或来源服务器强加的中间组件，为其他服务提供接口封装，以执行数据转换、性能增强或安全增强 代理组件是由客户选择的中间件，用来为其他的服务、数据转换、性能增强、安全保护提供接口封装 用户代理使用客户连接器发起请求，并作为响应的最终接收者，常见的例子是Web浏览器 网关与代理的区别是，何时使用代理是由客户来决定的 下篇会写REST架构中的视图部分~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Rest Notes-表述性状态移交(Representational State Transfer ,REST)]]></title>
      <url>%2F2018%2FRest%20Notes-Representational%20State%20Transfer(REST)%2F</url>
      <content type="text"><![CDATA[摘要: 上篇文章提到的“新的架构风格(REST)”就是专门为分布式超媒体系统设计的，它由几种基于网络的架构风格中衍生而来的一种混合架构风格，并且添加了一些额外的架构约束，用来定义统一的连接器接口 正文:推导RESTWeb架构背后的设计基础理论可以描述为由一组应用于架构中元素之上的架构约束组成的架构风格 从“空”风格(Null Style)开始无论是建筑还是软件，架构过程有着两种常见的观点： 设计者一切从0开始最后建造出一个架构，直到架构满足系统需求 设计者从一个整体的系统需求出发，此时没有任何约束(空风格)，通过增量的识别出各种约束应用于系统的架构元素之上，不了解架构元素的可以回看第一篇文章 REST正是使用第二种观点开发出来的，从架构的观点来看，空风格描述了一个组件之间没有明显边界的系统，这就是我们描述REST的起点 客户-服务器首先添加一个客户-服务器约束，该约束背后原则是分离关注点，通过分离用户界面和数据存储这两个关注点，提高了可移植性、可伸缩性。对于Web而言最重要的是这种关注点分离使得组件可以独立的部署与进化 无状态接下来添加一个无状态约束：通信必须在本质上是无状态的，从客户端到服务器的每个请求都必须包含理解该请求所必需的所有信息，会话状态要全部保存在客户端 这一约束产生了可见性、可靠性和可伸缩性三个架构属性，原因可以去查看上面无状态的超链接，这里不重复解释 缓存.为了改善网络的效率，我们添加了缓存这个架构约束，好处在于减少了一些交互，从而提高效率和用户感知性能 早期的Web架构(1994年之前)是通过客户-缓存-无状态-服务器的架构约束集合(风格)来定义的，交互的通信协议仅包含了对非共享缓存(non-shared caches)的支持，并没有限定接口要对所有的资源提供一组一致的语义。相反地，Web依赖于使用一个公共的客户-服务器实现库(CERN的libwww)来维护Web应用之间的一致性 由于Web实现的开发者们早已超越了这种早期的设计，请求除了静态的文档之外还能够识别出动态生成的响应，也以代理和共享缓存的形式开展了对中间件的开发工作，但是必须对现有的协议进行扩展，这样中间件才能可靠的通信。以下三个架构约束（统一接口，分层系统，按需代码）则是对早期Web架构的扩充，以便用来对现代的Web架构的扩展加以指导 统一接口本约束也是使得REST风格与别的风格产生区别的核心特征，通过在组件接口上应用通用性的软件工程原则来简化系统架构，也改善了交互的可见性，也使得它们提供的服务与实现是解耦的，促进了独立的可进化性。当然任何东西都有两面性，统一接口的代价就是降低了效率。因为信息都是使用标准的形式来移交的，而不是特定于应用需求的形式。 统一接口的意义在于凡是参与到每一个http通信的所有组件(浏览器、http代理、服务网关、web服务器、应用服务器等)，都可以理解这个请求。构成这个请求的是uri、http、mime、html，用url标识资源，用http操作资源的表述，用mime协商请求双方都接收的媒体类型(html、json、xml等) REST接口被设计为可以高效的移交大粒度的超媒体数据，并对Web的场景情况做了优化，但是这也导致该接口对于其他形式的架构交互而言并不是最优的 为了获得统一接口，需要多个架构约束来指导组件的行为，REST由四个接口架构约束来定义： 资源的识别 通过表述来操作资源 自描述的信息 超媒体作为应用程序状态的引擎（HATEOAS） 分层系统为了进一步改善与互联网规模这个需求相关的行为，我们添加了分层系统架构约束，为整个系统的复杂性设置了边界，并且提高了底层独立性。我们能够使用层级来封装遗留服务，使新的服务免受遗留客户端的影响。 中间件还可以支持负载均衡来改善系统的可伸缩性。然而，分层系统会增加数据处理的开销和延迟，因此降低用户感知的性能。不过对于一个支持缓存的架构来说，则可以通过在中间层使用共享缓存来弥补这一缺点。此外还可以通过这些中间层实施安全策略（比如防火墙）。 分层系统架构约束与统一接口架构约束相结合，产生了与统一管道和过滤器风格类似的架构属性。在REST中，中间组件能够主动的转换消息的内容，因为这些消息是自描述的，并且其语义对于中间组件是可见的 按需代码我们为REST添加的最后架构约束来自基于网络应用的架构风格的按需代码约束，REST允许通过下载并执行applet形式或脚本形式的代码，对客户端的功能进行扩展。这样通过减少预先实现的功能的数目，简化了客户端的开发，允许部署之后下载功能代码也改善了系统的可扩展性。但是这样做降低了可见性（REST的连接器和组件并无法理解这些脚本），因此它只是REST的一个可选的架构约束 风格推导小节REST架构风格由一组经过选择的架构约束组成，通过这些架构约束在候选架构上产生所期待的架构属性，夏天是根据基于网络应用的架构风格图形化描述了REST架构风格的架构约束来源 本篇文章主要是对rest风格的推导，下一篇文章会介绍REST架构中的架构元素]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Rest Notes-设计Web架构：问题与领悟]]></title>
      <url>%2F2018%2FRest%20Notes-Designing%20Web%20Problems%20and%20Insights%2F</url>
      <content type="text"><![CDATA[摘要: 本文介绍Web架构的需求，以及作者在对Web通信协议做设计评估遇到的问题，根据上篇文章的调查和分类获得的领悟推导出了开发某种架构风格的方法，用来改进现代Web架构的设计工作提供指导 正文:设计Web架构：问题与领悟Web应用领域的需求Berners-Lee(Web之父)写到：“Web’s major goal was to be a shared information spacethrough which people and machines could communicate”，意思是Web的主要目的是旨在形成一种共享的信息空间(链接众多文档的广域的超媒体信息检索系统)，人类和机器都可以通过它来进行沟通 这个系统最初期望的用户是分散在世界各地的、通过互联网连接的各个大学和政府的高能物理研究实验室。他们的机器是不同种类的终端、工作站、服务器和超级计算机的大杂烩，所以他们的操作系统和文件格式也是一个大杂烩。构建一个这样的系统所面临的挑战是为这些信息文档提供统一的接口，使得这些信息可以在众多的平台上进行交流通信，以及当新的设备接入到这个系统时，可以进行增量的部署。 低门槛参与创建和构造信息是自愿的，因此采用“低门槛”策略是十分必要的。 选择超媒体作为用户界面是因为其简单性和通用性。 无论信息来源何处都能使用相同的界面进行呈现 链接的关系可以形成一个关系“网状结构” 对于创作者而言，超媒体的创作语言也必须是简单的，能够使用现有的编辑工具来进行创建，无论是否连接到互联网，都可以使用此超媒体格式来保存创作的内容。 对于应用开发者而言，简单性也是一个目标，因此所有的协议都被定义为文本格式，以方便对通信进行观察和测试。 可扩展性简单性使得我们部署一个分布式系统的最初实现成为了可能，可扩展性使得我们避免了永远陷入已部署系统的局限之中。就像社会的变化一样，一个系统如果想要像Web那么长寿就必须要做好应对变化的准备 分布式超媒体超媒体是由应用控制信息来定义的，这些信息内嵌在信息的表述之中。分布式超媒体系统允许在远程地点存储表达控制信息，因此分布式超媒体系统中的用户操作需要将大量的数据从其存储地移交到其使用地，所以Web的架构必须支持大粒度的数据移交。超媒体交互的可用性很容易影响到用户感知的性能（比如用户选择了一个链接，到链接的界面呈现之间的时间），因为Web的交互的信息是跨域整个互联网的，则Web的架构必须尽量的减少网络交互的次数以改善用户感知的性能。 互联网规模Web旨在成为一个互联网规模的分布式超媒体系统，这意味着它的内涵远远不止仅仅是地理上的分布。互联网是跨越组织便捷互相连接的信息网络。信息服务的提供商必须能够有能力满足无法控制的可伸缩性和软件组件的独立部署两方面的要求 可伸缩性 无法控制的可伸缩性指的是架构元素可能会于其组织边界之外的元素进行通信，当它们遇到如下的情况时仍能正常运行：未曾预料到的负载、收到错误的数据或者恶意的数据等等 独立部署 多个组织边界也意味着系统应该可以应对新旧组件的共存，而不妨碍新组件使用它们的新功能。同时现有的架构元素在设计的时候需要考虑到以后会添加新功能，旧的实现也必须能够方便的识别出来，从而把这些遗留的行为封装起来，不会对新元素造成不利影响。对于Web这样的系统来说，强制要求架构中的所有组件都整齐划一的来部署是不现实的事情 问题尽管为Web的成功而欢欣鼓舞，但互联网开发者社区开始担心Web使用的快速增长率，因为最早的HTTP0.9是一个非常简单的协议，是为单个请求响应设计的，新的站点越来越多的采用了图片作为网页的一部分，导致出现了不同的浏览模式。此时的Web架构已经无法满足这样的需求了，随后在IETF形成了三个工作小组HTTP,URI和HTML。这些工作组的主要任务是定义现有架构性通信的子集（早期Web中普遍的一致的实现），然后指定一组规范来解决这些问题。这些工作带来的挑战是如何把一组新功能引入到一个已经被广泛部署的系统中；以及如何确保新功能的引入不会对那些使得Web成功的架构属性带来不利的影响甚至是毁灭性的影响 解决之道 识别出一组存在于早期Web架构(HTTP1.0和HTTP1.1之前)中的架构约束，这些架构约束负责产生出所期待的架构属性 识别出在互联网规模的分布式超媒体系统中所期待的架构属性，然后选择额外的会产生那些架构属性的架构风格，将它们与早期的Web架构中的约束相结合，形成一种新的风格 使用新的架构风格作为指导，对修改和扩展Web架构的提议进行评估，看其是否存在冲突，如果存在冲突则表明这个提议违反了一个或多个Web背后的设计原则 上面的1、2、3实际上是一种无顺序的、迭代的方式来应用的 修正后的协议规范是根据”新的架构风格“的指导来编写的，最后通过修订后规范，开发实现它，然后进行部署。这些解决之道是源自于Fielding博士直接参与了Apache Http服务器的项目和libwww-perl客户端库，以及为网景的Navigator、Lynx和微软的IE的开发者提供建议得到的经验 下篇文章就要介绍上面的“新的架构风格”(REST)推导过程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Rest Notes-基于网络应用的架构风格]]></title>
      <url>%2F2018%2FRest%20Notes-Web%20Based%20Architecture%20Styles%2F</url>
      <content type="text"><![CDATA[摘要: 上章节划定了我们要讨论的范围是基于网络应用的架构，接下来对基于网络应用的常见架构风格进行了调查，并针对每个风格进行多方面的评估 正文:基于网络应用的架构风格数据流风格 风格 继承 网络性能 用户感知性能 简单性 可进化性 可配置性 可扩展性 可重用性 可见性 PF ± + + + + + UPF PF - ± ++ + ++ + ++ + (-)是消极影响，(+)是积极影响，(±)是表示影响的性质取决于问题领域的某个方面，(空)是没有约束 管道和过滤器(Pipe and Filter,PF) 每个过滤器(组件)从输入端读取数据流，在输出端产出数据流，通常会对输入数据流应用一种转换并增量的处理它们 缺点： 长管道会增加延迟 不能增量处理只能批量顺序处理，降低用户感知性能 统一管道和过滤器(Uniform Pipe and Filter,UPF)在PF风格的基础上增加了必须具有相同接口的约束 如Unix操作系统中，其中过滤器进程具有一个字符输入流(stdin)和两个字符输出数据流(stdout和siderr)组成的接口 通过限定使用这个接口就可以排列组合独立的过滤器形成新的应用，理解过滤器的运转也会变得简单 缺点： 当数据需要转换时候这个约束可能会降低网络性能 复制风格 风格 继承 用户感知的性能 效率 可伸缩性 简单性 可靠性 RR ++ + + $ RR + + + + 复制仓库(Replicated Repository,RR)利用多个进程提供相同的服务来改善数据的可访问性、可伸缩性，给客户端制造出只有一个集中服务的幻觉 优点： 改善了用户感知的性能 减少处理正常请求的延迟 在主服务器故障或断网时候支持离线操作 缺点： 复制所导致的复杂性 缓存(Cache,$)缓存风格继承复制仓库风格，复制个别请求结果以便后面的请求复用 优点： 缓存风格实现起来要更容易 缺点： 用户感知的性能层面上改善不大，因为会存在大量没有命中缓存的请求，离线操作也只会是历史数据 分层风格 风格 继承 网络性能 用户感知性能 效率 可伸缩性 简单性 可进化性 可重用性 可见性 可移植性 可靠性 CS + + + LS - + + + + L+CS CS+LS - ++ + ++ + + CSS CS - ++ + + + + CSS+$ CSS+$ - + + ++ + + + + LC$SS LCS+C$SS - ± + +++ ++ ++ + + + + RS CS + - + + - RDA CS + - - + - 客户-服务器(Client-Server,CS)这个是最常见的架构风格，服务端提供接口(服务)，客户端通过连接器发送请求执行这个接口(服务)，服务端收到后进行正常操作 分层-客户-服务器(Layered-Client-Server,LCS)分层系统(Layered System,LS)是按照层次来组织的，下面一层给上面一层提供服务，底层则会隐藏细节；在基于网络的系统中(前文提到的讨论范围)，分层系统仅限于与CS相结合，形成LCS风格 LCS是在CS的基础上添加了代理(proxy)组件和网关(gateway)组件，例如我们目前前端开发使用的转发代理和API网关，这样额外的工作为系统添加了多个层，从而实现例如LoadBlance和Security Check 优点： 通过隐藏和封装的层级关系，减少了耦合，改善了可进化性和可重用性 缺点： 增加了处理数据的开销和延迟 降低了用户感知性能 客户-无状态-服务器(Client-Stateless-Server,CSS)该风格强调的是在服务端不允许有会话状态(session state)，所以客户端给服务端发的每个请求都必须包含理解(解析到)请求的必备信息，会话状态交给客户端保存 优点： 可见性 以前需要看很多请求数据才可以确定请求的全部性质，现在看一个就行啦 可靠性 使故障的恢复更简单(无状态嘛) 可伸缩性 不保存多个请求的状态 缺点： 每次请求都需要添加类似重复的数据 降低网络性能，增大了交互的开销 客户-缓存-无状态-服务器(Client-Cache-Stateless-Server,CSS)在CSS风格基础上增加了缓存风格，在客户端与服务端中间斡旋，重用历史的请求响应 优点： 减少了一些交互，从而提高效率和用户感知性能 远程会话(Remote Session,RS)该风格属于CS的一种变体，试图将客户端的复杂性最小化，可重用性(客户端)最大化，可以理解为“客户端的分布式会话” 优点： 集中维护服务端接口更加容易 利用会话上下文提高效率 缺点： 减低了服务端的可伸缩性(毕竟需要保存状态，这点和无状态刚好是反的) 降低了交互的可见性 远程数据访问(Remote Data Access,RDA)该风格是CS的一种变体，将应用状态分布在客户端和服务端上，如客户端发送一个查询格式(sql或者自定义查询参数)给服务端，服务端执行这个查询，返回一个结果集，客户端可以拿到结果集进行数据筛选或拼接 有点类似在某险看到的数据服务，提供查询接口，根据自定义参数返回想要的数据 优点： 提高了可见性(sql或约定好的参数规则) 服务端可以进行数据的筛选，避免巨结果集在网络的传输 缺点： 降低了服务端的可伸缩性 部分的故障会导致可靠性的损失 移动代码风格 风格 继承 网络性能 用户感知的性能 效率 可伸缩性 简单性 可进化性 可扩展性 可定制性 可配置性 可重用性 可见性 可移植性 可靠性 VM ± + - + REV CS+VM + - ± + + - + - COD CS+VM + + + ± + + - 虚拟机(Virtual Machine,VM)所有的移动代码都需要以某种方式来执行，这正是是虚拟机风格，虚拟机通常被当做某些语言的引擎，如JVM 优点： 改善了可扩展性(指令和实现的分离，如JVM的Indy指令) 缺点： 明显会降低了可见性、简单性 远程求值(Remote Evaluation,REV)顾名思义，类似我们在一些开源组件看到的GLUE模式，或者说Web IDE这种，客户端将需要执行的代码发到服务端，服务端进行执行 按需代码(Code on Demand,COD)该风格与上面的REV核心方向是相反的，由客户端访问服务端拿到想要的代码在客户端本地执行 这种风格在做流程自动化机器人有用到，访问服务端接口拿到动态脚本，客户端这边执行自动化脚本实现页面自动化操作 点对点(Peer-to-Peer) 风格 继承 网络性能 用户感知的性能 效率 可伸缩性 简单性 可进化性 可扩展性 可配置性 可重用性 可见性 可移植性 可靠性 EBI + – ± + + + + - - C2 EBI+LCS - + + ++ + + ++ ± + ± 基于事件的集成(Event-based Integration,EBI)该风格也被称为隐式调用风格或者事件系统风格，通过消除了解连接器接口的标识信息的必要性，降低了组件之间的耦合 组件调用是通过发布事件或者广播，由系统本身来调用订阅该事件的组件，基于事件的这种风格为可扩展性、可重用性和可进化性(这些架构属性在第二篇基于网络的架构有详细介绍)提供了强有力的支持 缺点： 事件风暴(可伸缩性问题) 缺乏可理解性 不适合交换大粒度的数据 C2C2风格是对上面EBI的一个加强，通过增加分层-客户-服务器(LCS)风格来达到支持大粒度的重用和解决了可伸缩问题 异步通知消息向下传送，异步请求消息向上传送]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Rest Notes-基于网络应用的架构]]></title>
      <url>%2F2018%2FRest%20Notes-Web%20Based%20Architecture%2F</url>
      <content type="text"><![CDATA[摘要: 本文为Rest论文的第二章节基于网络应用的架构学习总结，该章同第一章软件架构一样继续讨论论文的背景，主要是对论文要讨论的范围进行一个定义 正文:基于网络应用的架构范围本文讨论的范围限制在基于网络应用的架构风格 基于网络 VS 分布式基于网络的架构组件之间的通信仅限于消息传递或者消息传递的等价物 Tanenbaum和van Renesse是这样区分两者：基于网络的系统有能力跨越网络运行，分布式好像是普通的集中式系统，但是运行在多个独立的CPU上 应用软件 VS 网络软件应用软件的架构是对于整个系统的一种抽象，用户动作的目的可以被表示为功能性的架构属性，而网络抽象目的则是将bit从一个地点移动到另一个地点，不关心为何移动 只有在应用的层面上我们才可以拿到详细的运行参数(交互参数、应用状态参数、吞吐量等)等去评估设计上的权衡，所以我们讨论的范围需要限制在对应用软件架构的讨论 关键关注点的架构属性性能(Performance)基于网络应用的性能首先取决于应用的需求，然后是所选择的交互风格，接下来是实现架构，最后是每个组件的实现 网络性能(Network Performance) 吞吐量 信息在组件之间移交的速率 开销 分为初始化开销和每次交互产生的开销 带宽 特定网络连接上可用的最大吞吐量 可用带宽 应用实际可用的那部分带宽 用户感知的性能(User-perceived Performance) 延迟 指从最初的触发请求到得到最早的响应指示之间持续的时间 完成时间 完成一个应用动作所花费的时间 延迟与完成时间区别在于一个能够增量的处理数据一个是全部处理完。例如页面的异步加载与全部加载完毕 网络效率(Network Efficiency) 最佳的应用性能是通过不适用网络而获得的，对于基于网络的应用来说有效的减少网络交互才是最高效的架构风格 我们可以利用缓存、对数据的迁移路径缩短减少某些交互的必要性 可伸缩性(Scalability)我们可以通过以下方法来改善可伸缩性：简化组件、将服务分布到很多组件(对交互去中心化)、以及通过监控对交互和配置进行一般控制 影响： 交互的频率 组件负载随时间的分布 强一致性or弱一致性 同步or异步 环境 可修改性(Modifiability)可修改性包括可进化性(一个组件改变不会对其他组件产生负面影响)、可扩展性、可定制性(临时定义的支持)、可配置性(部署之后修改的支持)、可重用性，我们在对一个已部署的应用做出改变时候，不应该去停止和重新启动整个系统，还要准备好应对随着时间的变化产生的兼容性 可见性(Visibility)可见性是指一个组件对于其他两个组件之间的交互进行监视和斡旋(wo xuan)的能力 拥有了可见性之后，就能够通过多个交互共享的缓存来改善性能、通过分层服务来改善可伸缩性、通过反射式监控来改善性能、通过允许防火墙等中间件对交互做检查来改善安全性 可移植性(Portability)这里的可移植性指的是软件能够在不同环境下运行，例如虚拟机架构风格以及那些限制只使用标准格式的数据元素的架构风格 可靠性(Reliability)从应用的架构角度来说，可靠性可以被看作架构元素出现故障影响的程度 可以通过避免单点故障、增加冗余、允许监视、以及将故障的范围缩小到一个可恢复的动作]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Rest Notes-软件架构]]></title>
      <url>%2F2018%2FRest%20Notes-Software%20Architecture%2F</url>
      <content type="text"><![CDATA[摘要: 本文为Rest论文的第一章节软件架构学习总结，该章从Rest论文的背景出发，先引入了一些软件架构的概念术语，然后定义了一套自洽的软件架构术语，文中出现的很多人(Perry、Wolf、Shaw、Garlan)都是最早从事软件体系结构研究的 正文:软件架构一个系统的软件体系结构是由组件(构件)集合、组件(构件)之间的交互、连接器以及互相结合的约束限制和描述来组成的。服务器、数据库、某层次架构的层等都算是所属架构的组件实例 抽象原则(核心)通过封装隐藏内部源码实现的细节，架构的设计与源代码结构的设计关系应该是相互分离的 架构元素(Elements)作者将软件架构定义为一些架构元素(组件、连接器和数据)的配置，这些元素之间的关系受到约束，以获得所期待的一组架构属性。 作者认为软件架构不应该包括基础原理这块，虽然基础原理可以影响到一个架构的开发，但是一个架构一旦建成，它将脱离其所基于的基本原理而独立存在。就好像一个大楼建成后蓝图和计划被烧毁了但是楼并不会倒塌。 组件(Components)组件在Perry和Wolf的定义中属于处理元素，也即是执行数据转换的元素，Garlan和Shaw将组件简单描述为执行计算的元素，作者试图更加精确的将组件和连接器区分开来：组件是软件指令和内部状态的抽象单元，通过其接口提供数据的转换能力(包括数据的计算、转换、封装等) 组件的定义应该由其提供的接口和服务来定义而不是隐藏在该接口之后的实现来定义 连接器(Connectors)连接器在Perry和Wolf定位中属于连接元素，也即是将架构的不同部分结合在一起的粘合剂 example:远程过程调用、消息传递协议、数据流 通过例子可以看出来其连接器其实是来支持组件之间的通信，其内部可能也是通过组件对数据的转换、移交、反转换来达到通信的目的，然而从架构层面可以忽略这些细节 数据(Data)数据是组件通过连接器接收或发送的信息元素 在对架构做评估时候，一定要去考虑数据元素，一种是直接与组件进行交互，第二种是将组件转化为一个数据元素通过网络进行传输，然后进行反转换得到一个能够在本地与之交互的组件 配置(Configurations)配置是在系统运行期间的组件、连接器和数据之间的架构关系的结构 Abowd等人将架构的描述定义为：组件可以定义为计算的所在地，连接器定义为组件之间的交互，配置定义为相互交互的组件和连接器的集合 架构属性(Properties)架构属性比较抽象，举个例子：组件的可重用率、效率、扩展性等非功能属性和具体的功能属性都属于架构属性 架构设计的目标是创建了一个包含一组架构属性的架构，不同架构属性的相对重要性取决于所期待的系统的本身特性 架构风格(Styles)架构风格是一种机制，用来对架构进行分类并且定义它们的公共特征，并约束了架构元素的角色和功能以及元素之间的关系 ”风格“常用于描述个性化，使用风格来描述架构约束常常令人迷惑，Loerke将风格描述为挑剔者对过去架构的观点，Loerke认为在传统的建筑架构设计中风格的真正来源是一组应用于设计之上的约束，达到或复制一种特定的风格应该是设计者的最低目标。这样将架构设计的约束称为一种更为抽象的风格表达变的更加容易。可以认为一种架构风格是一组相互协作的架构约束，给它取了个名字罢了 Perry和Wolf认为一种架构风格封装了关于架构元素(组件、连接器、数据)的重要决策，强调元素之间关系的约束 Garlan和Shaw认为一种架构风格决定了在此架构风格的架构中能够使用哪些组件和连接器 作者认为他们对架构风格的定义比较狭隘，原因是他们将架构看作是形式化的描述，而不是正在运行的系统 虽然一些架构风格常常被描述为适合所有软件的”银弹”式解决方案，但是一个好的设计者应该去选择最为匹配的架构风格。选择一个正确的架构风格需要去理解应用的领域，通信的需求，预测每种交互风格对基于网络通信的特性的敏感度 模式与模式语言(Patterns and Pattern Lang)在Java这种OOP编程语言领域，一种设计模式被定义为一种重要的和重复出现的系统构造，而一种模式语言是一个模式的系统 模式的设计空间包括了如java的类继承和接口组合或者更高层次的设计，这个设计空间应该是在架构风格(约束)之下，促使系统出现所期待的架构属性 视图(Views)架构视图常常特定于应用，并且基于应用而千变万化，而视图的种类更是多种多样 Perry和Wolf描述了三种重要的软件架构视图： 处理视图 侧重于流经组件的数据流 数据视图 侧重于处理的流程，而不是连接器 连接视图 侧重于组件之间的关系和通信状态]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[API 网关的安全]]></title>
      <url>%2F2018%2FAPI-Gateway-Safety%2F</url>
      <content type="text"><![CDATA[摘要: 本篇文章是总结工作中遇到的安全问题 正文:API 网关的安全XSRF/CSRF跨站请求伪造(Cross-site request forgery)是一种挟制用户在当前已登录的web程序上执行非本意的操作的攻击方法，简单来说就是你在浏览器打开了两个页面，其中一个页面通过窃取另一个页面的cookie来发送伪造请求 Example某一家银行转账操作的url地址为：http://www.examplebank.com/withdraw?account=AccoutName&amp;amount=1000&amp;for=PayeeName 藏身于恶意网站的某代码片段：&lt;img src=&quot;http://www.examplebank.com/withdraw?account=Alice&amp;amount=1000&amp;for=Badman&quot;&gt; 若账户人员为Alice的用户访问了恶意网站，其登录信息尚未过期，就会丢失1000资金 CSRF攻击并不是直接获取用户账户控制权，而是欺骗用户浏览器，让其已用户的名义执行操作 防御措施 HTTP头Referer字段，这个字段用以标明请求来源于哪个地址，看其url是否与要请求地址位于同一域名下 添加校验Token,恶意网站的请求不带Token无法通过校验 XSS跨站脚本(Cross-site scripting)是一种网站应用程序的安全漏洞攻击，是代码注入的一种。 防御措施 过滤特殊字符(转义) 使用浏览器自带的xss-filter X-XSS-Protection CSP(Content Security Policy) 如限制script src Content-Security-Policy: script-src ‘self’ frame-ancestors 限制了当前页面可以被哪些页面以iframe,frame,object等方式加载 Github的CSP参数 123456789101112Content-Security-Policy: default-src 'none'; base-uri 'self';block-all-mixed-content;connect-src 'self' uploads.github.com status.github.com collector.githubapp.com api.github.com www.google-analytics.com github-cloud.s3.amazonaws.com github-production-repository-file-5c1aeb.s3.amazonaws.com github-production-upload-manifest-file-7fdce7.s3.amazonaws.com github-production-user-asset-6210df.s3.amazonaws.com wss://live.github.com;font-src assets-cdn.github.com;form-action 'self' github.com gist.github.com;frame-ancestors 'none';frame-src render.githubusercontent.com;img-src 'self' data: assets-cdn.github.com identicons.github.com collector.githubapp.com github-cloud.s3.amazonaws.com *.githubusercontent.com; manifest-src 'self';media-src 'none';script-src assets-cdn.github.com;style-src 'unsafe-inline' assets-cdn.github.com X-Frame-Options:SAMEORIGIN 这个页面只允许同源页面加载 Http-Only 保护cookie JWT的安全JWT一种基于JSON的、用于在网络上声明某种主张的令牌，由三部分组成，头部、消息体与签名。 前端将JWT通过HTTP Header发送给服务端可以有效防护CSRF，但是服务端既然无状态，Token在客户端存储位置就是一个问题 存放位置 存在Cookie,要使用Http-Only 保护cookie 存在Local Storage 无法防止XSS LocalStorage 的API通过JavaScript提供的，攻击者可以通过XSS攻击窃取信息，如Token等 12345if(localStorage.length)&#123; for(i in localStorage) &#123; console.log(localStorage.getItem(i)); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM Specification notes 1 -Jvm Structure]]></title>
      <url>%2F2018%2FJVM-Specification-notes-1%2F</url>
      <content type="text"><![CDATA[摘要: Jvm Structure 正文:Java 虚拟机结构Class文件格式数据类型 原始类型(基本类型) 数值类型{整数[byte8 short16 int32 long64 char16]、浮点[float32 double64]} 布尔类型{boolean8} returnAddress类型{表示一条字节码指令的操作码} 引用类型 编译器应当在编译期间尽最大努力完成可能的类型检查，使得虚拟机在运行期间无需进行这些操作 编译器会在编译期或运行期会将byte和short类型的数据带符号扩展（Sign-Extend）为相应的int类型数据，将boolean和char类型数据零位扩展（Zero-Extend）为相应的int类型数据 运行时数据区程序运行期间会使用到的运行时数据区 PC寄存器每一个虚拟机线程都有自己的PC寄存器，保存Java虚拟机正在执行的字节码指令的地址 Java 虚拟机栈栈与线程同时创建，存储局部变量与一些过程结果的地方 Java堆可供各条线程共享的运行时内存区域，也是供所有类实例和数组对象分配内存的区域 Java堆在虚拟机启动的时候就被创建，它存储了被自动内存管理系统所管理的各种对象，这些受管理的对象无需，也无法显式地被销毁 方法区可供各条线程共享的运行时内存区域 方法区在虚拟机启动的时候被创建，存储了每一个类的结构信息，例如运行时常量池、字段和方法数据、构造函数和普通方法的字节码内容、还包括一些在类、实例、接口初始化时用到的特殊方法 虽然方法区是堆的逻辑组成部分，但是简单的虚拟机实现可以选择在这个区域不实现垃圾收集 运行时常量池每一个类或接口的常量池的运行时表示形式，它包括了若干种不同的常量：从编译期可知的数值字面量到必须运行期解析后才能获得的方法或字段引用 每一个运行时常量池都分配在Java虚拟机的方法区之中，在类和接口被加载到虚拟机后，对应的运行时常量池就被创建出来 本地方法栈如果支持本地方法栈，则会在线程创建的时候按线程分配 栈帧(Frame)用来存储数据和部分过程结果的数据结构，同时也被用来处理动态链接、方法返回值和异常分派 栈帧随着方法调用而创建，随着方法结束而销毁，无论方法是正常完成还是异常完成 栈帧的存储空间分配在Java虚拟机栈 每一个栈帧都有自己的局部变量表、操作数栈和指向当前方法所属的类的运行时常量池的引用 栈帧容量的大小仅仅取决于Java虚拟机的实现和方法调用时可被分配的内存 一条线程只有正在执行某个方法的栈帧是活动的，叫做当前栈帧，对应的方法叫当前方法，定义这个方法的类叫当前类。对局部变量表和操作数栈的各种操作，通常指的是当前栈帧进行的操作 栈帧是线程本地私有的数据，不可能在一个栈帧之中引用另外一条线程的栈帧 如果当前方法调用了其他方法，或者当前方法执行结束，那这个方法的栈帧就不再是当前栈帧了。当一个新的方法被调用，则会新建一个栈帧并成为当前栈帧，当方法返回时会将结果（当前新的栈帧）返回给上一个栈帧，当前栈帧丢弃，上一个栈帧重新成为当前栈帧。 局部变量表长度由编译期决定，存储于类和接口的二进制表示之中，既通过方法的Code属性保存及提供给栈帧使用 一个局部变量可以保存类型boolean、byte、char、short、float、reference和returnAddress的数据 两个局部变量可以保存类型为long和double的数据 当方法被调用时候，参数将会传递至从0开始的连续的局部变量表里。如果是实例方法被调用则第0个局部变量一定是this 局部变量使用索引来进行定位访问，0-max long和double这种需要两个局部变量的类型，索引取最小的那个局部变量。 操作数栈同局部变量表，长度由编译期决定，存储于类和接口的二进制表示之中，既通过方法的Code属性保存及提供给栈帧使用 操作数栈所属的栈帧在刚刚被创建的时候，操作数栈是空的。 Java虚拟机提供一些字节码指令来从局部变量表或者对象实例的字段中复制常量或变量值到操作数栈中，也提供了一些指令用于从操作数栈取走数据、操作数据和把操作结果重新入栈。在方法调用的时候，操作数栈也用来准备调用方法的参数以及接收方法返回结果，例子参考初识jvm指令执行流程 一个long或者double类型的数据会占用两个单位的栈深度，其他数据类型则会占用一个单位深度 动态链接在Class文件里面，描述一个方法调用了其他方法，或者访问其成员变量是通过符号引用来表示的，动态链接的作用就是将这些符号引用所表示的方法转换为实际方法的直接引用 类加载的过程中将要解析掉尚未被解析的符号引用，并且将变量访问转化为访问这些变量的存储结构所在的运行时内存位置的正确偏移量 由于动态链接的存在，通过晚期绑定（Late Binding）使用的其他类的方法和变量在发生变化时，将不会对调用它们的方法构成影响 浮点算法Java虚拟机采纳了《IEEE Standard for Binary Floating-Point Arithmetic》（ANSI/IEEE Std. 754-1985，New York）浮点算法规范中的部分子集 Java虚拟机和IEEE 754中的浮点算法 在Java虚拟机中的浮点操作在遇到非法操作，如被零除（Divison By Zero）、上限溢出（Overflow）、下限溢出（Underflow）和非精确（Inexact）时，不会抛出exception、trap或者其他IEEE 754异常情况中定义的信号。 12double d = 1;System.out.println(d/0); //Infinity 非exception Java虚拟机里面，将浮点数转化为整型数是使用向零舍入(去尾操作) 12double d = 1.61;System.out.println((int)d);//1 非2 初始化方法的特殊命名 &lt;init&gt; 在Java虚拟机层面上，Java语言中的构造函数是以一个名为&lt;init&gt;的特殊实例初始化方法的形式出现的 &lt;init&gt;这个方法名称是由编译器命名的，因为它并非一个合法的Java方法名字，不可能通过程序编码的方式实现。实例初始化方法只能在实例的初始化期间，通过Java虚拟机的invokespecial令来调用，只有在实例正在构造的时候，实例初始化方法才可以被调用访问 &lt;clinit&gt; 类或者接口是通过&lt;clinit&gt;方法完成初始化的，这个名字也是由编译器命名的，没有任何虚拟机字节码指令可以调用这个方法，只有在类的初始化阶段中会被虚拟机自身调用 异常的处理抛异常的本质实际上是程序控制权的一种即时的、非局部（Nonlocal）的转换——从异常抛出的地方转换至处理异常的地方 同步异常 当前线程执行的某个操作所导致的异常 异步异常 其他线程中出现的异常 由Java虚拟机执行的每一个方法都会配有零至多个异常处理器（Exception Handlers），异常处理器描述了其在方法代码中的有效作用范围（通过字节码偏移量范围来描述）、能处理的异常类型以及处理异常的代码所在的位置 当有异常被抛出时，Java虚拟机会搜索当前方法的包含的各个异常处理器，如果能找到可以处理该异常的异常处理器，则将代码控制权转向到异常处理器中描述的处理异常的分支之中 字节码指令Java虚拟机的指令由一个字节长度的、代表着某种特定操作含义的操作码（Opcode）以及跟随其后的零至多个代表此操作所需参数的操作数（Operands）所构成。虚拟机中许多指令并不包含操作数，只有一个操作码。如果忽略异常处理，那Java虚拟机的解释器使用下面这个伪代码的循环即可有效地工作： 12345do &#123; 自动计算PC寄存器以及从PC寄存器的位置取出操作码; if (存在操作数) 取出操作数; 执行操作码所定义的操作&#125; while (处理下一次循环); 如果要将一个16位长度的无符号整数使用两个无符号字节存储起来，如下所示 (byte1 &lt;&lt; 8) | byte2 加载和存储指令 xload 从局部变量加载到操作数栈 xstore 从操作数栈存储到局部变量表 xpush，xdc，xconst 将一个常量加载到操作数栈 wide 扩充局部变量表的访问索引 运算指令对两个操作数栈上的值进行某种特定运算，并把结果重新存入到操作栈顶 整型数据运算 如：iadd，isub，imul，idiv 浮点型数据运算 如：fadd，fsub，fmul，fdiv 类型转换指令将两种Java虚拟机数值类型进行相互转换 宽化类型转换 小范围类型向大范围类型的安全转换，无需显式的转换指令 窄化类型转换 (i2b，i2c，i2s，l2i，f2i，f2l，d2i，d2l，d2f)可能会导致转换结果产生不同的正负号、不同的数量级，数值丢失精度等 注意： 浮点型转整型 NaN-&gt;0 尽管可能发生上限溢出、下限溢出和精度丢失等情况，但是Java虚拟机中数值类型的窄化转换永远不可能导致虚拟机抛出运行时异常 对象创建与操作 创建类实例：new 创建数组：newarray，anewarray，multianewarray 访问类字段(static)和实例字段(!static)：getfield，putfield，getstatic，putstatic 将一个数组元素加载到操作数栈：xaload 将一个操作数栈值储存到数组元素中：xastore 取数组长度的指令：arraylenth 检查类实例类型的指令：instanceof，checkcast 控制转移指令 条件分支 ifeq，iflt，ifle，ifne，ifgt，ifge，ifnull，ifnonnull，if_icmpeq，if_icmpne，if_icmplt，if_icmpgt，if_icmple，if_icmpge，if_acmpeq和if_acmpne 复合条件分支 tableswitch，lookupswitch 无条件分支 goto，goto_w，jsr，jsr_w，ret 各种类型的比较最终都会转化为int类型的比较操作： boolean类型、byte类型、char类型和short类型的条件分支比较操作，都使用int类型的比较指令来完成。而对于long类型、float类型和double类型的条件分支比较操作，则会先执行相应类型的比较运算指令，运算指令会返回一个整形值到操作数栈中，随后再执行int类型的条件分支比较操作来完成整个分支跳转 方法调用与返回指令 方法调用 invokevirtual(调用对象的实例方法)； invokeinterface(调用接口方法-&gt;找到实现接口的对象-&gt;找出适合的方法； invokespecial(调用特殊处理的实例方法：初始化方法 私有方法 父类方法)； invokestatic(调用类方法) 方法返回 return(void) xreturn(返回类型x) 抛出异常在程序中显式抛出异常的操作会由athrow指令实现，除了这种情况，还有别的异常会在其他Java虚拟机指令检测到异常状况时由虚拟机自动抛出 同步Java虚拟机可以支持方法级的同步和方法内部一段指令序列的同步 方法级同步 隐式，无需通过字节码指令来控制 指令集序列同步 通常是由Java语言的synchronized块来表示，java虚拟机的指令集有monitorenter和monitorexit两条指令来支持synchronized关键字的语义 结构化锁定 方法调用期间每一个管程退出都与前面的管程进入相匹配的情形，持有与释放次数相等]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[初识JVM指令执行流程]]></title>
      <url>%2F2018%2FJVM-Instruction-Execution-Flow%2F</url>
      <content type="text"><![CDATA[摘要: 记录下学习JVM指令执行流程的理解 正文:初识JVM指令执行流程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * 0: aload_0 * 1: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V * 4: return * * @author liugang * @since 2018-04-28 */public class Example1 &#123; /** * 为主方法创建一个frame并将其推入线程栈 * 用于执行方法的是method frame，该frame由两个主要部分组成: * 1. local variables Array 局部变量数组--存储方法参数和局部变量位置 * 2. Operand Stack 操作数栈--执行方法的计算 * */ public static void main(String[] args) &#123; /** * Code: * 0: iconst_2 * 1: iconst_3 * 2: invokestatic #2 // Method add:(II)I * 5: istore_1 * 6: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; * 9: iload_1 * 10: invokevirtual #4 // Method java/io/PrintStream.println:(I)V * 13: return * * 步骤： * local variables: args(0) result(1) * 2 3放入操作数栈中 * invoke static add a=2 b=3 * add(int a, int b); * add GG,main的操作数栈保存add的return值:5 * istore_1 将其弹出并将其设置为索引为1(variable result)的变量的值 * */ int result = add(2,3); /** * get static将java/lang/System.out压入操作数栈 * 现在操作数栈里有两个值 out和5 * invoke virtual 调用PrintStream.println方法 * 它从操作数栈中弹出两个元素： * 第一个元素是一个要传递给println方法的整数参数 * 第二个元素是对将要调用println方法的对象的引用 * */ System.out.println(result); &#125; /** * iload 将局部变量表的0 1位置int型变量2 3加载到栈顶 * iadd从栈顶弹出两个数 相加 把和送入到栈顶 * 最后，ireturn弹出顶层元素 * * 0: iload_0 * 1: iload_1 * 2: iadd * 3: ireturn * * @author liugang 2018-04-28 10:47 * */ public static int add(int a, int b) &#123; return a+b; &#125;&#125; 参考链接:jvm-architecture-101-get-to-know-your-virtual-machine]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[栈的应用——四则运算表达式]]></title>
      <url>%2F2018%2FData-Structure-StackApply1%2F</url>
      <content type="text"><![CDATA[摘要:本文是看《大话数据结构》栈章节的学习总结 正文:栈的应用——四则运算表达式 栈的应用场景有很多，如浏览器的后退，编辑软件的回退等，今天要谈的是栈的基本应用之四则运算表达式(中缀转后缀表达式) 大家都知道用计算器可以很方便的计算出两数运算的结果，但是如果遇到有优先级的四则运算，计算器又是如何去精确的计算出结果呢？ 在20世纪50年代有一个叫Jan Łukasiewicz的波兰数学家想到了一种不需要括号的后缀表达式，我们称为逆波兰表示法 ，逆波兰记法不需要括号来标识操作符的优先级 中缀转后缀表达式我们平时所用的标准四则运算表达式，如： 150-(7+5)*2+30*2 叫做中缀表达式，因为所有的运算符号都在两个数字之间，现在我们通过使用栈将其转为后缀表达式 规则： 从左到右遍历上面中缀表达式的每个数字符号 如果是数字则直接输出 如果是符号则判断与栈顶中的符号优先级，是右括号的或者比栈顶中符号优先级低的依次去括号出栈输出 否则在栈中等待最后遍历完依次输出 转换过程 按照上述规则依次遍历150-(7+5)*2+30*2，150是数字直接输出，-号进栈，第三个是左括号也是符号依然进栈，7是数字直接输出，如下图一所示。 下面接着+号进栈，5输出，接下注意的是右括号，遇到右括号需要匹配前面的左括号，并依次去括号出栈输出(输出了+)。接着*号进栈，2输出，如下图二所示。 此时栈顶是*,然后+号准备进栈，对比发现+优先级低于栈顶，则栈顶元素依次输出，完了后+号进栈 。接着30输出，*比栈顶+优先级高，直接进栈不输出，然后2输出。如下图三所示。 最后遍历结束栈中符号依次输出，最终的后缀表达式结果是150 7 5 + 2 * - 30 2 * + 后缀表达式计算结果上述结果：150 7 5 + 2 * - 30 2 * +， 可能很多人问转这个有什么用，接下来看的是该后缀表达式的计算过程。 计算规则：从左到右遍历每个数字和符号，遇到数字就进栈，遇到符号将处于栈顶的两个元素出栈并运算，运算结果进栈，一直到最后算出最终结果 150 7 5依次进栈，+号是符号，将栈顶的 7 5出栈并运算(+)，结果是12并进栈，2是数字同样进栈。如下图四所示。 接着是*号，将栈顶的两个元素运算并重新入栈(12 *2)；然后是-号，栈顶两个元素分别是150 24，结果是126入栈；然后数字30 2依次入栈。如下图五所示。 遍历到*，将栈顶元素30 2运算并重新进栈，最后是+号，所以结果是186出栈，栈变为空。如下图六所示。 上述过程都充分的利用了栈的后进先出特性来处理的，所以该表达式的转换和计算是栈的经典应用之一，对理解栈本身也有很大的帮助~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Zookeeper、kafka部署]]></title>
      <url>%2F2018%2Fmiddleware-install-zk-kafka%2F</url>
      <content type="text"><![CDATA[摘要:安装kafka文档 正文:安装zookeeper、kafka解压zk安装包1tar -zxvf zookeeper-3.4.10.tar.gz 添加系统环境变量vim /etc/profile尾部追加 123export ZOOKEEPER_HOME=/software/zookeeper-3.4.10/export PATH=$ZOOKEEPER_HOME/bin:$PATHexport PATH 输入source /etc/profile重新加载系统环境变量 修改zookeeper配置文件1234[root@server28 zookeeper-3.4.10]# cd conf/[root@server28 conf]# cp zoo_sample.cfg zoo.cfg[root@server28 conf]# lsconfiguration.xsl log4j.properties zoo.cfg zoo_sample.cfg 修改zoo.cfg 1234567891011121314# 服务器与客户端之间交互的基本时间单元（ms）tickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# 配置保存数据文件夹dataDir=/software/zookeeper-3.4.10/data# 配置保存日志文件夹，当此配置不存在时默认路径与dataDir一致dataLogDir=/software/zookeeper-3.4.10/logs# 客户端访问zookeeper的端口号clientPort=2181 启动、关闭zookeeper 启动服务 1234[root@server28 bin]# ./zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /software/zookeeper-3.4.10/bin/../conf/zoo.cfgStarting zookeeper ... STARTED 关闭服务 1234[root@server28 bin]# ./zkServer.sh stopZooKeeper JMX enabled by defaultUsing config: /software/zookeeper-3.4.10/bin/../conf/zoo.cfgStopping zookeeper ... STOPPED 重启服务 123456789[root@server28 bin]# ./zkServer.sh restartZooKeeper JMX enabled by defaultUsing config: /software/zookeeper-3.4.10/bin/../conf/zoo.cfgZooKeeper JMX enabled by defaultUsing config: /software/zookeeper-3.4.10/bin/../conf/zoo.cfgStopping zookeeper ... STOPPEDZooKeeper JMX enabled by defaultUsing config: /software/zookeeper-3.4.10/bin/../conf/zoo.cfgStarting zookeeper ... STARTED 解压kafka安装包1234tar -zxvf kafka_2.11-0.10.1.1.tgzmv kafka_2.11-0.10.1.1 kafkacd kafkacp config/server.properties bin 启动kafka服务12# 后台启动[root@server28 bin]# ./kafka-server-start.sh -daemon server.properties 检查12345[root@server28 bin]# jps31523 Jps1332 jenkins.war31032 QuorumPeerMain31224 Kafka 删除Topic删除Kafka的topic12341.如果kafka启动时加载的配置文件server.properties没有配置delete.topic.enable = true这条命令并不执行删除动作，仅仅是在zookeeper上标记该topic要被删除，需要往下执行.[root@server28 bin]# ./kafka-topics.sh -delete -zookeeper 192.168.103.28:2181 -topic mic-serviceTopic mic-service is already marked for deletion.2.从kafka manager去删除 stop Kafka12345[root@server28 bin]# ./kafka-server-stop.sh server.properties[root@server28 bin]# jps23792 Jps1332 jenkins.war31032 QuorumPeerMain 删除Kafka的log123在配置文件找到kafka日志目录并删除对应目录，这里是全部清空[root@server28 tmp]# cd kafka-logs/[root@server28 tmp]# rm -rf * 删除Zookeeper下节点123456[root@server28 bin]# zkCli.sh -server 192.168.103.28:2181[zk: 192.168.103.28:2181(CONNECTED) 0] rmr /admin/delete_topics/mic-service[zk: 192.168.103.28:2181(CONNECTED) 1] rmr /brokers/topics/mic-service[zk: 192.168.103.28:2181(CONNECTED) 2] rmr /config/topics/mic-service[zk: 192.168.103.28:2181(CONNECTED) 3] ls /admin/delete_topics[] 我的博客即将搬运同步至腾讯云+社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=3jvl2yjjxbk04]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis 集群规范]]></title>
      <url>%2F2018%2Fdatabase-redis-cluster-spec%2F</url>
      <content type="text"><![CDATA[摘要:参考官方文档Redis Cluster spec总结的Redis规范 正文:Redis 集群规范安全写入两个写入丢失的可能 写入操作到达主节点，主节点异步冗余备份还没传播到从节点时候主节点挂了，该写入会丢失 几率很小，虽然是异步备份，但主节点写入并回复客户端的时间和传播给slave节点时间大致相同 故障转移时候，一个没有更新路由表的客户端会在主–&gt;从之前做写入操作（几率更小） 原因：长时间无法被大多数主节点访问的节点会被故障转移掉，不再接受任何写入操作，其修复好后仍然会有一小段时间拒绝写入。好让其他节点有时间去告知配置信息的变更 可用性根据redis选举机制，高可用需要至少3台服务器(3个master节点)，每个master节点都至少要有一个salve节点可达，最好是从节点数量&gt;主节点数量 master遇到故障转移到slave后，集群会再次恢复可用 master故障修复后会重新加入集群成为新master的从节点，防止下次故障 当从节点有两个就可以多一次故障转移 性能在Redis的集群中，节点并不是把命令转发到负责键的节点上，而是把客户端重定向到服务一定范围内的键的节点上。 最终客户端获得一份最新的集群路由表，里面有写着哪些节点服务哪些键，所以在正常操作中客户端是直接联系到对应的节点来发送指令。 由于使用了异步复制，节点不会等待其他节点对写入操作的回复 所以普通操作是可以被处理得跟在Redis单机版一样的，在一个拥有 N 个master节点的 Redis 集群中，由于线性扩展的设计，你可以认为同样的操作在集群上的性能是Redis单机版的n倍 键分布模型Redis 集群的键空间被分割为 16384 个槽（slot）， 集群的最大节点数量也是 16384 个。 推荐的最大节点数量为 1000 个左右。 每个主节点都负责处理 16384 个哈希槽的其中一部分。 参考链接Redis Cluster Spec Redis 集群规范]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis 集群部署]]></title>
      <url>%2F2018%2Fdatabase-redis-cluster%2F</url>
      <content type="text"><![CDATA[摘要:最近工作搭建redis集群时候的笔记 正文:Redis集群搭建版本 系统: CentOS 7.4 Redis: redis-4.0.2 ruby: 2.4.2 安装gcc1234rpm -ivh gcc-c++-4.8.5-16.el7.x86_64.rpm --nodepsPreparing... ################################# [100%]Updating / installing... 1:gcc-c++-4.8.5-16.el7 ################################# [100%] 安装Redis1234cd /opt tar xzf redis-4.0.2.tar.gzcd redis-4.0.2make 如果因为编译失败可以使用make distclean 创建节点 创建redis-cluster目录 123mkdir /opt/redis-4.0.2/redis-clustercd /opt/redis-4.0.2/redis-clustermkdir 7100 7101 7102 分别修改这三个配置文件，把如下redis.conf 配置内容粘贴进去 123vi 7100/redis.confvi 7101/redis.conf vi 7102/redis.conf redis.conf 12345678port 7100bind 192.168.103.14daemonize yespidfile /var/run/redis_7100.pidcluster-enabled yescluster-config-file nodes_7100.confcluster-node-timeout 20100appendonly yes 配置说明 1234567891011121314151617181920212223#端口7100,7101,7102port 7100#默认ip为127.0.0.1，需要改为其他节点机器可访问的ip，否则创建集群时无法访问对应的端口，无法创建集群bind 192.168.103.14#redis后台运行daemonize yes#pidfile文件对应7100，7101，7102pidfile /var/run/redis_7100.pid#开启集群，把注释#去掉cluster-enabled yes#集群的配置，配置文件首次启动自动生成 7100，7101，7102 cluster-config-file nodes_7100.conf#请求超时，默认15秒，可自行设置 cluster-node-timeout 20100 #aof日志开启，有需要就开启，它会每次写操作都记录一条日志appendonly yes 在另外一台机器上重复以上操作，目录和端口改为7103、7104、7105 启动集群12345# 第一台机器上执行 3个节点for((i=0;i&lt;=2;i++)); do /opt/redis-4.0.2/src/redis-server /opt/redis-4.0.2/redis-cluster/710$i/redis.conf; done#第二台机器上执行 3个节点for((i=3;i&lt;=5;i++)); do /opt/redis-4.0.2/src/redis-server /opt/redis-4.0.2/redis-cluster/710$i/redis.conf; done 检查服务12ps -ef | grep redis //redis是否启动成功netstat -tnlp | grep redis //监听redis端口 搭建集群现在我们已经有了六个正在运行中的 Redis 实例，通过使用 Redis 集群命令行工具 redis-trib ， 编写节点配置文件的工作可以非常容易地完成： redis-trib 位于 Redis 源码的 src 文件夹中， 它是一个 Ruby 程序， 这个程序通过向实例发送特殊命令来完成创建新集群， 检查集群， 或者对集群进行重新分片（reshared）等工作。所以我们先来安装ruby。 安装ruby通过yum安装的ruby往往版本较低，这里使用安装包安装 下载地址 12345tar -xvzf ruby-2.4.2.tar.gzcd ruby-2.4.2./configuremakesudo make install 安装完成后，可以查看是否安装成功，若遇到没有输出版本可以重新打开命令窗口试试 1ruby -v 接下来我们安装redis依赖 1gem install redis 创建集群接下来我们使用 Redis 集群命令行工具 redis-trib，在其中一台机器上运行如下命令 1/opt/redis-4.0.2/src/redis-trib.rb create --replicas 1 192.168.103.14:7100 192.168.103.14:7101 192.168.103.14:7102 192.168.103.28:7103 192.168.103.28:7104 192.168.103.28:7105 会出现如下内容 12345678910111213141516171819202122&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:192.168.103.14:7100192.168.103.28:7103192.168.103.14:7101Adding replica 192.168.103.28:7104 to 192.168.103.14:7100Adding replica 192.168.103.14:7102 to 192.168.103.28:7103Adding replica 192.168.103.28:7105 to 192.168.103.14:7101M: c190d12629fd227c909caa96f5e978ff996364ed 192.168.103.14:7100 slots:0-5460 (5461 slots) masterM: 77ea96b2eb31b0dd44acc986fe8484358cd9863f 192.168.103.14:7101 slots:10923-16383 (5461 slots) masterS: b08c0a2e59ef7564eeda7f8d7ca08ec7f3766c1d 192.168.103.14:7102 replicates 76d59f4caaf766bea9122b1e6327e13721c8ca3bM: 76d59f4caaf766bea9122b1e6327e13721c8ca3b 192.168.103.28:7103 slots:5461-10922 (5462 slots) masterS: 77abb939328acb2198fe3e4a495c217d25b91cda 192.168.103.28:7104 replicates c190d12629fd227c909caa96f5e978ff996364edS: 82f48a3c8d0d684fe31254fd4115d8c3b5622f4e 192.168.103.28:7105 replicates 77ea96b2eb31b0dd44acc986fe8484358cd9863fCan I set the above configuration? (type 'yes' to accept): yes 输入yes继续 123456789101112131415161718192021222324252627&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join....&gt;&gt;&gt; Performing Cluster Check (using node 192.168.103.14:7100)M: c190d12629fd227c909caa96f5e978ff996364ed 192.168.103.14:7100 slots:0-5460 (5461 slots) master 1 additional replica(s)M: 77ea96b2eb31b0dd44acc986fe8484358cd9863f 192.168.103.14:7101 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: 82f48a3c8d0d684fe31254fd4115d8c3b5622f4e 192.168.103.28:7105 slots: (0 slots) slave replicates 77ea96b2eb31b0dd44acc986fe8484358cd9863fS: b08c0a2e59ef7564eeda7f8d7ca08ec7f3766c1d 192.168.103.14:7102 slots: (0 slots) slave replicates 76d59f4caaf766bea9122b1e6327e13721c8ca3bM: 76d59f4caaf766bea9122b1e6327e13721c8ca3b 192.168.103.28:7103 slots:5461-10922 (5462 slots) master 1 additional replica(s)S: 77abb939328acb2198fe3e4a495c217d25b91cda 192.168.103.28:7104 slots: (0 slots) slave replicates c190d12629fd227c909caa96f5e978ff996364ed[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 可以看到master节点分别是14:7100(0-5460)、14:7101(10923-16383)、28:7103(5461-10922)，salve节点分别是28:7150 、14:7102 、28:7104 对应关系可以根据上面可以看到分别是3主3从 若输入yes后出现 12345678910111213Can I set the above configuration? (type 'yes' to accept): yes/usr/local/lib/ruby/gems/2.4.0/gems/redis-4.0.1/lib/redis/client.rb:119:in `call': ERR Slot 5798 is already busy (Redis::CommandError) from /usr/local/lib/ruby/gems/2.4.0/gems/redis-4.0.1/lib/redis.rb:2764:in `block in method_missing' from /usr/local/lib/ruby/gems/2.4.0/gems/redis-4.0.1/lib/redis.rb:45:in `block in synchronize' from /usr/local/lib/ruby/2.4.0/monitor.rb:214:in `mon_synchronize' from /usr/local/lib/ruby/gems/2.4.0/gems/redis-4.0.1/lib/redis.rb:45:in `synchronize' from /usr/local/lib/ruby/gems/2.4.0/gems/redis-4.0.1/lib/redis.rb:2763:in `method_missing' from /opt/redis-4.0.2/src/redis-trib.rb:212:in `flush_node_config' from /opt/redis-4.0.2/src/redis-trib.rb:776:in `block in flush_nodes_config' from /opt/redis-4.0.2/src/redis-trib.rb:775:in `each' from /opt/redis-4.0.2/src/redis-trib.rb:775:in `flush_nodes_config' from /opt/redis-4.0.2/src/redis-trib.rb:1296:in `create_cluster_cmd' from /opt/redis-4.0.2/src/redis-trib.rb:1700:in `&lt;main&gt;' 解决办法 1234567891011121314# 每个节点执行以下命令,然后重新执行创建集群命令/opt/redis-4.0.2/src/redis-cli -h 192.168.103.14 -p 7100192.168.103.14:7100&gt; flushallOK192.168.103.14:7100&gt; cluster reset softOK192.168.103.14:7100&gt; exit.../opt/redis-4.0.2/src/redis-cli -h 192.168.103.28 -p 7103192.168.103.28:7103&gt; flushallOK192.168.103.28:7103&gt; cluster reset softOK192.168.103.28:7103&gt; exit 集群验证连接集群测试1234567891011121314# 选择一个节点set值/opt/redis-4.0.2/src/redis-cli -c -h 192.168.103.28 -p 7104192.168.103.28:7104&gt; set name admin-&gt; Redirected to slot [5798] located at 192.168.103.28:7103OK192.168.103.28:7103&gt; get name"admin"192.168.103.28:7103&gt; exit# 换个节点测试[root@server28 /]# /opt/redis-4.0.2/src/redis-cli -c -h 192.168.103.14 -p 7101192.168.103.14:7101&gt; get name-&gt; Redirected to slot [5798] located at 192.168.103.28:7103"admin"192.168.103.28:7103&gt; exit 可以发现name &quot;admin&quot;被放置在28:7103主节点上，槽位是(5461-10922) 注: Redis 集群没有使用一致性hash, 而是引入了 哈希槽的概念. Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽.集群的每个节点负责一部分hash槽,举个例子,比如当前集群有3个节点,那么: 节点 A 包含 0 到 5500号哈希槽. 节点 B 包含5501 到 11000 号哈希槽. 节点 C 包含11001 到 16384号哈希槽. 这种结构很容易添加或者删除节点. 比如如果我想新添加个节点D, 我需要从节点 A, B, C中得部分槽到D上. 如果我想移除节点A,需要将A中的槽移到B和C节点上,然后将没有任何槽的A节点从集群中移除即可. 由于从一个节点将哈希槽移动到另一个节点并不会停止服务,所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态. 检查集群状态1234567891011121314151617181920/opt/redis-4.0.2/src/redis-trib.rb check 192.168.103.14:7100&gt;&gt;&gt; Performing Cluster Check (using node 192.168.103.14:7100)M: c190d12629fd227c909caa96f5e978ff996364ed 192.168.103.14:7100 slots:0-5460 (5461 slots) master 1 additional replica(s)M: 77ea96b2eb31b0dd44acc986fe8484358cd9863f 192.168.103.14:7101 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: 82f48a3c8d0d684fe31254fd4115d8c3b5622f4e 192.168.103.28:7105 slots: (0 slots) slave replicates 77ea96b2eb31b0dd44acc986fe8484358cd9863fS: b08c0a2e59ef7564eeda7f8d7ca08ec7f3766c1d 192.168.103.14:7102 slots: (0 slots) slave replicates 76d59f4caaf766bea9122b1e6327e13721c8ca3bM: 76d59f4caaf766bea9122b1e6327e13721c8ca3b 192.168.103.28:7103 slots:5461-10922 (5462 slots) master 1 additional replica(s)S: 77abb939328acb2198fe3e4a495c217d25b91cda 192.168.103.28:7104 slots: (0 slots) slave replicates c190d12629fd227c909caa96f5e978ff996364ed 列出集群节点12345678/opt/redis-4.0.2/src/redis-cli -c -h 192.168.103.14 -p 7101192.168.103.14:7101&gt; cluster nodes77abb939328acb2198fe3e4a495c217d25b91cda 192.168.103.28:7104@17104 slave c190d12629fd227c909caa96f5e978ff996364ed 0 1523435804915 5 connected76d59f4caaf766bea9122b1e6327e13721c8ca3b 192.168.103.28:7103@17103 master - 0 1523435804000 4 connected 5461-1092282f48a3c8d0d684fe31254fd4115d8c3b5622f4e 192.168.103.28:7105@17105 slave 77ea96b2eb31b0dd44acc986fe8484358cd9863f 0 1523435805918 6 connectedb08c0a2e59ef7564eeda7f8d7ca08ec7f3766c1d 192.168.103.14:7102@17102 slave 76d59f4caaf766bea9122b1e6327e13721c8ca3b 0 1523435803000 4 connected77ea96b2eb31b0dd44acc986fe8484358cd9863f 192.168.103.14:7101@17101 myself,master - 0 1523435803000 2 connected 10923-16383c190d12629fd227c909caa96f5e978ff996364ed 192.168.103.14:7100@17100 master - 0 1523435806920 1 connected 0-5460 打印集群信息123456789101112131415161718192.168.103.14:7101&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:2cluster_stats_messages_ping_sent:1605cluster_stats_messages_pong_sent:1682cluster_stats_messages_meet_sent:5cluster_stats_messages_sent:3292cluster_stats_messages_ping_received:1681cluster_stats_messages_pong_received:1610cluster_stats_messages_meet_received:1cluster_stats_messages_received:3292 节点cluster meet &lt;ip&gt; &lt;port&gt;将 ip 和 port 所指定的节点添加到集群当中 cluster forget &lt;node_id&gt; 从集群中移除 node_id 指定的节点 123456789101112192.168.103.14:7100&gt; cluster meet 192.168.103.28 7106OK192.168.103.14:7100&gt; cluster nodes047f60047efa74c6f597e935b8b5896c15057cf6 192.168.103.28:7106@17106 master - 0 1523448401000 0 connected77ea96b2eb31b0dd44acc986fe8484358cd9863f 192.168.103.14:7101@17101 master - 0 1523448401961 2 connected 10923-1638382f48a3c8d0d684fe31254fd4115d8c3b5622f4e 192.168.103.28:7105@17105 slave 77ea96b2eb31b0dd44acc986fe8484358cd9863f 0 1523448402964 6 connectedb08c0a2e59ef7564eeda7f8d7ca08ec7f3766c1d 192.168.103.14:7102@17102 slave 76d59f4caaf766bea9122b1e6327e13721c8ca3b 0 1523448403965 4 connected76d59f4caaf766bea9122b1e6327e13721c8ca3b 192.168.103.28:7103@17103 master - 0 1523448402000 4 connected 5461-1092277abb939328acb2198fe3e4a495c217d25b91cda 192.168.103.28:7104@17104 slave c190d12629fd227c909caa96f5e978ff996364ed 0 1523448404969 5 connectedc190d12629fd227c909caa96f5e978ff996364ed 192.168.103.14:7100@17100 myself,master - 0 1523448401000 1 connected 0-5460192.168.103.14:7100&gt; cluster forget 047f60047efa74c6f597e935b8b5896c15057cf6OK cluster nodes命令的结果含义如下： 节点ID IP:端口 标志: master, slave, myself, fail, … 如果是个从节点, 这里是它的主节点的NODE ID 集群最近一次向节点发送 PING 命令之后， 过去了多长时间还没接到回复。. 节点最近一次返回 PONG 回复的时间。 节点的配置纪元（configuration epoch）：详细信息请参考 Redis 集群规范 。 本节点的网络连接情况：例如 connected 。 节点目前包含的槽：例如 192.168.103.28:7103 目前包含号码为 5960 至 10921 的哈希槽。 使用redis-trib.rb 新增节点 添加master节点 1/opt/redis-4.0.2/src/redis-trib.rb add-node 192.168.103.28:7106 192.168.103.14:7100 添加salve节点(随机选一个主节点),前提是节点要为空 1/opt/redis-4.0.2/src/redis-trib.rb add-node --slave 192.168.103.28:7106 192.168.103.14:7100 添加salve节点(指定主节点为192.168.103.14:7101) 1/opt/redis-4.0.2/src/redis-trib.rb add-node --slave --master-id 77ea96b2eb31b0dd44acc986fe8484358cd9863f 192.168.103.28:7106 192.168.103.14:7100 ​ 也可以使用cluster replicate 1192.168.103.28:7106&gt; cluster replicate 77ea96b2eb31b0dd44acc986fe8484358cd9863f 使用redis-trib.rb 移除节点 1/opt/redis-4.0.2/src/redis-trib.rb del-node 192.168.103.14:7100 `&lt;node-id&gt;` 参考链接CentOs7.3 搭建 Redis-4.0.1 Cluster 集群服务 Redis 集群教程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Cloud Netflix OSS 学习总结]]></title>
      <url>%2F2018%2FSpringCloud-Netflix%2F</url>
      <content type="text"><![CDATA[摘要: 本篇博客是使用SpringCloud框架开发微服务时候的一篇技术分享 正文:Spring Cloud Netflix OSS提供了对Netflix开源项目的集成，使我们可以以Spring Boot编程风格使用Netflix旗下相关框架，只需要在程序里添加注解，就可以使用成熟的Netflix组件(Eureka、Hystrix、Zuul、Ribbon、Sidecar) Spring Cloud EurekaEureka客户端 向Eureka注册服务 高可用(HA) 多注册中心主机 如果配置了多个Eureka注册服务器，那么默认情况只有一台可用的服务器，存在注册信息。如果Down掉了，则会选择下一台可用的Eureka服务器。 配置 应用间隔 registry-fetch-interval-seconds:30 去服务端获取注册信息的间隔时间 同步间隔 instance-info-replication-interval-seconds:30 更新实例信息的变化到服务端的间隔时间 参考链接 注意 端口不要使用0 Eureka缓存 Eureka Server对注册列表进行缓存，默认时间为30s。 Eureka Client对获取到的注册信息进行缓存，默认时间为30s。 Ribbon会从上面提到的Eureka Client获取服务列表，将负载均衡后的结果缓存30s。 Eureka服务端 注册中心对比 Feature Consul zookeeper etcd euerka 服务健康检查 服务状态，内存，硬盘等 (弱)长连接，keepalive 连接心跳 可配支持 多数据中心 支持 — — — kv存储服务 支持 支持 支持 — 一致性 raft paxos raft — cap ca cp cp ap 使用接口(多语言能力) 支持http和dns 客户端 http/grpc http（sidecar） watch支持 全量/支持long polling 支持 支持 long polling 支持 long polling/大部分增量 自身监控 metrics — metrics metrics 安全 acl /https acl https支持（弱） — spring cloud集成 已支持 已支持 已支持 已支持 CAP C 数据一致性 一致性是指数据的原子性，在经典的数据库中通过事务来保障，事务完成时，无论成功或回滚，数据都会处于一致的状态，在分布式环境下，一致性是指多个节点数据是否一致 raft A 服务可用性 服务一直保持可用的状态，当用户发出一个请求，服务能在一定的时间内返回结果 P 网络分区故障的容错性 在分布式应用中，可能因为一些分布式的原因导致系统无法运转，好的分区容忍性，使应用虽然是一个分布式系统，但是好像一个可以正常运转的整体 Consul 服务发现 健康检查 键值存储 多数据中心 官网 Spring Cloud Consul 参考文档 Eureka Server高可用配置 12345678910111213141516171819---spring: profiles: peer1eureka: instance: hostname: peer1 client: serviceUrl: defaultZone: http://peer2/eureka/---spring: profiles: peer2eureka: instance: hostname: peer2 client: serviceUrl: defaultZone: http://peer1/eureka/ 参考文档 Spring Cloud Ribbon主要功能是为REST客户端实现负载均衡 Netflix Ribbon 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; Ribbon 客户端 12345678910@SpringBootApplication@RibbonClients(&#123; @RibbonClient(name = "service-provider")&#125;)public class Application &#123; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 配置 application.properties 12service-provider.ribbon.listOfServers = \ http://$&#123;host&#125;:$&#123;port&#125; Netflix Ribbon 整合 Eureka Ribbon 客户端 123456789101112@SpringBootApplication@RibbonClients(&#123; @RibbonClient(name = "service-provider")&#125;)@EnableDiscoveryClientpublic class Application &#123; @Bean @LoadBalanced public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 配置 Spring Cloud OpenFeign 发展 9.0.0版本之后groupId io.netflix.feign更改为io.github.openfeign 对应依赖spring-cloud-starter-feign–&gt;spring-cloud-starter-openfeign 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt; feign 客户端 Application.java 123456789@SpringBootApplication@EnableFeignClientspublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; feignClient.java 12345@FeignClient(value = "ms-business-task-engine-server")public interface ITaskEngineService &#123; @RequestMapping(value = "/TaskQueue/addTaskToQueue",method = RequestMethod.POST) BaseResponse addTaskToQueue(@RequestBody List&lt;SubTaskDTO&gt; subTaskDTOList);&#125; 配置参考ribbon Spring Cloud Hystrixhystrix可帮助隔离每个服务，使单个服务的响应失败，避免微服务架构中因个别服务出现异常而引起级联故障蔓延。 特性 断路器机制(断路–&gt;半开–&gt;恢复) 资源隔离 熔断降级 Hystrix Dashboard 监控Spring Cloud Zuul在没有网关的时候，随着系统不断庞大，运维维护越来越复杂，接口校验逻辑的冗余越来越多，校验逻辑升级更为复杂。 ZuulFilter过滤器类型 pre 路由之前执行 route 路由请求时被调用 post 在route和error过滤器之后被过滤 error 处理请求发生错误时候被调用 过滤器执行顺序 order越小，优先级越高 过滤器是否被执行 shouldFilter = true(结合yaml控制开启) 过滤器具体逻辑 run() Routes路由规则与列表 Spring Cloud Sidecar非JVM语言接入SpringCloud的两种方案 Sidecar 必须去实现一个健康检查接口 只有状态，服务治理只能从网关层控制流量 自己实现注册中心API Http接口(推荐) 示例代码-github]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK8的ConcurrentHashMap源码学习笔记]]></title>
      <url>%2F2018%2Fjavase-Map-ConcurrentHashMap%2F</url>
      <content type="text"><![CDATA[摘要:继上篇HashMap分析后，接下来分析ConcurrentHashMap的put和扩容… 正文:目标 首要目标:保持并发的可读性,同时最小化更新产生的竞争 次要目标:保持与HashMap相同或更好的空间消耗,并支持许多线程在空表上的高初始插入率。 设计 使用CAS代替之前版本的分段锁 红黑树 putVal()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178/** * sizeCtl：表初始化和调整控制。当负值时，表被初始化或调整大小:-1用于初始化，-(1 +主动调整大小的线程数)用于调整大小，默认为0。初始化完成后，保存下一个元素count值，以调整表的大小。 */private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; //volatile读 while ((tab = table) == null || tab.length == 0) &#123; //如果一个线程发现sizeCtl&lt;0，意味着另外的线程执行CAS操作成功，当前线程只需要让出cpu时间片 //volatile读 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin //第一次put操作的线程会执行Unsafe.compareAndSwapInt方法修改sizeCtl为-1，有且只有一个线程能够修改成功，其它线程通过Thread.yield()让出CPU时间片等待table初始化完成 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125;/** * 使用Unsafe.getObjectVolatile()获取数组元素，原因是Java数组是无法表达元素是volatile、final的 */final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) //初始化 tab = initTable(); //为空，则设置为头节点(CAS) else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; //节点添加 V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; //达到阈值转为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125;/** * 如果当前table的个数未达到MIN_TREEIFY_CAPACITY(64)则先进行扩容 */private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) tryPresize(n &lt;&lt; 1); else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; synchronized (b) &#123; if (tabAt(tab, index) == b) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &#125; setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125;&#125;/** * 扩容(size = 2n) */private final void tryPresize(int size) &#123; //size如果大于max(Int)/2 则直接扩为max(Int),否则为大于3*size + 1的最小二次幂 int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; //volatile读，sizeCtl大于0指没有进行初始化和扩容的操作 while ((sc = sizeCtl) &gt;= 0) &#123; Node&lt;K,V&gt;[] tab = table; int n; if (tab == null || (n = tab.length) == 0) &#123; n = (sc &gt; c) ? sc : c; //执行Unsafe.compareAndSwapInt方法修改sizeCtl为-1，有且只有一个线程能够修改成功，其它线程通过Thread.yield()让出CPU时间片等待table初始化完成 if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; @SuppressWarnings("unchecked") //初始化 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; &#125; &#125; //最大了 else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; else if (tab == table) &#123; int rs = resizeStamp(n); if (sc &lt; 0) &#123; //竞争失败 Node&lt;K,V&gt;[] nt; //正在咨询大佬... if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; //竞争成功 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); &#125; &#125;&#125; transfer()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; //分片 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range //nextTab初始化(CAS保证只有一个线程调用此方法) if (nextTab == null) &#123; // initiating try &#123; //根据当前数组长度n，新建一个两倍长度的数组nextTable @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; //初始化ForwardingNode(nextTab) 用于并发移动时，其它线程可以知道这个节点正在被移动，或已经被移动 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; //循环的关键变量，判断是否已经扩容完成，完成就return，退出循环 boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; while (advance) &#123; int nextIndex, nextBound; //i指当前处理的槽位序号，bound指需要处理的槽位边界 if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; nextTable = null; table = nextTab; //sizeCtl设为新数组大小的3/4(2n-n/2) sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; //resizeStamp()没看懂 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) &#123; //使用fn&amp;n可以快速把链表中的元素分为两份 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; //放到新Tab setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); //红黑树同样是根据h&amp;n分为两份 if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; //拆分之后如果长度小于默认阈值(6)则转为链表 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; //设置新的Tab setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125; HashMap vs ConcurrentHashMap ConcurrentHashMap是线程安全的，在并发环境下不需要额外同步 ConcurrentHashMap有很好的扩展性，在多线程环境下性能方面比做了同步的HashMap要好，但是在单线程环境下，HashMap会比ConcurrentHashMap好一点 参考链接 深入分析ConcurrentHashMap1.8的扩容实现 seaswalker/JDK 晚安~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK8的HashMap源码学习笔记]]></title>
      <url>%2F2018%2Fjavase-Map-HashMap%2F</url>
      <content type="text"><![CDATA[摘要:接下来开始学习JDK常用类的源码部分，从HashMap开始…. 正文:概念HashMap是数组+链表+红黑树实现的，红黑树是在JDK8中增加的，优化了链表过长的效率问题 泊松分布HashMap源码注释有提到这个概念，泊松分布是单位时间内独立事件发生次数的概率分布，指数分布是独立事件的时间间隔的概率分布，可以参考阮一峰泊松分布博客 设计方法参数 都会带hash值作为参数(通常由公共参数提供)，允许它们彼此调用而无需重新计算用户哈希代码。 全局变量1234567static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 默认初始容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //最大容量(超出则扩为(2^31)-1)static final float DEFAULT_LOAD_FACTOR = 0.75f; //默认加载因子static final int TREEIFY_THRESHOLD = 8; //转树的阈值static final int MIN_TREEIFY_CAPACITY = 64; //当桶数组容量小于该值时，优先进行扩容，而不是树化(容量大小会影响碰撞率)static final int UNTREEIFY_THRESHOLD = 6; //红黑树转链表阈值(扩容时候红黑树拆分用到)int threshold; //当前HashMap所能容纳键值对数量的最大值 算threshold的方法： 123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; tableSizeFor()方法作用是算出大于或等于cap的最小2的幂，如2^5+1的结果则是2^6也就是64 hash()方法1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 可以看到在JDK8的实现中，优化了高位运算的算法，自己的高半区和低半区做异或，减少了低位的碰撞率。 putVal()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //初始化buckets table+为null扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //位置为null直接插入新的节点 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //如果hash值相同并且key相同则直接覆盖 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //判断该链是不是红黑树，是的话走Tree版本的putVal else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //否则则是链表 else &#123; for (int binCount = 0; ; ++binCount) &#123; //如果下个节点为空则放入下个节点 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //链表长度大于8转换为红黑树进行处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //覆盖 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //超出当前容量最大值就扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; resize()方法我们先来看下扩容机制，在HashMap中元素位置都是2的幂，接下来我们来看具体代码实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; //如果当前容量大于默认值2^30，则扩容至2^31-1 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //double else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //initial capacity else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //默认构造方法初始化Cap else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //newThr 为 0 时，按阈值计算公式进行计算 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; //把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) //对红黑树进行拆分 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; //遍历链表 do &#123; next = e.next; //原位置(根据0和非0判断是否扩容) if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; //原位置+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); //原位置的放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; //原位置+oldCap的放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; split()方法该方法是红黑树拆分方法，普通链表需要拆分，红黑树也同样需要拆分 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; //对红黑树节点进行分组(同链表一个原理) for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; if (loHead != null) &#123; //如果 loHead 不为空，且链表长度小于等于 6，则将红黑树转成链表 if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; //原位置的放到bucket里 tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; //原位置+oldCap的放到bucket里 tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125;&#125; untreeify()方法此方法是将红黑树转为链表 1234567891011121314151617final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; //转为Node Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd;&#125;Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(p.hash, p.key, p.value, next);&#125; 晚安~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[XXL-JOB使用笔记]]></title>
      <url>%2F2018%2Fscheduler-xxl-job%2F</url>
      <content type="text"><![CDATA[摘要:XXL-JOB是一个轻量级分布式任务调度框架，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用正文: XXL-JOB的介绍XXL-JOB是一个轻量级分布式任务调度框架，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用 XXL-JOB快速入门文档地址 中文文档 English Documentation 下载源码 源码仓库地址 Release Download https://github.com/xuxueli/xxl-job Download http://gitee.com/xuxueli0323/xxl-job Download 配置部署”调度中心”初始化“调度数据库”1xxl-job\doc\db\tables_xxl_job.sql 修改数据库配置信息1xxl-job\xxl-job-admin\src\main\resources\xxl-job-admin.properties 打包在xxl-job根目录下执行 1mvn clean package 部署“调度中心” 找到xxl-job-admin的target目录 1xxl-job\xxl-job-admin\target\xxl-job-admin-1.9.1-SNAPSHOT.war 更改名字为xxl-job-admin.war,放在tomcat的webapps下,在bin文件夹双击执行startup.bat 访问http://localhost:8080/xxl-job-admin 登录(密码在xxl-job-admin.properties)后界面如下图所示: Docker部署”调度中心” PreBuild.sh 123#!/bin/bashdocker rm -f $(docker ps -a | grep "tomcat/xxl-job-admim"| awk '&#123; print $1 &#125;') &gt;/dev/null 2&gt;&amp;1docker rmi -f tomcat/xxl-job-admim &gt;/dev/null 2&gt;&amp;1 Dockerfile 12345678FROM tomcat:8## db设置为获取环境变量 方便动态传参ENV driverClass com.mysql.jdbc.DriverENV url jdbc:mysql://localhost:3306/xxl-job?useUnicode=true&amp;characterEncoding=UTF-8ENV user rootENV password rootADD xxl-job-admin.war /usr/local/tomcat/webapps/CMD ["catalina.sh", "run"] Dockerbuild.sh 1docker build -t tomcat/xxl-job-admim . DockerRun.sh 1docker run --restart=always -d -p 8997:8080 tomcat/xxl-job-admim &gt;/dev/null 2&gt;&amp;1 配置部署“执行器项目”参考官方Demo1xxl-job\xxl-job-executor-samples\xxl-job-executor-sample-springboot 在根目录 mvn clean package然后执行java -jar xxx.jar或者IDE启动SpringBoot 页面配置 新增执行器 打开“调度中心”的执行器管理，发现有一个默认的，AppName正对应xxl-job-executor-sample-springboot服务配置的xxl.job.executor.appname，此时可以使用默认的无需添加。 新增任务 打开”调度中心”的任务管理，点击新增任务： 配置参考如下配置，JobHandler填写xxl-job-executor-sample-springboot的DemoJobHandler.java类上的@JobHandler(value=&quot;demoJobHandler&quot;)value值，Cron表达式可以参考在线Cron表达式生成器 保存成功后点击执行按钮 查看日志点击任务右侧的日志按钮，可以查看该任务的日志： 点击执行日志可以看到当前执行的log,对应xxl-job-executor-sample-springbootDemo的DemoJobHandler.java的代码:]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Validator 使用总结]]></title>
      <url>%2F2018%2Fframe-validator%2F</url>
      <content type="text"><![CDATA[摘要:祝大家元旦快乐！在日常开发中，前台对参数校验后，为了避免用户直接使用http工具直接向后台发起不合法请求，后台往往也需要校验，本文将要介绍的是使用Validator对数据进行校验。 正文:介绍首先说下大家常用的hibernate-validator，它是对JSR-303/JSR-349标准的实现，然后spring为了给开发者提供便捷集成了 hibernate-validator，默认在springmvc模块。 依赖本文所介绍皆在springboot应用的基础上，首先加上web模块： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 可以查看其子依赖，发现web模块默认使用了hibernate-validator： 1234567891011121314151617181920&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;&lt;/dependency&gt; 对实体类添加校验1234567891011121314151617181920212223242526public class AgentTrustor implements Serializable,UniqueVerifiableVO &#123; private static final long serialVersionUID = 4095871718305603749L; /** * 主键ID */ @Id @ApiModelProperty(value="主键ID", required = true) private Integer fid; /** * 代理人代码 */ @Length(min = 3,message = "代理人代码位数至少三位") @Column(name = "ftrustor_id") @ApiModelProperty(value="代理人代码", required = true) private String ftrustorId; /** * 联系人邮箱 */ @Email(message = "邮箱格式错误") @Column(name = "femail") @ApiModelProperty(value="联系人邮箱", required = true) private String femail;&#125; 通过注释名即可推断出校验的内容，message用作校验失败时的提示信息。 对Rest层添加校验1234567@ApiOperation(value="新增", notes="") @PostMapping(value = "") //@Transactional(rollbackFor=Exception.class) public ObjectRestResponse&lt;AgentTrustor&gt; add(@RequestBody @Validated AgentTrustor agentTrustor) throws BaseException&#123; agentTrustorBiz.bizInsertSelective(agentTrustor); return new ObjectRestResponse&lt;AgentTrustor&gt;().rel(true); &#125; 统一异常的处理经过对校验异常的debug发现，该异常为MethodArgumentNotValidException： 可以看到该异常对象的结构，同样我们可以根据其结构解析出想要的结果： 12345678910111213@ExceptionHandler(MethodArgumentNotValidException.class) public BaseResponse validExceptionHandler(HttpServletResponse response, MethodArgumentNotValidException ex) &#123; BindingResult bindingResult = ex.getBindingResult(); StringBuffer stringBuffer = new StringBuffer(); if(bindingResult.hasErrors())&#123; for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; //该格式仅仅作为response展示和log作用，前端应自己做校验 stringBuffer.append(fieldError.getObjectName() + "--" + fieldError.getDefaultMessage() + " "); &#125; &#125; logger.error(stringBuffer.toString()); return new BaseResponse(HttpStatus.BAD_REQUEST.value(),stringBuffer.toString()); &#125; 上面代码是统一异常处理中的一部分，主要是用来处理参数校验产生的MethodArgumentNotValidException异常。 分组校验当我们遇到不同场景需要有不同的校验规则时候，我们可以使用分组校验。如：一个请求只校验id,一个请求只校验email： 123456789101112131415161718192021222324252627282930public class AgentTrustor implements Serializable,UniqueVerifiableVO &#123; private static final long serialVersionUID = 4095871718305603749L; /** * 主键ID */ @Id @ApiModelProperty(value="主键ID", required = true) private Integer fid; /** * 代理人代码 */ @Length(min = 3,message = "代理人代码位数至少三位",groups = &#123;ID.class&#125;) @Column(name = "ftrustor_id") @ApiModelProperty(value="代理人代码", required = true) private String ftrustorId; /** * 联系人邮箱 */ @Email(message = "邮箱格式错误",groups = &#123;EMAIL.class&#125;) @Column(name = "femail") @ApiModelProperty(value="联系人邮箱", required = true) private String femail; public interface ID&#123;&#125;; public interface EMAIL&#123;&#125;;&#125; 根据需要在@Validated属性中指定需要校验的分组名，可以指定1到多个。指定到的分组名会全部进行校验，不指定的不校验 1234567@ApiOperation(value="新增", notes="") @PostMapping(value = "") //@Transactional(rollbackFor=Exception.class) public ObjectRestResponse&lt;AgentTrustor&gt; add(@RequestBody @Validated(AgentTrustor.ID.class) AgentTrustor agentTrustor) throws BaseException&#123; agentTrustorBiz.bizInsertSelective(agentTrustor); return new ObjectRestResponse&lt;AgentTrustor&gt;().rel(true); &#125; APIJSR提供的校验注解 12345678910111213@Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式 Hibernate Validator提供的校验注解 12345@NotBlank(message =) 验证字符串非null，且长度必须大于0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[docker部署基于nodejs的vue应用]]></title>
      <url>%2F2017%2FDocker-Nodejs-Vue%2F</url>
      <content type="text"><![CDATA[摘要:use Docker containers for Vue.js applications 正文:环境准备安装docker，具体操作参考官方文档。 Vue项目准备- 在项目根目录下，添加Dockerfile文件，Dockerfile是一个文本文档，其中包含用户可以在命令行上调用以构建镜像的所有命令(注意要先清除node_modules文件夹内容)1234567891011121314151617181920212223242526#指定我们的基础镜像是node，版本是v8.0.0 指定的基础image可以是官方远程仓库中的，也可以位于本地仓库 FROM node:8.0.0 #指定维护者的信息 MAINTAINER mser #将根目录下的文件都copy到container（运行此镜像的容器）文件系统的app文件夹下 ADD . /app/ #cd到app文件夹下 WORKDIR /app#安装项目依赖包 RUN npm install RUN npm rebuild node-sass --force #配置环境变量 ENV HOST 0.0.0.0 ENV PORT 9528 #容器对外暴露的端口号 EXPOSE 9528 #容器启动时执行的命令 每个Dockerfile只有一个CMD命令 多了则会覆盖之前的CMD CMD ["npm", "run","dev"] 构建镜像- 查看本地docker镜像1234[root@localhost AG-Admin-v2.0]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/sebp/elk latest 2918030b8729 8 days ago 1.051 GBdocker.io/node 8.0.0 065e283f68bd 5 months ago 666.5 MB - build123456789101112[root@localhost AG-Admin-v2.0]# docker build -t ms-ui:1.0 .Sending build context to Docker daemon 3.897 MBStep 1 : FROM node:8.0.0 ---&gt; 065e283f68bdStep 2 : MAINTAINER EOI---&gt; Running in 275025d855c0 ---&gt; e66a97693ac5Removing intermediate container 275025d855c0Step 3 : ADD . /app/ ---&gt; bbb817cfbb8b.....省略一万行Successfully built 6af9d7ffb2ab - 启动镜像12345678[root@localhost AG-Admin-v2.0]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEms-ui 1.0 6af9d7ffb2ab 2 minutes ago 920.5 MBdocker.io/sebp/elk latest 2918030b8729 8 days ago 1.051 GBdocker.io/node 8.0.0 065e283f68bd 5 months ago 666.5 MB[root@localhost AG-Admin-v2.0]# docker run -d -p 9528:9528 ms-ui:1.01ffc51cbea42bb4ee9f43a5987ed2569923cfe42bb5f140cf8268fd38d9dd37a docker run -d -p 9528:9528 ms-ui:1.0中的 -d 代表是后台运行、-p 9528:9528代表本地9528映射到容器内的9528端口，ms-ui:1.0是我们要运行的镜像 - 测试是否成功12345678910111213141516171819202122[root@localhost AG-Admin-v2.0]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1ffc51cbea42 ms-ui:1.0 "npm run dev" About a minute ago Up About a minute 0.0.0.0:9528-&gt;9528/tcp zen_lamarrea9400d0259b sebp/elk "/usr/local/bin/start" 6 days ago Exited (137) 2 hours ago test_elk_173e22237ef4e sebp/elk "/usr/local/bin/start" 6 days ago Exited (1) 6 days ago elk[root@localhost AG-Admin-v2.0]# docker logs 1ffc51cbea42npm info it worked if it ends with oknpm info using npm@5.0.0npm info using node@v8.0.0&gt; juicy@1.2.0 dev /app&gt; node build/dev-server.jsnpm info lifecycle juicy@1.2.0~predev: juicy@1.2.0npm info lifecycle juicy@1.2.0~dev: juicy@1.2.0[HPM] Proxy created: /jwt -&gt; http://localhost:8765[HPM] Proxy rewrite rule created: "^/jwt" ~&gt; "/jwt"[HPM] Proxy created: /api -&gt; http://localhost:8765[HPM] Proxy rewrite rule created: "^/api" ~&gt; "/api"(node:15) UnhandledPromiseRejectionWarning: Unhandled promise rejection (rejection id: 1): Error: Exited with code 3(node:15) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code. DONE Compiled successfully in 10673ms07:51:55&gt; Listening at http://localhost:9528 docker ps -a可以查看docker的运行容器，发现我们的容器正在运行，可以通过docker logs 来查看运行日志，当看到我们熟悉的Listening at http://localhost:9528 就知道成功啦，可以在本地通过浏览器访问UI。 - 常用命令123456789docker stop &lt;CONTAINER ID&gt;可以停止容器运行 docker start &lt;CONTAINER ID&gt;可以启动容器运行 docker restart &lt;CONTAINER ID&gt;可以重启容器 docker rm &lt;CONTAINER ID&gt; -f可以强制删除在运行的容器docker rmi &lt;IMAGE NAME&gt; 可以删除镜像]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK8的CAS实现学习笔记]]></title>
      <url>%2F2017%2Fjavase-CAS%2F</url>
      <content type="text"><![CDATA[摘要:CAS全称为compare and swap，是原子操作的一种，可用于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某一数据时由于执行顺序不确定性以及中断的不可预知性产生的数据不一致问题。 该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值。 –from Wikipedia 正文:在使用上，通常会记录下某块内存中的旧值，通过对旧值进行一系列的操作后得到新值，然后通过CAS操作将新值与旧值进行交换。如果这块内存的值在这期间内没被修改过，则旧值会与内存中的数据相同，这时CAS操作将会成功执行 使内存中的数据变为新值。如果内存中的值在这期间内被修改过，则一般来说旧值会与内存中的数据不同，这时CAS操作将会失败，新值将不会被写入内存。 CAS的实现接下来我们去看CAS在java中的实现，sun.misc.Unsafe提供了compareAndSwap系列函数。 1234567891011121314151617181920212223242526/** * Atomically update Java variable to &lt;tt&gt;x&lt;/tt&gt; if it is currently * holding &lt;tt&gt;expected&lt;/tt&gt;. * @return &lt;tt&gt;true&lt;/tt&gt; if successful */ public final native boolean compareAndSwapObject(Object o, long offset, Object expected, Object x); /** * Atomically update Java variable to &lt;tt&gt;x&lt;/tt&gt; if it is currently * holding &lt;tt&gt;expected&lt;/tt&gt;. * @return &lt;tt&gt;true&lt;/tt&gt; if successful */ public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x); /** * Atomically update Java variable to &lt;tt&gt;x&lt;/tt&gt; if it is currently * holding &lt;tt&gt;expected&lt;/tt&gt;. * @return &lt;tt&gt;true&lt;/tt&gt; if successful */ public final native boolean compareAndSwapLong(Object o, long offset, long expected, long x); 可以看到native发现这是一个本地方法调用，可以去查看对应的OpenJDK中调用代码atomic_linux_x86.inline.hpp / atomic_windows_x86.inline.hpp 1234567891011121314//linux(int 类型)inline jint Atomic::cmpxchg(jint exchange_value, volatile jint* dest, jint compare_value) &#123; int mp = os::is_MP(); __asm__ volatile (LOCK_IF_MP(%4) "cmpxchgl %1,(%3)" : "=a" (exchange_value) : "r" (exchange_value), "a" (compare_value), "r" (dest), "r" (mp) : "cc", "memory"); return exchange_value;&#125;//windows(int 类型)inline jint Atomic::cmpxchg(jint exchange_value, volatile jint* dest, jint compare_value) &#123; return (*os::atomic_cmpxchg_func)(exchange_value, dest, compare_value);&#125; 可以看到其实现方式是基于硬件平台的汇编指令cmpxchg指令完成的，JVM只是封装了汇编调用。以linux x86处理器为例子，int mp = os::is_MP()中的MP是multiprocessor，即多处理器，当遇到是多处理器的情况下加上LOCK。cmpxchgl指的应该是compare and exchange指令。 CAS在Java中的使用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 public class UnsafeTest &#123; private static Unsafe unsafe; static &#123; try &#123; // 通过反射获取rt.jar下的Unsafe类 Field field = Unsafe.class.getDeclaredField("theUnsafe"); field.setAccessible(true); unsafe = (Unsafe) field.get(null); &#125; catch (Exception e) &#123; System.out.println("Get Unsafe instance occur error" + e); &#125; &#125; public static void main(String[] args) throws Exception &#123; Class clazz = Target.class; Field[] fields = clazz.getDeclaredFields(); Target target = new Target(); Field intFiled = clazz.getDeclaredField("intParam"); Field longFiled = clazz.getDeclaredField("longParam"); Field strFiled = clazz.getDeclaredField("strParam"); Field strFiled2 = clazz.getDeclaredField("strParam2"); // intParam System.out.print(unsafe.compareAndSwapInt(target, 12, 3, 10) + ":"); System.out.println((Integer) intFiled.get(target)); // longParam System.out.print(unsafe.compareAndSwapLong(target, 16, 1l, 2l) + ":"); System.out.println((Long) longFiled.get(target)); // strParam System.out.print(unsafe.compareAndSwapObject(target, 24, null, "5") + ":"); System.out.println((String) strFiled.get(target)); // strParam2 System.out.print(unsafe.compareAndSwapObject(target, 28, null, "6") + ":"); System.out.println((String) strFiled2.get(target)); &#125; &#125; class Target &#123; int intParam = 3; long longParam = 1l; String strParam; String strParam2;&#125; 如代码所示，compareAndSwapXx方法会根据第二个参数”偏移量”去拿偏移量这么多的属性的值和第三个参数对比，如果相同则将该属性值替换为第四个参数。该偏移量是指某个字段相对Java对象的起始位置的偏移量，可以通过unsafe.objectFieldOffset(param)去获取对应属性的偏移量。 顺便介绍个查看对象的属性位置分布的一个小工具：jol 使用Demo:首先引用jol-core包 123456&lt;!-- https://mvnrepository.com/artifact/org.openjdk.jol/jol-core --&gt;&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt;&lt;/dependency&gt; 然后在项目里简单使用下： 123456public class TestOffset &#123; public static void main(String[] args) &#123; out.println(VM.current().details()); out.println(ClassLayout.parseClass(Throwable.class).toPrintable()); &#125;&#125; 结果如下，根据偏移量界面化的显示属性分布的位置： 1234567891011121314151617# Running 64-bit HotSpot VM.# Using compressed oop with 3-bit shift.# Using compressed klass with 3-bit shift.# Objects are 8 bytes aligned.# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]java.lang.Throwable object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 12 (object header) N/A 12 4 (alignment/padding gap) 16 4 java.lang.String Throwable.detailMessage N/A 20 4 java.lang.Throwable Throwable.cause N/A 24 4 java.lang.StackTraceElement[] Throwable.stackTrace N/A 28 4 java.util.List Throwable.suppressedExceptions N/AInstance size: 32 bytesSpace losses: 4 bytes internal + 0 bytes external = 4 bytes total CAS存在的ABA问题CAS普遍存在的一个问题就是ABA问题，即是当线程一将变量A修改为B，之后又修改为A，线程二去对比A发现没变化就会判断出错。目前很多都是使用加上版本号来解决，加个version字段，每次修改就++，每次判断时候多判断下版本号是否变化来确定某变量是否被修改。 下班啦，暂且到这里，祝大家十一玩的开心~~~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Method的invoke方法源码分析]]></title>
      <url>%2F2017%2Fjavase-Method-invoke%2F</url>
      <content type="text"><![CDATA[摘要:最近有使用到Method的invoke方法，于是就学习了下Method的invoke方法源码(暂未深入到native) 正文:源码分析首先看一下invoke方法的代码实现： 123456789101112131415161718192021222324class AccessibleObject implements AnnotatedElement &#123; boolean override; //访问权限 public boolean isAccessible() &#123; return override; &#125;&#125;//Method.classpublic Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException &#123; if (!override) &#123; if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, obj, modifiers); &#125; &#125; MethodAccessor ma = methodAccessor; // read volatile if (ma == null) &#123; ma = acquireMethodAccessor(); &#125; return ma.invoke(obj, args); &#125; 可以看到在该方法第一步会先去判断AccessibleObject的override属性是否为true 若为true则忽略访问权限的控制 若为false则会去调用Reflection.quickCheckMemberAccess()判断是不是public，若不是则会使用Reflection.getCallerClass()获取调用此方法的class，然后校验其是否有权限 最后会调用MethodAccessor的invoke()方法 MethodAccessor的invoke方法源码如下所示，就是一个接口： 12345public interface MethodAccessor &#123; /** Matches specification in &#123;@link java.lang.reflect.Method&#125; */ public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException;&#125; 可以看到它只是一个单方法接口，其invoke()方法与Method.invoke()的对应。 创建MethodAccessor实例的是ReflectionFactory。 sun.reflect.ReflectionFactory： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class ReflectionFactory &#123; private static boolean initted = false; // ... // // "Inflation" mechanism. Loading bytecodes to implement // Method.invoke() and Constructor.newInstance() currently costs // 3-4x more than an invocation via native code for the first // invocation (though subsequent invocations have been benchmarked // to be over 20x faster). Unfortunately this cost increases // startup time for certain applications that use reflection // intensively (but only once per class) to bootstrap themselves. // To avoid this penalty we reuse the existing JVM entry points // for the first few invocations of Methods and Constructors and // then switch to the bytecode-based implementations. // // Package-private to be accessible to NativeMethodAccessorImpl // and NativeConstructorAccessorImpl private static boolean noInflation = false; private static int inflationThreshold = 15; // ... /** We have to defer full initialization of this class until after the static initializer is run since java.lang.reflect.Method's static initializer (more properly, that for java.lang.reflect.AccessibleObject) causes this class's to be run, before the system properties are set up. */ private static void checkInitted() &#123; if (initted) return; AccessController.doPrivileged(new PrivilegedAction() &#123; public Object run() &#123; // Tests to ensure the system properties table is fully // initialized. This is needed because reflection code is // called very early in the initialization process (before // command-line arguments have been parsed and therefore // these user-settable properties installed.) We assume that // if System.out is non-null then the System class has been // fully initialized and that the bulk of the startup code // has been run. if (System.out == null) &#123; // java.lang.System not yet fully initialized return null; &#125; String val = System.getProperty("sun.reflect.noInflation"); if (val != null &amp;&amp; val.equals("true")) &#123; noInflation = true; &#125; val = System.getProperty("sun.reflect.inflationThreshold"); if (val != null) &#123; try &#123; inflationThreshold = Integer.parseInt(val); &#125; catch (NumberFormatException e) &#123; throw (RuntimeException) new RuntimeException("Unable to parse property sun.reflect.inflationThreshold"). initCause(e); &#125; &#125; initted = true; return null; &#125; &#125;); &#125; // ... public MethodAccessor newMethodAccessor(Method method) &#123; checkInitted(); if (noInflation) &#123; return new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); &#125; else &#123; NativeMethodAccessorImpl acc = new NativeMethodAccessorImpl(method); DelegatingMethodAccessorImpl res = new DelegatingMethodAccessorImpl(acc); acc.setParent(res); return res; &#125; &#125;&#125; 可以看到，实际的MethodAccessor实现有两个版本，一个是Java实现的，另一个是native code实现的。Java实现的版本在初始化时需要较多时间，但长久来说性能较好；native版本正好相反，启动时相对较快，但运行时间长了之后速度就比不过Java版了。 这个需要注意的是inflationThreshold的值是15，也就是说前15次是使用的native版本，之后使用的是java版本，具体实现可以往下看。 为了权衡两个版本的性能，Sun的JDK使用了“inflation”的技巧：让Java方法在被反射调用时，开头若干次使用native版，等反射调用次数超过阈值时则生成一个专用的MethodAccessor实现类，生成其中的invoke()方法的字节码，以后对该Java方法的反射调用就会使用Java版。 (Sun的JDK是从1.4系开始采用这种优化的) 可以在启动命令里加上-Dsun.reflect.noInflation=true，就会RefactionFactorynoInflation属性就变成true了，这样不用等到15调用后，程序一开始就会用java版的MethodAccessor了 可以在上段代码newMethodAccessor()方法看到DelegatingMethodAccessorImpl res = new DelegatingMethodAccessorImpl(acc); sun.reflect.DelegatingMethodAccessorImpl： 1234567891011121314151617class DelegatingMethodAccessorImpl extends MethodAccessorImpl &#123; private MethodAccessorImpl delegate; DelegatingMethodAccessorImpl(MethodAccessorImpl delegate) &#123; setDelegate(delegate); &#125; public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException &#123; return delegate.invoke(obj, args); &#125; void setDelegate(MethodAccessorImpl delegate) &#123; this.delegate = delegate; &#125;&#125; 这个类是方便在native与Java版的MethodAccessor之间实现切换。 sun.reflect.NativeMethodAccessorImpl： 123456789101112131415161718192021222324252627282930313233class NativeMethodAccessorImpl extends MethodAccessorImpl &#123; private Method method; private DelegatingMethodAccessorImpl parent; private int numInvocations; NativeMethodAccessorImpl(Method method) &#123; this.method = method; &#125; public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException &#123; if (++numInvocations &gt; ReflectionFactory.inflationThreshold()) &#123; MethodAccessorImpl acc = (MethodAccessorImpl) new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); parent.setDelegate(acc); &#125; return invoke0(method, obj, args); &#125; void setParent(DelegatingMethodAccessorImpl parent) &#123; this.parent = parent; &#125; private static native Object invoke0(Method m, Object obj, Object[] args);&#125; 可以看到在每次调用invoke方法时候会++numInvocations，inflationThreshold的值是15，该块就是上文所说的native版本和java版本的切换实现部分。当numInvocations超过inflationThreshold的值调用MethodAccessorGenerator.generateMethod()来生成Java版的MethodAccessor的实现类，并且改变DelegatingMethodAccessorImpl所引用的MethodAccessor为Java版。后续经由DelegatingMethodAccessorImpl.invoke()调用到的就是Java版的实现了。 测试用例可以使用demo测试invoke方法执行的流程： 123456789101112131415161718public class A &#123; public void foo(String name) &#123; System.out.println("Hello," + name); &#125;&#125;//Testpublic class TestClassLoad &#123; public static void main(String[] args) throws Exception &#123; Class&lt;?&gt; clz = Class.forName("testinvoke.A"); Object o = clz.newInstance(); Method m = clz.getMethod("foo", String.class); for (int i = 0; i &lt; 16; i++) &#123; m.invoke(o, Integer.toString(i)); &#125; &#125; &#125;&#125; 可以在运行的时候使用-XX:+TraceClassLoading参数监控类加载情况： 12345678910111213141516171819202122232425262728293031323334353637[Loaded testinvoke.A from file:/C:/Users/itliusir/git/test/Test/bin/][Loaded sun.reflect.NativeMethodAccessorImpl from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.DelegatingMethodAccessorImpl from D:\jdk8\jre\lib\rt.jar]Hello,0Hello,1Hello,2Hello,3Hello,4Hello,5Hello,6Hello,7Hello,8Hello,9Hello,10Hello,11Hello,12Hello,13Hello,14[Loaded sun.reflect.ClassFileConstants from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.AccessorGenerator from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.MethodAccessorGenerator from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.ByteVectorFactory from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.ByteVector from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.ByteVectorImpl from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.ClassFileAssembler from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.UTF8 from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.Label from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.Label$PatchInfo from D:\jdk8\jre\lib\rt.jar][Loaded java.util.ArrayList$Itr from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.MethodAccessorGenerator$1 from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.ClassDefiner from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.ClassDefiner$1 from D:\jdk8\jre\lib\rt.jar][Loaded java.util.concurrent.ConcurrentHashMap$ForwardingNode from D:\jdk8\jre\lib\rt.jar][Loaded sun.reflect.GeneratedMethodAccessor1 from __JVM_DefineClass__]Hello,15[Loaded java.lang.Shutdown from D:\jdk8\jre\lib\rt.jar][Loaded java.lang.Shutdown$Lock from D:\jdk8\jre\lib\rt.jar]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MAT内存分析工具使用]]></title>
      <url>%2F2017%2FJVM-MAT%2F</url>
      <content type="text"><![CDATA[摘要:Eclipse Memory Analysis Tools (MAT) 是一个分析 Java堆数据的专业工具,用它可以定位内存泄漏的原因。 正文:Memory Analyzer的安装 Eclipse-&gt;Help-&gt;Eclipse Marketplace 安装完成后可以调用jdk工具jps查看当前的java进程，然后调用jmap将该进程的内存heap输出到文件。 通过MAT以图像形式直观的展示内存泄漏报表等 首先Eclipse-&gt;File-&gt;Open File 打开上一步生成的文件 第一个选项是内存泄漏报表（自动检查可能存在内存泄露的对象，通过报表展示存活的对象以及为什么他们没有被垃圾收集）； 第二个是对象报表（对可疑对象进行分析，如字符串是否定义重了，空的collection、finalizer以及弱引用等）； 这里我们打开第一个： Memory Analyzer主界面介绍 下面的Histogram（列出内存中的对象，对象的个数以及大小）这里我们可以使用正则去进行匹配 可以在具体的Class右键List objects-&gt;with incoming…./outgoing…查看该Class的实例 1. outgoing references ：表示该对象的出节点（被该对象引用的对象）。 2. incoming references ：表示该对象的入节点（引用到该对象的对象）。 下面的Dominator Tree是列出最大的对象以及其依赖存活的Object （大小是以Retained Heap为标准排序的） 而Top Consumers则是通过图形列出最大的Object Duplicate Class是通过MAT自动分析泄漏的原因 一般Histogram和 Dominator Tree是最常用的。 Memory Analyzer中概念介绍 Shallow heap Shallow size就是对象本身占用内存的大小，不包含其引用的对象。 1. 常规对象（非数组）的Shallow size由其成员变量的数量和类型决定。 2. 数组的shallow size由数组元素的类型（对象类型、基本类型）和数组长度决定 Retained Heap 它表示如果一个对象被释放，那么因为该对象的释放而减少引用从而导致释放所有的对象所占用的heap大小 为了计算Retained Memory，MAT引入了Dominator Tree。加入对象A引用B和C，B和C又都引用到D（一个菱形）。此时要计算Retained Memory，A的包括A本身和B，C，D。B和C因为共同引用D，所以他俩的Retained Memory都只是他们本身。D当然也只是自己。我觉得是为了加快计算的速度，MAT改变了对象引用图，而转换成一个对象引用树。在这里例子中，树根是A，而B，C，D是他的三个儿子。B，C，D不再有相互关系。把引用图变成引用树，计算Retained Heap就会非常方便，显示也非常方便。对应到MAT UI上，在dominator tree这个view中，显示了每个对象的shallow heap和retained heap。然后可以以该节点位树根，一步步的细化看看retained heap到底是用在什么地方了。要说一下的是，这种从图到树的转换确实方便了内存分析，但有时候会让人有些疑惑。本来对象B是对象A的一个成员，但因为B还被C引用，所以B在树中并不在A下面，而很可能是平级，如下图所示。 为了纠正这点，MAT中点击右键，可以List objects中选择with outgoing references和with incoming references。这是个真正的引用图的概念 GC Root GC发现通过任何reference chain(引用链)无法访问某个对象的时候，该对象即被回收。名词GC Roots正是分析这一过程的起点，例如JVM自己确保了对象的可到达性(那么JVM就是GC Roots)，所以GC Roots就是这样在内存中保持对象可到达性的，一旦不可到达，即被回收。通常GC Roots是一个在current thread(当前线程)的call stack(调用栈)上的对象（例如方法参数和局部变量），或者是线程自身或者是system class loader(系统类加载器)加载的类以及native code(本地代码)保留的活动对象。所以GC Roots是分析对象为何还存活于内存中的利器。 在Histogram或者Domiantor Tree的某一个条目上，右键可以查看其GC Root Path 参考： http://blog.csdn.net/yxz329130952/article/details/50288145 http://www.jianshu.com/p/d8e247b1e7b2 晚安~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK8的LinkedList源码学习笔记]]></title>
      <url>%2F2017%2Fjavase-List-LinkedList1%2F</url>
      <content type="text"><![CDATA[摘要:上一篇分析了ArrayList之后接下来分析下LinkedList的底层设计,它与ArrayList在底层的实现上有所不同。 正文:首先，LinkedList的继承和实现了的类和接口： LinkedList 是一个继承于AbstractSequentialList的双向链表。它也可以被当作堆栈、队列或双端队列进行操作。同时实现了Deque接口，即能将LinkedList当作双端队列使用。 另外实现了Cloneable接口，Serializable接口。接下来看LinkedList的构造方法： 123456789101112131415161718/** * Constructs an empty list. */ public LinkedList() &#123; &#125; /** * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection's * iterator. * * @param c the collection whose elements are to be placed into this list * @throws NullPointerException if the specified collection is null */ public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c); &#125; LinkedList提供了两个构造方法，第一个是默认无参的，第二个是带Collection的类型参数： 使用this()调用默认的构造方法 成员变量分析 1234567891011121314151617/** * 当前有多少个节点 */transient int size = 0; /** * 第一个节点. * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * 最后一个节点. * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last; 核心方法分析 1. addAll()方法 addAll有两个重载函数，addAll(Collection&lt;? extends E&gt;)型和addAll(int, Collection&lt;? extends E&gt;)型，我们平时习惯调用的addAll(Collection&lt;? extends E&gt;)型会转化为addAll(int, Collection&lt;? extends E&gt;)型，所以我们着重分析此函数即可 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; //JDK8将对index的判断封装了一个方法checkPositionIndex(index); //这个就不用说了，集合转为数组 Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; //succ指向当前需要插入节点的位置，pred指向其前一个节点 Node&lt;E&gt; pred, succ; //在列表尾部插入的时候 if (index == size) &#123; succ = null; pred = last; &#125; else &#123; //若不是在尾部插入时候则先去根据索引查询对应的元素可见该块最下面的node()方法 succ = node(index); pred = succ.prev; &#125; //遍历collection中的所有元素将其依次插入到此链表中指定位置 for (Object o : a) &#123; @SuppressWarnings("unchecked") E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; &#125; if (succ == null) &#123; last = pred; &#125; else &#123; pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true; &#125;/** * 根据index返回对应元素. */ Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); //若index&lt;size/2正序移位获取索引位置 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125; &#125; 2. removeXXX()方法 LinkedList提供了头删除removeFirst()、尾删除removeLast()、remove(int index)、remove(Object o)、clear()这些删除元素的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133/** * Removes and returns the first element from this list. */public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f); &#125; /** * Removes and returns the last element from this list. */ public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l); &#125;/** * Unlinks non-null first node f. * 删除非空的首节点f. */ private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC //将原首节点的next节点设置为首节点 first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element; &#125; /** * Unlinks non-null last node l. * 删除非空的尾节点f. */ private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC //将原尾节点的prev节点设置为尾节点 last = prev; if (prev == null) first = null; else prev.next = null; size--; modCount++; return element; &#125;/** * Remove. */public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false; &#125;/** * Unlinks non-null node x. * 删除非空节点. */ E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; //如果被删除节点为头节点 if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; //如果被删除节点为尾节点 if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; //size-1 modCount++; return element; &#125;/** * Removes all of the elements from this list. * 清空所有节点. */ public void clear() &#123; // Clearing all of the links between nodes is "unnecessary", but: // - helps a generational GC if the discarded nodes inhabit // more than one generation // - is sure to free memory even if there is a reachable Iterator for (Node&lt;E&gt; x = first; x != null; ) &#123; Node&lt;E&gt; next = x.next; x.item = null; x.next = null; x.prev = null; x = next; &#125; first = last = null; size = 0; modCount++; &#125; 3. set()方法 12345678//很容易分析，先检查index，然后根据index返回对应元素，最后将元素--&gt;x.itempublic E set(int index, E element) &#123; checkElementIndex(index); Node&lt;E&gt; x = node(index); E oldVal = x.item; x.item = element; return oldVal; &#125; 4. getXXX()方法 LinkedList提供了getFirst()、getLast()、contains(Object o)、get(int index)、indexOf(Object o)、lastIndexOf(Object o)这些查找元素的方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * Returns the first element in this list. */ public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item; &#125;/** * Returns the last element in this list. */ public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item; &#125;public boolean contains(Object o) &#123; return indexOf(o) != -1; &#125;/** * 正向查找，返回LinkedList中元素值Object o第一次出现的位置，如果元素不存在，则返回-1 */ public int indexOf(Object o) &#123; int index = 0; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; //正向 if (x.item == null) return index; index++; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1; &#125;//逆向查找，返回LinkedList中元素值Object o最后一次出现的位置，如果元素不存在，则返回-1 public int lastIndexOf(Object o) &#123; int index = size; //LinkedList可以为null if (o == null) &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; //逆向 index--; if (x.item == null) return index; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; index--; if (o.equals(x.item)) return index; &#125; &#125; return -1; &#125;/** * 根据index获取当前元素. */ public E get(int index) &#123; checkElementIndex(index); return node(index).item; &#125; 5. Queue操作 Queue操作提供了peek()、element()、poll()、remove()、offer(E e)这些方法。 123456789101112131415161718192021222324252627//获取但不移除此队列的头；如果此队列为空，则返回 null public E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125; //获取但不移除此队列的头；如果此队列为空，则抛出NoSuchElementException异常 public E element() &#123; return getFirst(); &#125; //获取并移除此队列的头，如果此队列为空，则返回 null public E poll() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); &#125; //获取并移除此队列的头，如果此队列为空，则抛出NoSuchElementException异常 public E remove() &#123; return removeFirst(); &#125; //将指定的元素值(E e)插入此列表末尾 public boolean offer(E e) &#123; return add(e); &#125; 6. Deque操作 Deque操作提供了offerFirst(E e)、offerLast(E e)、peekFirst()、peekLast()、pollFirst()、pollLast()、push(E e)、pop()、removeFirstOccurrence(Object o)、removeLastOccurrence(Object o)这些方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879//将指定的元素值(E e)插入此列表末尾 public boolean offer(E e) &#123; return add(e); &#125; // Deque operations //将指定的元素插入此双端队列的开头 public boolean offerFirst(E e) &#123; addFirst(e); return true; &#125; //将指定的元素插入此双端队列的末尾 public boolean offerLast(E e) &#123; addLast(e); return true; &#125; //获取，但不移除此双端队列的第一个元素；如果此双端队列为空，则返回 null public E peekFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125; //获取，但不移除此双端队列的最后一个元素；如果此双端队列为空，则返回 null public E peekLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : l.item; &#125; //获取并移除此双端队列的第一个元素；如果此双端队列为空，则返回 null public E pollFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); &#125; //获取并移除此双端队列的最后一个元素；如果此双端队列为空，则返回 null public E pollLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : unlinkLast(l); &#125; //将一个元素推入此双端队列所表示的堆栈（换句话说，此双端队列的头部） public void push(E e) &#123; addFirst(e); &#125; //从此双端队列所表示的堆栈中弹出一个元素（换句话说，移除并返回此双端队列的头部） public E pop() &#123; return removeFirst(); &#125; //从此双端队列移除第一次出现的指定元素，如果列表中不包含次元素，则没有任何改变 public boolean removeFirstOccurrence(Object o) &#123; return remove(o); &#125; //从此双端队列移除最后一次出现的指定元素,如果列表中不包含次元素，则没有任何改变 public boolean removeLastOccurrence(Object o) &#123; //由于LinkedList中允许存放null，因此下面通过两种情况来分别处理 if (o == null) &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; //逆向向前 if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false; &#125; LinkedList同样也采用了快速失败的机制，通过记录modCount参数来实现。在面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险。 晚安~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK8的ArrayList源码学习笔记]]></title>
      <url>%2F2017%2Fjavase-List-ArrayList1%2F</url>
      <content type="text"><![CDATA[摘要:ArrayList基本上是我们在java编程中用得最多的集合类了，是一个动态的数组，在我们用ArrayList的时候发现其非常方面，功能也很强大，但是其这强大的功能是底层是怎么实现的呢？ 正文:首先，ArrayList的继承和实现了的类和接口： 可以看出，ArrayList不仅实现了Cloneable、Serializable接口，还实现了RandomAccess接口、List接口。 RandomAccess是一个标记接口，用于标明实现该接口的List支持快速随机访问，主要目的是使算法能够在随机和顺序访问的list中表现的更加高效。因为这个接口是没有任何实现的，实现了这个接口的类，就表明这个类支持快速访问，就相当于实现了Serializable就等于支持序列化和反序列化，这是个标准。 接下来看ArrayList的构造方法： 12345678910111213141516171819202122232425public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+initialCapacity); &#125; &#125; public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; ArrayList提供了三个构造方法，第一个是由调用者传入指定List的大小来创建elementData数组。第二个是默认的构造方法，默认数组容量是10。第三个是根据传入的一个集合，将集合转化成数组，然后赋给elementData。面试题里经常出现ArrayList list = new ArrayList(20)一共扩容了几次，虽然ArrayList默认容量是10，但是它有一个是指定list大小的构造方法，会在new ArrayList(20)时候自动生成一个20容量的集合，所以是不会发生扩容也即是0次。 成员变量分析 123456789101112//默认容量 private static final int DEFAULT_CAPACITY = 10; //空数组 private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;//空数组，新增元素时候用 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;//数组 transient Object[] elementData; //数组大小 private int size;//数组最大容量private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 核心方法分析 1. trim to size 压缩空间 123456789public void trimToSize() &#123; modCount++; //一个精简的三元表达式 if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125; &#125; 2. grow 扩容 1234567891011121314151617181920212223242526private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; //新空间分配直接扩大50% int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //得出较大的值 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: //元素复制 elementData = Arrays.copyOf(elementData, newCapacity); &#125;private static int hugeCapacity(int minCapacity) &#123; /** * hugeCapacity的判断小于0则为溢出，由于在jvm内部是以反 * 码存储的数据，首位为符号位，当容量扩增后，若溢出，首位 * 则变为1，此时变为负数，则可以快速判断出是否溢出。 */ if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; 3. fail-fast机制 1234/** * 子类使用这个字段是可选的，若子类希望提供fail-fast(快速失败) iterators或者list iterators 可以在方法里使用该方法. */protected transient int modCount = 0; 这个变量用于快速判断该实例是否有变化，若在进行迭代的时候有变更，那么就抛出一个并发修改异常(ConcurrentModificationException)。fail-fast是Java集合的一种错误检测机制。当多个线程对集合进行结构上的改变的操作时，有可能会产生fail-fast机制。 4. add 新增一个元素 指定位置插入： 123456789101112public void add(int index, E element) &#123; //下标检查，是否越界了 rangeCheckForAdd(index); //扩增容量，同时改变modcount ensureCapacityInternal(size + 1); //index后面的元素后移 System.arraycopy(elementData, index, elementData, index + 1, size - index); //指定位置放置元素 elementData[index] = element; //元素数量大小自增 size++; &#125; 向后插入： 12345678910public boolean add(E e) &#123; //扩大容量,修改modcount ensureCapacityInternal(size + 1); // Increments modCount!! //注意 //数组是从0开始的存元素的，而数组个数是从1开始计数的 //这个地方是往第size个位置上存元素 //再将元素个数加1 elementData[size++] = e; return true; &#125; 由此可见，向后插入没有使用数组复制，因此效率会高于指定位置插入。 5. remove 移除一个元素 由上面的插入方法可以看到List底层的数组处理使用到了System.arraycopy()方法,下面综合删除和数组复制方法讲下删除原理，下面是删除代码： 1234567891011121314151617181920212223242526272829303132333435363738394041 public class TestArrayList &#123; static Object[] elementData = null; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add("A"); list.add("B"); list.add("C"); list.add("D"); list.add("E"); int size = list.size(); elementData = list.toArray(); /** * removeMyList(要删除元素的位置,size); * */ removeMyList(2,size); for(Object ele:elementData)&#123; System.out.println(ele); &#125; &#125; private static void removeMyList(int index,int size) &#123; /** * arraycopy(Object src,int srcPos, * Object dest,int destPos, * int length); * src:源数组； srcPos:源数组要复制的起始位置； * dest:目的数组； destPos:目的数组放置的起始位置； * length:复制的长度。 * * 若自己到自己复制实现过程是先生成一个长度为length的临时数组, * 将elementData数组中srcPos到srcPos+length-1之间的数据拷贝到临时数组中， * 再执行System.arraycopy(临时数组,index+1,elementData,index,size-index-1). * index:要删除元素的位置 * list删除元素时候是srcPos=index+1,destPos=index,length=size-index-1 * 意思是将要删除的元素和之后元素复制到自己元素和之后的位置将自己覆盖 * */ System.arraycopy(elementData, index+1, elementData, index, size-index-1); elementData[--size] = null; //相当于往前移了一位将最后一位重复的置null &#125;&#125; 其删除操作如下图所示： 下一篇将要写关于LinkedList的源码分析~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于Spring事务的传播特性]]></title>
      <url>%2F2017%2Fspring-Transactional%2F</url>
      <content type="text"><![CDATA[摘要:Spring事务管理基于底层数据库本身的事务处理机制，对数据库事务操作的一次封装，相当于把使用JDBC代码开启、提交、回滚事务进行了封装。其传播特性共有七个 正文:事务的传播特性 Propagation.REQUIRED 方法被调用时自动开启事务，在事务范围内使用则使用同一个事务，如果当前线程中已经存在事务, 方法调用会加入此事务, 如果当前没有事务，就新建一个事务。 Propagation.REQUIRES_NEW 无论何时自身都会开启事务，这个事务不依赖于外部事务，它拥有自己的隔离范围，自己的锁，等等。当内部事务开始执行时，外部事务将被挂起，内部事务结束时，外部事务将继续执行。 Propagation.SUPPORTS 自身不会开启事务，在事务范围内使用挂起事务，运行完毕不使用事务 Propagation.NOT_SUPPORTED 自身不会开启事务，在事务范围内使用挂起事务，运行完毕恢复事务 Propagation.MANDATORY 自身不会开启事务，必须在事务环境使用否则报错 Propagation.NEVER 自身不会开启事务，在事务范围内使用抛出异常 Propagation.NESTED 如果当前存在事务，则在嵌套的事务中执行，如果没有则按照TransactionDefinition.PROPAGATION_REQUIRED 属性执行。可以认为是已经存在事务的一个真正的子事务。嵌套事务开始执行时，它将取得一个 save point。如果这个嵌套事务失败，我们将回滚到此save point。嵌套事务是外部事务的一部分，只有外部事务结束后它才会被提交。 Propagation.REQUIRES_NEW和Propagation.NESTED 的最大区别在于，Propagation.REQUIRES_NEW完全是一个新的事务，而 Propagation.NESTED 则是外部事务的子事务。如果外部事务 commit，嵌套事务也会被 commit，这个规则同样适用于rollback。 测试代码因为业务的需要，业务逻辑优先在单个Service中实现，同样为了保证数据的一致性需要使用事务，在单个Service中实现会出现嵌套事务。 如我们使用service C同时调用service A和service B ，如果service B抛出异常那么service C（外部事务）如果没有特殊配置（如异常时事务提交）那么整个事务是一定会rollback的。 测试代码：Service C：如下代码所示，使用声明式注解@Transactional(rollbackFor=Exception.class)默认传播特性是Propagation.REQUIRED。1234567@Transactional(rollbackFor=Exception.class,propagation=Propagation.REQUIRED)@Overridepublic int insert(Users users) throws Exception&#123; int i = users1Service.insert(users); int j = users2Service.insert1(users); return i+j;&#125; Controller层：1234567@RequestMapping(value = "/", method = RequestMethod.POST)public ResponseInfo postUser1(@RequestBody Users user) throws Exception &#123; ResponseInfo resInfo = new ResponseInfo(); int i = usersService.insert(user); resInfo.setResponseInfo("users一共新增了" + i + "条数据"); return resInfo;&#125; Service A：12345@Transactional(rollbackFor=Exception.class,propagation=Propagation.REQUIRES_NEW)@Overridepublic int insert(Users users) throws Exception&#123; return usersMapper.insert(users);&#125; Service B：12345@Transactional(rollbackFor=Exception.class,propagation=Propagation.REQUIRED)@Overridepublic int insert1(Users users) throws Exception&#123; return usersMapper.insert1(users);&#125; 根据以上代码可以通过测试两张表同时插入而一张表失败最后返回的数据进行分析：本次使用Postman测试工具，数据库oracle 11g。两张表其中一张age字段为number6位，一张为number2位，测试数据为三位，会有一张表插入失败，测试数据如下图所示。 结果是两张表都没有插入，如下图所示。 经过测试，说明嵌套事务与事务的传播特性有关，都使用默认的传播属性REQUIRED第一张插入后，第二张失败会导致外部事务（Service C）rollback，保证了数据的一致性。若内部事务有使用REQUIRES_NEW属性，则会单独开一事务其运行结果不会影响外部数据会出现数据不一致。若内部事务有使用NESTED属性，内部事务如果出现异常则会rollback到save point，从而外部事务可以使用try-catch进行分支执行（try里执行Service A，catch里执行Service B）。查询语句应该设置为read-only，传播范围设置为NOT_SUPPORTED如下代码所示：12345678910/** * &#123;@inheritDoc&#125; * &#123;@link newframe.business.demo.service.SecurityInfoService#queryAll()&#125; * */ @Transactional(propagation = Propagation.NOT_SUPPORTED, readOnly = true) @Override public List&lt;SecurityInfo&gt; queryAll() throws MessageException &#123; List&lt;SecurityInfo&gt; list = securityInfoMapper.queryAll(); return list; &#125; 具体使用哪个属性根据业务来进行选择。 Spring注解在项目中如果大量组件采用xml的bean定义来配置，显然会增加配置文件的体积，查找不太方便。而注解可以很方便的标注完将其放入spring容器管理。 业务层注解@Service：用于标注业务层组件。@Controller：用于标注控制层组件。@Repository：用于标注数据访问组件，即Dao组件。@Component：泛指组件，不容易归类可以使用该组件。 Bean容器相关的注解@Autowired：等同autowire=byType，根据类型的自动注入依赖。@Qualifier：等同autowire=byName，当@Autowired注解需要判断多个 bean类型相同时，就需要使用@Qualifier(“xxBean”)来指定依赖的bean 的id。@Resource：属于JSR250标准，作用同@Autowired，是属于byName类 型的依赖注入，使用方式：@Resource(name=”xxBean”)，不带参数是默 认类名首字母小写。 @RequestBody：用于读取request请求的body部分数据(Json串或XML数据)，将其转化为需要的对象。@ResponseBody：将Controller的方法返回的对象通过适当的转换(通过配置可以返回Json或XML数据)，写入response对象的body数据区。新框架可以在Controller里使用该注解返回Json数据。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[很方便的密码加密算法BCrypt]]></title>
      <url>%2F2017%2FAlgorithm-BCrypt%2F</url>
      <content type="text"><![CDATA[摘要:用户表的密码一般都不是使用明文，使用明文坏处可以参考之前CSDN数据库被黑导致用户密码泄露造成的影响。虽然使用明文也有一定的方便之处(毕竟现在的加密都是单向的，比如客户打电话问密码、老大或者上级问密码)，但是我们完全可以根据用户提供的其他信息(比如密保让客户自己输入密码进行更改而不是直接告诉用户密码)，无论怎么样明文存储密码的坏处一定大于好处。下面将介绍使用Spring Security时候遇到的默认密码加密算法BCrypt： 正文:BCrypt算法将salt随机并混入最终加密后的密码，验证时也无需单独提供之前的salt，从而无需单独处理salt问题。 salt随机部分代码： 123//根据SecureRandom对象与gensalt()方法产生随机值String salt = gensalt(xx, new SecureRandom());String BCpwd = hashpw("123456", salt); 用法很简单： 12//BCpwd是加密后的密文String BCpwd = BCrypt.hashpw(password, BCrypt.gensalt()); 加密后的格式一般为： $2a$10$/bTVvqqlH9UiE0ZJZ7N2Me3RIgUCdgMheyTgV0B4cMCSokPa.6oCa 其中：$是分割符，无意义；2a是bcrypt加密版本号；10是cost的值；而后的前22位是salt值；再然后的字符串就是密码的密文了。 这块代码的格式拼接可以查看gensalt()方法源码： 123456789101112131415161718public static String gensalt(int log_rounds, SecureRandom random) &#123; if (log_rounds &lt; 4 || log_rounds &gt; 31) &#123; throw new IllegalArgumentException("Bad number of rounds"); &#125; StringBuilder rs = new StringBuilder(); byte rnd[] = new byte[BCRYPT_SALT_LEN]; random.nextBytes(rnd); rs.append("$2a$"); if (log_rounds &lt; 10) &#123; rs.append("0"); &#125; rs.append(log_rounds); rs.append("$"); encode_base64(rnd, rnd.length, rs); return rs.toString();&#125; 下面是我整理的一套BCrypt算法源码，可以很方便的直接拿来用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544package bcrypt;import java.io.ByteArrayOutputStream;import java.io.UnsupportedEncodingException;import java.security.SecureRandom;import java.util.regex.Pattern;public class TestBCrypt &#123; private static Pattern BCRYPT_PATTERN = Pattern .compile("\\A\\$2a?\\$\\d\\d\\$[./0-9A-Za-z]&#123;53&#125;"); private static final int GENSALT_DEFAULT_LOG2_ROUNDS = 10; private static final int BCRYPT_SALT_LEN = 16; // Blowfish parameters private static final int BLOWFISH_NUM_ROUNDS = 16; // Initial contents of key schedule private static final int P_orig[] = &#123; 0x243f6a88, 0x85a308d3, 0x13198a2e, 0x03707344, 0xa4093822, 0x299f31d0, 0x082efa98, 0xec4e6c89, 0x452821e6, 0x38d01377, 0xbe5466cf, 0x34e90c6c, 0xc0ac29b7, 0xc97c50dd, 0x3f84d5b5, 0xb5470917, 0x9216d5d9, 0x8979fb1b &#125;; private static final int S_orig[] = &#123; 0xd1310ba6, 0x98dfb5ac, 0x2ffd72db, 0xd01adfb7, 0xb8e1afed, 0x6a267e96, 0xba7c9045, 0xf12c7f99, 0x24a19947, 0xb3916cf7, 0x0801f2e2, 0x858efc16, 0x636920d8, 0x71574e69, 0xa458fea3, 0xf4933d7e, 0x0d95748f, 0x728eb658, 0x718bcd58, 0x82154aee, 0x7b54a41d, 0xc25a59b5, 0x9c30d539, 0x2af26013, 0xc5d1b023, 0x286085f0, 0xca417918, 0xb8db38ef, 0x8e79dcb0, 0x603a180e, 0x6c9e0e8b, 0xb01e8a3e, 0xd71577c1, 0xbd314b27, 0x78af2fda, 0x55605c60, 0xe65525f3, 0xaa55ab94, 0x57489862, 0x63e81440, 0x55ca396a, 0x2aab10b6, 0xb4cc5c34, 0x1141e8ce, 0xa15486af, 0x7c72e993, 0xb3ee1411, 0x636fbc2a, 0x2ba9c55d, 0x741831f6, 0xce5c3e16, 0x9b87931e, 0xafd6ba33, 0x6c24cf5c, 0x7a325381, 0x28958677, 0x3b8f4898, 0x6b4bb9af, 0xc4bfe81b, 0x66282193, 0x61d809cc, 0xfb21a991, 0x487cac60, 0x5dec8032, 0xef845d5d, 0xe98575b1, 0xdc262302, 0xeb651b88, 0x23893e81, 0xd396acc5, 0x0f6d6ff3, 0x83f44239, 0x2e0b4482, 0xa4842004, 0x69c8f04a, 0x9e1f9b5e, 0x21c66842, 0xf6e96c9a, 0x670c9c61, 0xabd388f0, 0x6a51a0d2, 0xd8542f68, 0x960fa728, 0xab5133a3, 0x6eef0b6c, 0x137a3be4, 0xba3bf050, 0x7efb2a98, 0xa1f1651d, 0x39af0176, 0x66ca593e, 0x82430e88, 0x8cee8619, 0x456f9fb4, 0x7d84a5c3, 0x3b8b5ebe, 0xe06f75d8, 0x85c12073, 0x401a449f, 0x56c16aa6, 0x4ed3aa62, 0x363f7706, 0x1bfedf72, 0x429b023d, 0x37d0d724, 0xd00a1248, 0xdb0fead3, 0x49f1c09b, 0x075372c9, 0x80991b7b, 0x25d479d8, 0xf6e8def7, 0xe3fe501a, 0xb6794c3b, 0x976ce0bd, 0x04c006ba, 0xc1a94fb6, 0x409f60c4, 0x5e5c9ec2, 0x196a2463, 0x68fb6faf, 0x3e6c53b5, 0x1339b2eb, 0x3b52ec6f, 0x6dfc511f, 0x9b30952c, 0xcc814544, 0xaf5ebd09, 0xbee3d004, 0xde334afd, 0x660f2807, 0x192e4bb3, 0xc0cba857, 0x45c8740f, 0xd20b5f39, 0xb9d3fbdb, 0x5579c0bd, 0x1a60320a, 0xd6a100c6, 0x402c7279, 0x679f25fe, 0xfb1fa3cc, 0x8ea5e9f8, 0xdb3222f8, 0x3c7516df, 0xfd616b15, 0x2f501ec8, 0xad0552ab, 0x323db5fa, 0xfd238760, 0x53317b48, 0x3e00df82, 0x9e5c57bb, 0xca6f8ca0, 0x1a87562e, 0xdf1769db, 0xd542a8f6, 0x287effc3, 0xac6732c6, 0x8c4f5573, 0x695b27b0, 0xbbca58c8, 0xe1ffa35d, 0xb8f011a0, 0x10fa3d98, 0xfd2183b8, 0x4afcb56c, 0x2dd1d35b, 0x9a53e479, 0xb6f84565, 0xd28e49bc, 0x4bfb9790, 0xe1ddf2da, 0xa4cb7e33, 0x62fb1341, 0xcee4c6e8, 0xef20cada, 0x36774c01, 0xd07e9efe, 0x2bf11fb4, 0x95dbda4d, 0xae909198, 0xeaad8e71, 0x6b93d5a0, 0xd08ed1d0, 0xafc725e0, 0x8e3c5b2f, 0x8e7594b7, 0x8ff6e2fb, 0xf2122b64, 0x8888b812, 0x900df01c, 0x4fad5ea0, 0x688fc31c, 0xd1cff191, 0xb3a8c1ad, 0x2f2f2218, 0xbe0e1777, 0xea752dfe, 0x8b021fa1, 0xe5a0cc0f, 0xb56f74e8, 0x18acf3d6, 0xce89e299, 0xb4a84fe0, 0xfd13e0b7, 0x7cc43b81, 0xd2ada8d9, 0x165fa266, 0x80957705, 0x93cc7314, 0x211a1477, 0xe6ad2065, 0x77b5fa86, 0xc75442f5, 0xfb9d35cf, 0xebcdaf0c, 0x7b3e89a0, 0xd6411bd3, 0xae1e7e49, 0x00250e2d, 0x2071b35e, 0x226800bb, 0x57b8e0af, 0x2464369b, 0xf009b91e, 0x5563911d, 0x59dfa6aa, 0x78c14389, 0xd95a537f, 0x207d5ba2, 0x02e5b9c5, 0x83260376, 0x6295cfa9, 0x11c81968, 0x4e734a41, 0xb3472dca, 0x7b14a94a, 0x1b510052, 0x9a532915, 0xd60f573f, 0xbc9bc6e4, 0x2b60a476, 0x81e67400, 0x08ba6fb5, 0x571be91f, 0xf296ec6b, 0x2a0dd915, 0xb6636521, 0xe7b9f9b6, 0xff34052e, 0xc5855664, 0x53b02d5d, 0xa99f8fa1, 0x08ba4799, 0x6e85076a, 0x4b7a70e9, 0xb5b32944, 0xdb75092e, 0xc4192623, 0xad6ea6b0, 0x49a7df7d, 0x9cee60b8, 0x8fedb266, 0xecaa8c71, 0x699a17ff, 0x5664526c, 0xc2b19ee1, 0x193602a5, 0x75094c29, 0xa0591340, 0xe4183a3e, 0x3f54989a, 0x5b429d65, 0x6b8fe4d6, 0x99f73fd6, 0xa1d29c07, 0xefe830f5, 0x4d2d38e6, 0xf0255dc1, 0x4cdd2086, 0x8470eb26, 0x6382e9c6, 0x021ecc5e, 0x09686b3f, 0x3ebaefc9, 0x3c971814, 0x6b6a70a1, 0x687f3584, 0x52a0e286, 0xb79c5305, 0xaa500737, 0x3e07841c, 0x7fdeae5c, 0x8e7d44ec, 0x5716f2b8, 0xb03ada37, 0xf0500c0d, 0xf01c1f04, 0x0200b3ff, 0xae0cf51a, 0x3cb574b2, 0x25837a58, 0xdc0921bd, 0xd19113f9, 0x7ca92ff6, 0x94324773, 0x22f54701, 0x3ae5e581, 0x37c2dadc, 0xc8b57634, 0x9af3dda7, 0xa9446146, 0x0fd0030e, 0xecc8c73e, 0xa4751e41, 0xe238cd99, 0x3bea0e2f, 0x3280bba1, 0x183eb331, 0x4e548b38, 0x4f6db908, 0x6f420d03, 0xf60a04bf, 0x2cb81290, 0x24977c79, 0x5679b072, 0xbcaf89af, 0xde9a771f, 0xd9930810, 0xb38bae12, 0xdccf3f2e, 0x5512721f, 0x2e6b7124, 0x501adde6, 0x9f84cd87, 0x7a584718, 0x7408da17, 0xbc9f9abc, 0xe94b7d8c, 0xec7aec3a, 0xdb851dfa, 0x63094366, 0xc464c3d2, 0xef1c1847, 0x3215d908, 0xdd433b37, 0x24c2ba16, 0x12a14d43, 0x2a65c451, 0x50940002, 0x133ae4dd, 0x71dff89e, 0x10314e55, 0x81ac77d6, 0x5f11199b, 0x043556f1, 0xd7a3c76b, 0x3c11183b, 0x5924a509, 0xf28fe6ed, 0x97f1fbfa, 0x9ebabf2c, 0x1e153c6e, 0x86e34570, 0xeae96fb1, 0x860e5e0a, 0x5a3e2ab3, 0x771fe71c, 0x4e3d06fa, 0x2965dcb9, 0x99e71d0f, 0x803e89d6, 0x5266c825, 0x2e4cc978, 0x9c10b36a, 0xc6150eba, 0x94e2ea78, 0xa5fc3c53, 0x1e0a2df4, 0xf2f74ea7, 0x361d2b3d, 0x1939260f, 0x19c27960, 0x5223a708, 0xf71312b6, 0xebadfe6e, 0xeac31f66, 0xe3bc4595, 0xa67bc883, 0xb17f37d1, 0x018cff28, 0xc332ddef, 0xbe6c5aa5, 0x65582185, 0x68ab9802, 0xeecea50f, 0xdb2f953b, 0x2aef7dad, 0x5b6e2f84, 0x1521b628, 0x29076170, 0xecdd4775, 0x619f1510, 0x13cca830, 0xeb61bd96, 0x0334fe1e, 0xaa0363cf, 0xb5735c90, 0x4c70a239, 0xd59e9e0b, 0xcbaade14, 0xeecc86bc, 0x60622ca7, 0x9cab5cab, 0xb2f3846e, 0x648b1eaf, 0x19bdf0ca, 0xa02369b9, 0x655abb50, 0x40685a32, 0x3c2ab4b3, 0x319ee9d5, 0xc021b8f7, 0x9b540b19, 0x875fa099, 0x95f7997e, 0x623d7da8, 0xf837889a, 0x97e32d77, 0x11ed935f, 0x16681281, 0x0e358829, 0xc7e61fd6, 0x96dedfa1, 0x7858ba99, 0x57f584a5, 0x1b227263, 0x9b83c3ff, 0x1ac24696, 0xcdb30aeb, 0x532e3054, 0x8fd948e4, 0x6dbc3128, 0x58ebf2ef, 0x34c6ffea, 0xfe28ed61, 0xee7c3c73, 0x5d4a14d9, 0xe864b7e3, 0x42105d14, 0x203e13e0, 0x45eee2b6, 0xa3aaabea, 0xdb6c4f15, 0xfacb4fd0, 0xc742f442, 0xef6abbb5, 0x654f3b1d, 0x41cd2105, 0xd81e799e, 0x86854dc7, 0xe44b476a, 0x3d816250, 0xcf62a1f2, 0x5b8d2646, 0xfc8883a0, 0xc1c7b6a3, 0x7f1524c3, 0x69cb7492, 0x47848a0b, 0x5692b285, 0x095bbf00, 0xad19489d, 0x1462b174, 0x23820e00, 0x58428d2a, 0x0c55f5ea, 0x1dadf43e, 0x233f7061, 0x3372f092, 0x8d937e41, 0xd65fecf1, 0x6c223bdb, 0x7cde3759, 0xcbee7460, 0x4085f2a7, 0xce77326e, 0xa6078084, 0x19f8509e, 0xe8efd855, 0x61d99735, 0xa969a7aa, 0xc50c06c2, 0x5a04abfc, 0x800bcadc, 0x9e447a2e, 0xc3453484, 0xfdd56705, 0x0e1e9ec9, 0xdb73dbd3, 0x105588cd, 0x675fda79, 0xe3674340, 0xc5c43465, 0x713e38d8, 0x3d28f89e, 0xf16dff20, 0x153e21e7, 0x8fb03d4a, 0xe6e39f2b, 0xdb83adf7, 0xe93d5a68, 0x948140f7, 0xf64c261c, 0x94692934, 0x411520f7, 0x7602d4f7, 0xbcf46b2e, 0xd4a20068, 0xd4082471, 0x3320f46a, 0x43b7d4b7, 0x500061af, 0x1e39f62e, 0x97244546, 0x14214f74, 0xbf8b8840, 0x4d95fc1d, 0x96b591af, 0x70f4ddd3, 0x66a02f45, 0xbfbc09ec, 0x03bd9785, 0x7fac6dd0, 0x31cb8504, 0x96eb27b3, 0x55fd3941, 0xda2547e6, 0xabca0a9a, 0x28507825, 0x530429f4, 0x0a2c86da, 0xe9b66dfb, 0x68dc1462, 0xd7486900, 0x680ec0a4, 0x27a18dee, 0x4f3ffea2, 0xe887ad8c, 0xb58ce006, 0x7af4d6b6, 0xaace1e7c, 0xd3375fec, 0xce78a399, 0x406b2a42, 0x20fe9e35, 0xd9f385b9, 0xee39d7ab, 0x3b124e8b, 0x1dc9faf7, 0x4b6d1856, 0x26a36631, 0xeae397b2, 0x3a6efa74, 0xdd5b4332, 0x6841e7f7, 0xca7820fb, 0xfb0af54e, 0xd8feb397, 0x454056ac, 0xba489527, 0x55533a3a, 0x20838d87, 0xfe6ba9b7, 0xd096954b, 0x55a867bc, 0xa1159a58, 0xcca92963, 0x99e1db33, 0xa62a4a56, 0x3f3125f9, 0x5ef47e1c, 0x9029317c, 0xfdf8e802, 0x04272f70, 0x80bb155c, 0x05282ce3, 0x95c11548, 0xe4c66d22, 0x48c1133f, 0xc70f86dc, 0x07f9c9ee, 0x41041f0f, 0x404779a4, 0x5d886e17, 0x325f51eb, 0xd59bc0d1, 0xf2bcc18f, 0x41113564, 0x257b7834, 0x602a9c60, 0xdff8e8a3, 0x1f636c1b, 0x0e12b4c2, 0x02e1329e, 0xaf664fd1, 0xcad18115, 0x6b2395e0, 0x333e92e1, 0x3b240b62, 0xeebeb922, 0x85b2a20e, 0xe6ba0d99, 0xde720c8c, 0x2da2f728, 0xd0127845, 0x95b794fd, 0x647d0862, 0xe7ccf5f0, 0x5449a36f, 0x877d48fa, 0xc39dfd27, 0xf33e8d1e, 0x0a476341, 0x992eff74, 0x3a6f6eab, 0xf4f8fd37, 0xa812dc60, 0xa1ebddf8, 0x991be14c, 0xdb6e6b0d, 0xc67b5510, 0x6d672c37, 0x2765d43b, 0xdcd0e804, 0xf1290dc7, 0xcc00ffa3, 0xb5390f92, 0x690fed0b, 0x667b9ffb, 0xcedb7d9c, 0xa091cf0b, 0xd9155ea3, 0xbb132f88, 0x515bad24, 0x7b9479bf, 0x763bd6eb, 0x37392eb3, 0xcc115979, 0x8026e297, 0xf42e312d, 0x6842ada7, 0xc66a2b3b, 0x12754ccc, 0x782ef11c, 0x6a124237, 0xb79251e7, 0x06a1bbe6, 0x4bfb6350, 0x1a6b1018, 0x11caedfa, 0x3d25bdd8, 0xe2e1c3c9, 0x44421659, 0x0a121386, 0xd90cec6e, 0xd5abea2a, 0x64af674e, 0xda86a85f, 0xbebfe988, 0x64e4c3fe, 0x9dbc8057, 0xf0f7c086, 0x60787bf8, 0x6003604d, 0xd1fd8346, 0xf6381fb0, 0x7745ae04, 0xd736fccc, 0x83426b33, 0xf01eab71, 0xb0804187, 0x3c005e5f, 0x77a057be, 0xbde8ae24, 0x55464299, 0xbf582e61, 0x4e58f48f, 0xf2ddfda2, 0xf474ef38, 0x8789bdc2, 0x5366f9c3, 0xc8b38e74, 0xb475f255, 0x46fcd9b9, 0x7aeb2661, 0x8b1ddf84, 0x846a0e79, 0x915f95e2, 0x466e598e, 0x20b45770, 0x8cd55591, 0xc902de4c, 0xb90bace1, 0xbb8205d0, 0x11a86248, 0x7574a99e, 0xb77f19b6, 0xe0a9dc09, 0x662d09a1, 0xc4324633, 0xe85a1f02, 0x09f0be8c, 0x4a99a025, 0x1d6efe10, 0x1ab93d1d, 0x0ba5a4df, 0xa186f20f, 0x2868f169, 0xdcb7da83, 0x573906fe, 0xa1e2ce9b, 0x4fcd7f52, 0x50115e01, 0xa70683fa, 0xa002b5c4, 0x0de6d027, 0x9af88c27, 0x773f8641, 0xc3604c06, 0x61a806b5, 0xf0177a28, 0xc0f586e0, 0x006058aa, 0x30dc7d62, 0x11e69ed7, 0x2338ea63, 0x53c2dd94, 0xc2c21634, 0xbbcbee56, 0x90bcb6de, 0xebfc7da1, 0xce591d76, 0x6f05e409, 0x4b7c0188, 0x39720a3d, 0x7c927c24, 0x86e3725f, 0x724d9db9, 0x1ac15bb4, 0xd39eb8fc, 0xed545578, 0x08fca5b5, 0xd83d7cd3, 0x4dad0fc4, 0x1e50ef5e, 0xb161e6f8, 0xa28514d9, 0x6c51133c, 0x6fd5c7e7, 0x56e14ec4, 0x362abfce, 0xddc6c837, 0xd79a3234, 0x92638212, 0x670efa8e, 0x406000e0, 0x3a39ce37, 0xd3faf5cf, 0xabc27737, 0x5ac52d1b, 0x5cb0679e, 0x4fa33742, 0xd3822740, 0x99bc9bbe, 0xd5118e9d, 0xbf0f7315, 0xd62d1c7e, 0xc700c47b, 0xb78c1b6b, 0x21a19045, 0xb26eb1be, 0x6a366eb4, 0x5748ab2f, 0xbc946e79, 0xc6a376d2, 0x6549c2c8, 0x530ff8ee, 0x468dde7d, 0xd5730a1d, 0x4cd04dc6, 0x2939bbdb, 0xa9ba4650, 0xac9526e8, 0xbe5ee304, 0xa1fad5f0, 0x6a2d519a, 0x63ef8ce2, 0x9a86ee22, 0xc089c2b8, 0x43242ef6, 0xa51e03aa, 0x9cf2d0a4, 0x83c061ba, 0x9be96a4d, 0x8fe51550, 0xba645bd6, 0x2826a2f9, 0xa73a3ae1, 0x4ba99586, 0xef5562e9, 0xc72fefd3, 0xf752f7da, 0x3f046f69, 0x77fa0a59, 0x80e4a915, 0x87b08601, 0x9b09e6ad, 0x3b3ee593, 0xe990fd5a, 0x9e34d797, 0x2cf0b7d9, 0x022b8b51, 0x96d5ac3a, 0x017da67d, 0xd1cf3ed6, 0x7c7d2d28, 0x1f9f25cf, 0xadf2b89b, 0x5ad6b472, 0x5a88f54c, 0xe029ac71, 0xe019a5e6, 0x47b0acfd, 0xed93fa9b, 0xe8d3c48d, 0x283b57cc, 0xf8d56629, 0x79132e28, 0x785f0191, 0xed756055, 0xf7960e44, 0xe3d35e8c, 0x15056dd4, 0x88f46dba, 0x03a16125, 0x0564f0bd, 0xc3eb9e15, 0x3c9057a2, 0x97271aec, 0xa93a072a, 0x1b3f6d9b, 0x1e6321f5, 0xf59c66fb, 0x26dcf319, 0x7533d928, 0xb155fdf5, 0x03563482, 0x8aba3cbb, 0x28517711, 0xc20ad9f8, 0xabcc5167, 0xccad925f, 0x4de81751, 0x3830dc8e, 0x379d5862, 0x9320f991, 0xea7a90c2, 0xfb3e7bce, 0x5121ce64, 0x774fbe32, 0xa8b6e37e, 0xc3293d46, 0x48de5369, 0x6413e680, 0xa2ae0810, 0xdd6db224, 0x69852dfd, 0x09072166, 0xb39a460a, 0x6445c0dd, 0x586cdecf, 0x1c20c8ae, 0x5bbef7dd, 0x1b588d40, 0xccd2017f, 0x6bb4e3bb, 0xdda26a7e, 0x3a59ff45, 0x3e350a44, 0xbcb4cdd5, 0x72eacea8, 0xfa6484bb, 0x8d6612ae, 0xbf3c6f47, 0xd29be463, 0x542f5d9e, 0xaec2771b, 0xf64e6370, 0x740e0d8d, 0xe75b1357, 0xf8721671, 0xaf537d5d, 0x4040cb08, 0x4eb4e2cc, 0x34d2466a, 0x0115af84, 0xe1b00428, 0x95983a1d, 0x06b89fb4, 0xce6ea048, 0x6f3f3b82, 0x3520ab82, 0x011a1d4b, 0x277227f8, 0x611560b1, 0xe7933fdc, 0xbb3a792b, 0x344525bd, 0xa08839e1, 0x51ce794b, 0x2f32c9b7, 0xa01fbac9, 0xe01cc87e, 0xbcc7d1f6, 0xcf0111c3, 0xa1e8aac7, 0x1a908749, 0xd44fbd9a, 0xd0dadecb, 0xd50ada38, 0x0339c32a, 0xc6913667, 0x8df9317c, 0xe0b12b4f, 0xf79e59b7, 0x43f5bb3a, 0xf2d519ff, 0x27d9459c, 0xbf97222c, 0x15e6fc2a, 0x0f91fc71, 0x9b941525, 0xfae59361, 0xceb69ceb, 0xc2a86459, 0x12baa8d1, 0xb6c1075e, 0xe3056a0c, 0x10d25065, 0xcb03a442, 0xe0ec6e0e, 0x1698db3b, 0x4c98a0be, 0x3278e964, 0x9f1f9532, 0xe0d392df, 0xd3a0342b, 0x8971f21e, 0x1b0a7441, 0x4ba3348c, 0xc5be7120, 0xc37632d8, 0xdf359f8d, 0x9b992f2e, 0xe60b6f47, 0x0fe3f11d, 0xe54cda54, 0x1edad891, 0xce6279cf, 0xcd3e7e6f, 0x1618b166, 0xfd2c1d05, 0x848fd2c5, 0xf6fb2299, 0xf523f357, 0xa6327623, 0x93a83531, 0x56cccd02, 0xacf08162, 0x5a75ebb5, 0x6e163697, 0x88d273cc, 0xde966292, 0x81b949d0, 0x4c50901b, 0x71c65614, 0xe6c6c7bd, 0x327a140a, 0x45e1d006, 0xc3f27b9a, 0xc9aa53fd, 0x62a80f00, 0xbb25bfe2, 0x35bdd2f6, 0x71126905, 0xb2040222, 0xb6cbcf7c, 0xcd769c2b, 0x53113ec0, 0x1640e3d3, 0x38abbd60, 0x2547adf0, 0xba38209c, 0xf746ce76, 0x77afa1c5, 0x20756060, 0x85cbfe4e, 0x8ae88dd8, 0x7aaaf9b0, 0x4cf9aa7e, 0x1948c25c, 0x02fb8a8c, 0x01c36ae4, 0xd6ebe1f9, 0x90d4f869, 0xa65cdea0, 0x3f09252d, 0xc208e69f, 0xb74e6132, 0xce77e25b, 0x578fdfe3, 0x3ac372e6 &#125;; // bcrypt IV: "OrpheanBeholderScryDoubt" static private final int bf_crypt_ciphertext[] = &#123; 0x4f727068, 0x65616e42, 0x65686f6c, 0x64657253, 0x63727944, 0x6f756274 &#125;; // Table for Base64 encoding static private final char base64_code[] = &#123; '.', '/', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9' &#125;; // Table for Base64 decoding static private final byte index_64[] = &#123; -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, -1, -1, -1, -1, -1, -1, -1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, -1, -1, -1, -1, -1, -1, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, -1, -1, -1, -1, -1 &#125;; // Expanded Blowfish key private static int P[]; private static int S[]; public static void main(String[] args) &#123; //10是不确定的 此处只是个例子 String salt = gensalt(10, new SecureRandom()); //对123456加密 System.out.println(hashpw("123456", salt)); //是否匹配 System.out.println(matches("123456", "$2a$10$/bTVvqqlH9UiE0ZJZ7N2Me3RIgUCdgMheyTgV0B4cMCSokPa.6oCa")); &#125; private static void init_key() &#123; P = (int[]) P_orig.clone(); S = (int[]) S_orig.clone(); &#125; static void encode_base64(byte d[], int len, StringBuilder rs) throws IllegalArgumentException &#123; int off = 0; int c1, c2; if (len &lt;= 0 || len &gt; d.length) &#123; throw new IllegalArgumentException("Invalid len"); &#125; while (off &lt; len) &#123; c1 = d[off++] &amp; 0xff; rs.append(base64_code[(c1 &gt;&gt; 2) &amp; 0x3f]); c1 = (c1 &amp; 0x03) &lt;&lt; 4; if (off &gt;= len) &#123; rs.append(base64_code[c1 &amp; 0x3f]); break; &#125; c2 = d[off++] &amp; 0xff; c1 |= (c2 &gt;&gt; 4) &amp; 0x0f; rs.append(base64_code[c1 &amp; 0x3f]); c1 = (c2 &amp; 0x0f) &lt;&lt; 2; if (off &gt;= len) &#123; rs.append(base64_code[c1 &amp; 0x3f]); break; &#125; c2 = d[off++] &amp; 0xff; c1 |= (c2 &gt;&gt; 6) &amp; 0x03; rs.append(base64_code[c1 &amp; 0x3f]); rs.append(base64_code[c2 &amp; 0x3f]); &#125; &#125; static byte[] decode_base64(String s, int maxolen) throws IllegalArgumentException &#123; ByteArrayOutputStream out = new ByteArrayOutputStream(maxolen); int off = 0, slen = s.length(), olen = 0; byte c1, c2, c3, c4, o; if (maxolen &lt;= 0) &#123; throw new IllegalArgumentException("Invalid maxolen"); &#125; while (off &lt; slen - 1 &amp;&amp; olen &lt; maxolen) &#123; c1 = char64(s.charAt(off++)); c2 = char64(s.charAt(off++)); if (c1 == -1 || c2 == -1) &#123; break; &#125; o = (byte) (c1 &lt;&lt; 2); o |= (c2 &amp; 0x30) &gt;&gt; 4; out.write(o); if (++olen &gt;= maxolen || off &gt;= slen) &#123; break; &#125; c3 = char64(s.charAt(off++)); if (c3 == -1) &#123; break; &#125; o = (byte) ((c2 &amp; 0x0f) &lt;&lt; 4); o |= (c3 &amp; 0x3c) &gt;&gt; 2; out.write(o); if (++olen &gt;= maxolen || off &gt;= slen) &#123; break; &#125; c4 = char64(s.charAt(off++)); o = (byte) ((c3 &amp; 0x03) &lt;&lt; 6); o |= c4; out.write(o); ++olen; &#125; return out.toByteArray(); &#125; private static byte char64(char x) &#123; if (x &gt; index_64.length) &#123; return -1; &#125; return index_64[x]; &#125; public static String gensalt(int log_rounds, SecureRandom random) &#123; if (log_rounds &lt; 4 || log_rounds &gt; 31) &#123; throw new IllegalArgumentException("Bad number of rounds"); &#125; StringBuilder rs = new StringBuilder(); byte rnd[] = new byte[BCRYPT_SALT_LEN]; random.nextBytes(rnd); rs.append("$2a$"); if (log_rounds &lt; 10) &#123; rs.append("0"); &#125; rs.append(log_rounds); rs.append("$"); encode_base64(rnd, rnd.length, rs); return rs.toString(); &#125; public static String hashpw(String password, String salt) &#123; String real_salt; byte passwordb[], saltb[], hashed[]; char minor = (char) 0; int rounds, off = 0; StringBuilder rs = new StringBuilder(); int saltLength = salt.length(); if (saltLength &lt; 28) &#123; throw new IllegalArgumentException("Invalid salt"); &#125; if (salt.charAt(0) != '$' || salt.charAt(1) != '2') &#123; throw new IllegalArgumentException("Invalid salt version"); &#125; if (salt.charAt(2) == '$') &#123; off = 3; &#125; else &#123; minor = salt.charAt(2); if (minor != 'a' || salt.charAt(3) != '$') &#123; throw new IllegalArgumentException("Invalid salt revision"); &#125; off = 4; &#125; if (saltLength - off &lt; 25) &#123; throw new IllegalArgumentException("Invalid salt"); &#125; // Extract number of rounds if (salt.charAt(off + 2) &gt; '$') &#123; throw new IllegalArgumentException("Missing salt rounds"); &#125; rounds = Integer.parseInt(salt.substring(off, off + 2)); real_salt = salt.substring(off + 3, off + 25); try &#123; passwordb = (password + (minor &gt;= 'a' ? "\000" : "")).getBytes("UTF-8"); &#125; catch (UnsupportedEncodingException uee) &#123; throw new AssertionError("UTF-8 is not supported"); &#125; saltb = decode_base64(real_salt, BCRYPT_SALT_LEN); hashed = crypt_raw(passwordb, saltb, rounds); rs.append("$2"); if (minor &gt;= 'a') &#123; rs.append(minor); &#125; rs.append("$"); if (rounds &lt; 10) &#123; rs.append("0"); &#125; rs.append(rounds); rs.append("$"); encode_base64(saltb, saltb.length, rs); encode_base64(hashed, bf_crypt_ciphertext.length * 4 - 1, rs); return rs.toString(); &#125; private static byte[] crypt_raw(byte password[], byte salt[], int log_rounds) &#123; int cdata[] = (int[]) bf_crypt_ciphertext.clone(); int clen = cdata.length; byte ret[]; long rounds = roundsForLogRounds(log_rounds); init_key(); ekskey(salt, password); for (long i = 0; i &lt; rounds; i++) &#123; key(password); key(salt); &#125; for (int i = 0; i &lt; 64; i++) &#123; for (int j = 0; j &lt; (clen &gt;&gt; 1); j++) &#123; encipher(cdata, j &lt;&lt; 1); &#125; &#125; ret = new byte[clen * 4]; for (int i = 0, j = 0; i &lt; clen; i++) &#123; ret[j++] = (byte) ((cdata[i] &gt;&gt; 24) &amp; 0xff); ret[j++] = (byte) ((cdata[i] &gt;&gt; 16) &amp; 0xff); ret[j++] = (byte) ((cdata[i] &gt;&gt; 8) &amp; 0xff); ret[j++] = (byte) (cdata[i] &amp; 0xff); &#125; return ret; &#125; static long roundsForLogRounds(int log_rounds) &#123; if (log_rounds &lt; 4 || log_rounds &gt; 31) &#123; throw new IllegalArgumentException("Bad number of rounds"); &#125; return 1L &lt;&lt; log_rounds; &#125; private static void ekskey(byte data[], byte key[]) &#123; int i; int koffp[] = &#123; 0 &#125;, doffp[] = &#123; 0 &#125;; int lr[] = &#123; 0, 0 &#125;; int plen = P.length, slen = S.length; for (i = 0; i &lt; plen; i++) &#123; P[i] = P[i] ^ streamtoword(key, koffp); &#125; for (i = 0; i &lt; plen; i += 2) &#123; lr[0] ^= streamtoword(data, doffp); lr[1] ^= streamtoword(data, doffp); encipher(lr, 0); P[i] = lr[0]; P[i + 1] = lr[1]; &#125; for (i = 0; i &lt; slen; i += 2) &#123; lr[0] ^= streamtoword(data, doffp); lr[1] ^= streamtoword(data, doffp); encipher(lr, 0); S[i] = lr[0]; S[i + 1] = lr[1]; &#125; &#125; private static int streamtoword(byte data[], int offp[]) &#123; int i; int word = 0; int off = offp[0]; for (i = 0; i &lt; 4; i++) &#123; word = (word &lt;&lt; 8) | (data[off] &amp; 0xff); off = (off + 1) % data.length; &#125; offp[0] = off; return word; &#125; private static final void encipher(int lr[], int off) &#123; int i, n, l = lr[off], r = lr[off + 1]; l ^= P[0]; for (i = 0; i &lt;= BLOWFISH_NUM_ROUNDS - 2;) &#123; // Feistel substitution on left word n = S[(l &gt;&gt; 24) &amp; 0xff]; n += S[0x100 | ((l &gt;&gt; 16) &amp; 0xff)]; n ^= S[0x200 | ((l &gt;&gt; 8) &amp; 0xff)]; n += S[0x300 | (l &amp; 0xff)]; r ^= n ^ P[++i]; // Feistel substitution on right word n = S[(r &gt;&gt; 24) &amp; 0xff]; n += S[0x100 | ((r &gt;&gt; 16) &amp; 0xff)]; n ^= S[0x200 | ((r &gt;&gt; 8) &amp; 0xff)]; n += S[0x300 | (r &amp; 0xff)]; l ^= n ^ P[++i]; &#125; lr[off] = r ^ P[BLOWFISH_NUM_ROUNDS + 1]; lr[off + 1] = l; &#125; private static void key(byte key[]) &#123; int i; int koffp[] = &#123; 0 &#125;; int lr[] = &#123; 0, 0 &#125;; int plen = P.length, slen = S.length; for (i = 0; i &lt; plen; i++) &#123; P[i] = P[i] ^ streamtoword(key, koffp); &#125; for (i = 0; i &lt; plen; i += 2) &#123; encipher(lr, 0); P[i] = lr[0]; P[i + 1] = lr[1]; &#125; for (i = 0; i &lt; slen; i += 2) &#123; encipher(lr, 0); S[i] = lr[0]; S[i + 1] = lr[1]; &#125; &#125; public static boolean matches(CharSequence rawPassword, String encodedPassword) &#123; if (encodedPassword == null || encodedPassword.length() == 0) &#123; return false; &#125; if (!BCRYPT_PATTERN.matcher(encodedPassword).matches()) &#123; return false; &#125; return checkpw(rawPassword.toString(), encodedPassword); &#125; public static boolean checkpw(String plaintext, String hashed) &#123; return equalsNoEarlyReturn(hashed, hashpw(plaintext, hashed)); &#125; static boolean equalsNoEarlyReturn(String a, String b) &#123; char[] caa = a.toCharArray(); char[] cab = b.toCharArray(); if (caa.length != cab.length) &#123; return false; &#125; byte ret = 0; for (int i = 0; i &lt; caa.length; i++) &#123; ret |= caa[i] ^ cab[i]; &#125; return ret == 0; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[现在有10个随机数，随机数的范围在1到100之间。现在要求写出一种算法，将1到100之间没有在随机数中的数求出来]]></title>
      <url>%2F2017%2FAlgorithm-Random%2F</url>
      <content type="text"><![CDATA[摘要:代码如下： 正文:12345678910111213141516171819202122232425262728293031package test;import java.util.Random;public class TestRandom &#123; public static void main(String[] args) &#123; test(); &#125; static void test()&#123; int[] randomNums = new int[10]; Random random = new Random(); for (int i = 0, length = randomNums.length; i &lt; length; i++) &#123; randomNums[i] = random.nextInt(100); &#125; long start = System.currentTimeMillis(); boolean[] bitArray = new boolean[100]; for (int i = 0, length = randomNums.length; i &lt; length; i++) &#123; bitArray[randomNums[i]] = true; &#125; for (int i = 0, length = bitArray.length; i &lt; length; i++) &#123; if (bitArray[i]) &#123; continue; &#125;else&#123; System.out.println(i); &#125; &#125; long end = System.currentTimeMillis(); System.out.println("Spend milliseconds: " + (end - start)); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Builder模式]]></title>
      <url>%2F2017%2Fjavase-Builder%2F</url>
      <content type="text"><![CDATA[摘要:日常写代码有时候会遇到bean有很多的参数，也即是有多个构造器参数，这个时候我们可以考虑使用构建器。它既能保证像重叠构造器模式那样的安全性，也能保证像JavaBean模式那么好的可读性。这就是Builder模式。 正文:讲Builder模式之前，我们先来看一下日常使用构造器的方法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.bean.builder;public class Bean &#123; private int a; private int b; private int c; private int d; private int e; private int f; public Bean(int a, int b, int c, int d, int e, int f) &#123; super(); this.a = a; this.b = b; this.c = c; this.d = d; this.e = e; this.f = f; &#125; public Bean(int a, int b, int c, int d, int e) &#123; super(); this.a = a; this.b = b; this.c = c; this.d = d; this.e = e; &#125; public Bean(int a, int b, int c, int d) &#123; super(); this.a = a; this.b = b; this.c = c; this.d = d; &#125; // ....构造方法 public Bean() &#123; super(); &#125; //省略setter getter方法&#125; 由此可见,若想要灵活的new一个对象需要创建很多个重载的构造器，可读性和可维护性都不是很高。 使用构建器示例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.bean.builder;public class BuilderBean &#123; private final int a; private final int b; private final int c; private final int d; private final int e; private final int f; public static class Builder&#123; private final int a; private final int b; private int c = 0; private int d = 0; private int e = 0; private int f = 0; public Builder(int a,int b)&#123; this.a = a; this.b = b; &#125; public Builder c(int val)&#123; c = val; return this; &#125; public Builder d(int val)&#123; d = val; return this; &#125; public Builder e(int val)&#123; e = val; return this; &#125; public Builder f(int val)&#123; f = val; return this; &#125; public BuilderBean build()&#123; return new BuilderBean(this); &#125; &#125; private BuilderBean(Builder builder)&#123; a = builder.a; b = builder.b; c = builder.c; d = builder.d; e = builder.e; f = builder.f; &#125; &#125; 注意BuilderBean是不可变的，所有的默认参数值都单独放一个地方。builder的setter方法返回builder本身，以便后续继续调用别的方法。下面是客户端的代码12BuilderBean bb = new BuilderBean.Builder(10, 20). c(3).e(5).f(6).build(); 这样的客户端代码很容易编写，更重要的是易于阅读。与构造器相比，builder的微略优势在于，builder可以有多个可变的参数，构造器就像方法一样，只能有一个可变参数。 Builder模式的优点： 1.使用Builder模式必然会导致写两遍相关属性的代码和setter方法，看起来有点吃力不讨好。然而需要看到的是，客户端代码的可用性和可读性得到了大大提高。与此同时，构造函数的参数数量明显减少调用起来非常直观。 2.Builder模式十分灵活，可以利用单个builder构建多个对象，还可在创建期间进行调整根据对象的不同进行改变。 Builder模式的缺点： 1.为了创建对象，必须先创建它的构建器。虽然创建器的开销在实践中可能不那么明显，但是在某些十分注重性能的情况下，可能就成问题了。 2.Builder模式还比重叠构造器模式更加冗长，最好在4个或4个以上的参数才使用。 在我的Builder实现中，我会用Builder的构造函数而不是set方法传递客户需要的属性。这样做的好处在于，对象总是能被一次完整的实例化，而不是靠开发人员调用时用set方法补充额外的属性完成实例化。这也体现了不可变性带来的好处。然而，相应地也会造成自己设定的属性方法可读性降低。 总结：如果类的构造器或者静态工厂中具有多个参数，设计这种类时，Builder是种不错的选择，特别是当大多数参数都是可选的时候。与使用传统的重叠构造器模式相比，使用Builder模式的客户端代码更易于编写和阅读，构建器也比JavaBean更加安全。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Boot配置属性]]></title>
      <url>%2F2017%2FSpringboot4-SpringBoot-Configuration%2F</url>
      <content type="text"><![CDATA[摘要:springboot数据库连接池使用策略以及对应的配置属性 正文:springboot数据库连接池使用策略springboot官方文档介绍数据库连接池的使用策略如下： Production database connections can also be auto-configured using a pooling DataSource. Here’s the algorithm for choosing a specific implementation: We prefer the Tomcat pooling DataSource for its performance and concurrency, so if that is available we always choose it. If HikariCP is available we will use it. If Commons DBCP is available we will use it, but we don’t recommend it in production. Lastly, if Commons DBCP2 is available we will use it. If you use the spring-boot-starter-jdbc or spring-boot-starter-data-jpa ‘starter POMs’ you will automatically get a dependency to tomcat-jdbc. springboot会优先使用tomcat连接池，因为其性能和并发性很好，如果可用的话，将会优先使用。tomcat连接池，请查看： http://tomcat.apache.org/tomcat-8.0-doc/jdbc-pool.html 如果HikariCP可用，会选择使用 http://brettwooldridge.github.io/HikariCP/。 如果DBCP可用，会选择使用，但是不推荐在生产中使用它。 最后，如果使用DBCP2，会选择使用 如果在pom文件里有spring-boot-starter-jdbc 或者 spring-boot-starter-data-jpa 依赖项，那么，会自动获取tomcat-jdbc连接池。 springboot配置属性datasource spring.dao.exceptiontranslation.enabled是否开启PersistenceExceptionTranslationPostProcessor，默认为true spring.datasource.abandon-when-percentage-full设定超时被废弃的连接占到多少比例时要被关闭或上报 spring.datasource.allow-pool-suspension使用Hikari pool时，是否允许连接池暂停，默认为: false spring.datasource.alternate-username-allowed是否允许替代的用户名. spring.datasource.auto-commit指定updates是否自动提交. spring.datasource.catalog指定默认的catalog. spring.datasource.commit-on-return设置当连接被归还时，是否要提交所有还未完成的事务 spring.datasource.connection-init-sql指定连接被创建，再被添加到连接池之前执行的sql. spring.datasource.connection-init-sqls使用DBCP connection pool时，指定初始化时要执行的sql spring.datasource.connection-properties.[key]在使用DBCP connection pool时指定要配置的属性 spring.datasource.connection-test-query指定校验连接合法性执行的sql语句 spring.datasource.connection-timeout指定连接的超时时间，毫秒单位. spring.datasource.continue-on-error在初始化数据库时，遇到错误是否继续，默认false spring.datasource.data指定Data (DML)脚本 spring.datasource.data-source-class-name指定数据源的全限定名. spring.datasource.data-source-jndi指定jndi的地址 spring.datasource.data-source-properties.[key]使用Hikari connection pool时，指定要设置的属性 spring.datasource.db-properties使用Tomcat connection pool，指定要设置的属性 spring.datasource.default-auto-commit是否自动提交. spring.datasource.default-catalog指定连接默认的catalog. spring.datasource.default-read-only是否设置默认连接只读. spring.datasource.default-transaction-isolation指定连接的事务的默认隔离级别. spring.datasource.driver-class-name指定driver的类名，默认从jdbc url中自动探测. spring.datasource.fair-queue是否采用FIFO返回连接. spring.datasource.health-check-properties.[key]使用Hikari connection pool时，在心跳检查时传递的属性 spring.datasource.idle-timeout指定连接多久没被使用时，被设置为空闲，默认为10ms spring.datasource.ignore-exception-on-pre-load当初始化连接池时，是否忽略异常. spring.datasource.init-sql当连接创建时，执行的sql spring.datasource.initial-size指定启动连接池时，初始建立的连接数量 spring.datasource.initialization-fail-fast当创建连接池时，没法创建指定最小连接数量是否抛异常 spring.datasource.initialize指定初始化数据源，是否用data.sql来初始化，默认: true spring.datasource.isolate-internal-queries指定内部查询是否要被隔离，默认为false spring.datasource.jdbc-interceptors使用Tomcat connection - pool时，指定jdbc拦截器，分号分隔 spring.datasource.jdbc-url指定JDBC URL. spring.datasource.jmx-enabled是否开启JMX，默认为: false spring.datasource.jndi-name指定jndi的名称. spring.datasource.leak-detection-threshold使用Hikari connection pool时，多少毫秒检测一次连接泄露. spring.datasource.log-abandoned使用DBCP connection pool，是否追踪废弃statement或连接，默认为: false spring.datasource.log-validation-errors当使用Tomcat - connection pool是否打印校验错误. spring.datasource.login-timeout指定连接数据库的超时时间. spring.datasource.max-active指定连接池中最大的活跃连接数. spring.datasource.max-age指定连接池中连接的最大年龄 spring.datasource.max-idle指定连接池最大的空闲连接数量. spring.datasource.max-lifetime指定连接池中连接的最大生存时间，毫秒单位. spring.datasource.max-open-prepared-statements指定最大的打开的prepared statements数量. spring.datasource.max-wait指定连接池等待连接返回的最大等待时间，毫秒单位. spring.datasource.maximum-pool-size指定连接池最大的连接数，包括使用中的和空闲的连接. spring.datasource.min-evictable-idle-time-millis指定一个空闲连接最少空闲多久后可被清除. spring.datasource.min-idle指定必须保持连接的最小值(For DBCP and Tomcat connection pools) spring.datasource.minimum-idle指定连接维护的最小空闲连接数，当使用HikariCP时指定. spring.datasource.name指定数据源名. spring.datasource.num-tests-per-eviction-run指定运行每个idle object evictor线程时的对象数量 spring.datasource.password指定数据库密码. spring.datasource.platform指定schema要使用的Platform(schema-${platform}.sql)，默认为: all spring.datasource.pool-name指定连接池名字. spring.datasource.pool-prepared-statements指定是否池化statements. spring.datasource.propagate-interrupt-state在等待连接时，如果线程被中断，是否传播中断状态. spring.datasource.read-only当使用Hikari connection pool时，是否标记数据源只读 spring.datasource.register-mbeans指定Hikari connection pool是否注册JMX MBeans. spring.datasource.remove-abandoned指定当连接超过废弃超时时间时，是否立刻删除该连接. spring.datasource.remove-abandoned-timeout指定连接应该被废弃的时间. spring.datasource.rollback-on-return在归还连接时，是否回滚等待中的事务. spring.datasource.schema指定Schema (DDL)脚本. spring.datasource.separator指定初始化脚本的语句分隔符，默认: ; spring.datasource.sql-script-encoding指定SQL scripts编码. spring.datasource.suspect-timeout指定打印废弃连接前的超时时间. spring.datasource.test-on-borrow当从连接池借用连接时，是否测试该连接. spring.datasource.test-on-connect创建时，是否测试连接 spring.datasource.test-on-return在连接归还到连接池时是否测试该连接. spring.datasource.test-while-idle当连接空闲时，是否执行连接测试. spring.datasource.time-between-eviction-runs-millis指定空闲连接检查、废弃连接清理、空闲连接池大小调整之间的操作时间间隔 spring.datasource.transaction-isolation指定事务隔离级别，使用Hikari connection pool时指定 spring.datasource.url指定JDBC URL. spring.datasource.use-disposable-connection-facade是否对连接进行包装，防止连接关闭之后被使用. spring.datasource.use-equals比较方法名时是否使用String.equals()替换==. spring.datasource.use-lock是否对连接操作加锁 spring.datasource.username指定数据库名. spring.datasource.validation-interval指定多少ms执行一次连接校验. spring.datasource.validation-query指定获取连接时连接校验的sql查询语句. spring.datasource.validation-query-timeout指定连接校验查询的超时时间. spring.datasource.validation-timeout设定连接校验的超时时间，当使用Hikari connection pool时指定 spring.datasource.validator-class-name用来测试查询的validator全限定名. spring.datasource.xa.data-source-class-name指定数据源的全限定名. spring.datasource.xa.properties指定传递给XA data source的属性JPA spring.jpa.database指定目标数据库. spring.jpa.database-platform指定目标数据库的类型. spring.jpa.generate-ddl是否在启动时初始化schema，默认为false spring.jpa.hibernate.ddl-auto指定DDL mode (none, validate, update, create, create-drop). 当使用内嵌数据库时，默认是create-drop，否则为none. spring.jpa.hibernate.naming-strategy指定命名策略. spring.jpa.open-in-view是否注册OpenEntityManagerInViewInterceptor，绑定JPA EntityManager到请求线程中，默认为: true spring.jpa.properties添加额外的属性到JPA provider. spring.jpa.show-sql是否开启sql的log，默认为: falsejooq spring.jooq.sql-dialect指定JOOQ使用的SQLDialect，比如POSTGRES.h2 spring.h2.console.enabled是否开启控制台，默认为false spring.h2.console.path指定控制台路径，默认为: /h2-consoleJTA spring.jta.allow-multiple-lrc是否允许 multiple LRC，默认为: false spring.jta.asynchronous2-pc指定两阶段提交是否可以异步，默认为: false spring.jta.background-recovery-interval指定多少分钟跑一次recovery process，默认为: 1 spring.jta.background-recovery-interval-seconds指定多久跑一次recovery process，默认: 60 spring.jta.current-node-only-recovery是否过滤掉其他非本JVM的recovery，默认为: true spring.jta.debug-zero-resource-transaction是否追踪没有使用指定资源的事务，默认为: false spring.jta.default-transaction-timeout设定默认的事务超时时间，默认为60 spring.jta.disable-jmx是否禁用jmx，默认为false spring.jta.enabled是否开启JTA support，默认为: true spring.jta.exception-analyzer设置指定的异常分析类 spring.jta.filter-log-status使用Bitronix Transaction Manager时，是否写mandatory logs，开启的话，可以节省磁盘空间，但是调试会复杂写，默认为false spring.jta.force-batching-enabled使用Bitronix Transaction Manager时，是否批量写磁盘，默认为true. spring.jta.forced-write-enabled使用Bitronix Transaction Manager时，是否强制写日志到磁盘，默认为true spring.jta.graceful-shutdown-interval当使用Bitronix Transaction Manager，指定shutdown时等待事务结束的时间，超过则中断，默认为60 spring.jta.jndi-transaction-synchronization-registry-name当使用Bitronix Transaction Manager时，在JNDI下得事务同步registry，默认为: java:comp/TransactionSynchronizationRegistry spring.jta.jndi-user-transaction-name指定在JNDI使用Bitronix Transaction Manager的名称，默认:java:comp/UserTransaction spring.jta.journal当使用Bitronix Transaction Manager，指定The journal是否disk还是null还是一个类的全限定名，默认disk spring.jta.log-dirTransaction logs directory. spring.jta.log-part1-filename指定The journal fragment文件1的名字，默认: btm1.tlog spring.jta.log-part2-filename指定The journal fragment文件2的名字，默认: btm2.tlog spring.jta.max-log-size-in-mb指定journal fragments大小的最大值. 默认: 2M spring.jta.resource-configuration-filename指定Bitronix Transaction Manager配置文件名. spring.jta.server-id指定Bitronix Transaction Manager实例的id. spring.jta.skip-corrupted-logs是否忽略corrupted log files文件，默认为false. spring.jta.transaction-manager-id指定Transaction manager的唯一标识. spring.jta.warn-about-zero-resource-transaction当使用Bitronix Transaction Manager时，是否对没有使用指定资源的事务进行警告，默认为: true]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Boot中使用Swagger2构建强大的RESTful API文档]]></title>
      <url>%2F2017%2FSpringboot2-Swagger%2F</url>
      <content type="text"><![CDATA[摘要:Swagger2，它可以轻松的整合到Spring Boot中，并与Spring MVC程序配合组织出强大RESTful API文档。它既可以减少我们创建文档的工作量，同时说明内容又整合入实现代码中，让维护文档和修改代码整合为一体，可以让我们在修改代码逻辑的同时方便的修改文档说明。另外Swagger2也提供了强大的页面测试功能来调试每个RESTful API。 正文:具体效果如下图所示：下面来具体介绍，如何在Spring Boot中使用Swagger2。 添加Swagger2依赖在pom.xml中加入Swagger2的依赖1234567891011&lt;!-- Swagger2的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt; 创建Swagger2配置类在Application.java同级创建Swagger2的配置类Swagger2。1234567891011121314151617181920@Configuration@EnableSwagger2public class Swagger2 &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage("com.ysstech.micro.web")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title("Spring Boot中使用Swagger2构建RESTful APIs") .contact("ysstech") .version("1.0") .build(); &#125;&#125; 如上代码所示，通过@Configuration注解，让Spring来加载该类配置。再通过@EnableSwagger2注解来启用Swagger2。 再通过createRestApi函数创建Docket的Bean之后，apiInfo()用来创建该Api的基本信息（这些基本信息会展现在文档页面中）。select()函数返回一个ApiSelectorBuilder实例用来控制哪些接口暴露给Swagger来展现，本例采用指定扫描的包路径来定义，Swagger会扫描该包下所有Controller定义的API，并产生文档内容（除了被@ApiIgnore指定的请求）。 添加文档内容在完成了上述配置后，其实已经可以生产文档内容，但是这样的文档主要针对请求本身，而描述主要来源于函数等命名产生，对用户并不友好，我们通常需要自己增加一些说明来丰富文档内容。如下所示，我们通过@ApiOperation注解来给API增加说明、通过@ApiImplicitParams、@ApiImplicitParam注解来给参数增加说明。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879@RestController @RequestMapping(value="/user")/** * Spring Boot：约定优于配置 * Spring Boot构建RESTful API * */public class UserController &#123; @Autowired UsersService UsersService=null; @ApiOperation(value="获取用户列表",notes="") @RequestMapping(value="/", method=RequestMethod.GET) public ResponseInfo getUserList() throws Exception&#123; // 处理"/users/"的GET请求，用来获取用户列表 ResponseInfo resInfo = new ResponseInfo(); List&lt;Users&gt; list = new ArrayList&lt;Users&gt;(); resInfo.setResponseInfo(list); return resInfo; &#125; @ApiOperation(value="获取用户详细信息",notes="根据url的id来获取用户详细信息") @ApiImplicitParam(name="id",value="用户ID",required=true,dataType="int",paramType="path") @RequestMapping(value="/&#123;id&#125;", method=RequestMethod.GET) public ResponseInfo getUser(@PathVariable int id) throws Exception&#123; ResponseInfo resInfo = new ResponseInfo(); //List&lt;Users&gt; list = new ArrayList&lt;Users&gt;(); Users user =UsersService.selectByPrimaryKey(id); resInfo.setResponseInfo(user); return resInfo; &#125; @ApiOperation(value="创建用户",notes="根据User对象创建用户") @ApiImplicitParam(name="user",value="用户详细实体user",required=true) @RequestMapping(value="/", method=RequestMethod.POST) public ResponseInfo postUser(@RequestBody Users user) throws Exception&#123; // 处理"/users/"的POST请求，用来创建User ResponseInfo resInfo = new ResponseInfo(); UsersService.insert(user); return resInfo; &#125; @ApiOperation(value="更新用户详细信息", notes="根据url的id来指定更新对象，并根据传过来的user信息来更新用户详细信息") @ApiImplicitParams(&#123; @ApiImplicitParam(name = "id", value = "用户ID", required = true, dataType = "int",paramType="path"), @ApiImplicitParam(name = "user", value = "用户详细实体user", required = true, dataType = "User") &#125;) @RequestMapping(value="/&#123;id&#125;", method=RequestMethod.PUT) public ResponseInfo putUser(@PathVariable int id, @RequestBody Users user) throws Exception&#123; // 处理"/users/&#123;id&#125;"的PUT请求，用来更新User信息 ResponseInfo resInfo = new ResponseInfo(); List&lt;Users&gt; list = new ArrayList&lt;Users&gt;(); Users user1 = list.get(id); user1.setAge(user.getAge()); user1.setId(user.getId()); user1.setName(user.getName()); resInfo.setResponseInfo(list); return resInfo; &#125; @ApiOperation(value="删除用户", notes="根据url的id来指定删除对象") @ApiImplicitParam(name = "id", value = "用户ID", required = true, dataType = "int",paramType="path") @RequestMapping(value="/&#123;id&#125;", method=RequestMethod.DELETE) public ResponseInfo deleteUser(@PathVariable int id) throws Exception&#123; // 处理"/users/&#123;id&#125;"的DELETE请求，用来删除User ResponseInfo resInfo = new ResponseInfo(); List&lt;Users&gt; list = new ArrayList&lt;Users&gt;(); list.remove(id); resInfo.setResponseInfo(list); return resInfo; &#125; &#125; 完成上述代码添加上，启动Spring Boot程序，访问：http://localhost:8088/demojar/swagger-ui.html(加的有根目录demojar)。就能看到前文所展示的RESTful API的页面。我们可以再点开具体的API请求，以POST类型的/users请求为例，可找到上述代码中我们配置的Notes信息以及参数user的描述信息，如下图所示。 API文档访问与调试在上图请求的页面中，我们看到user的Value是个输入框？是的，Swagger除了查看接口功能外，还提供了调试测试功能，我们可以点击上图中右侧的Model Schema（黄色区域：它指明了User的数据结构），此时Value中就有了user对象的模板，我们只需要稍适修改，点击下方“Try it out！”按钮，即可完成了一次请求调用！ 此时，你也可以通过几个GET请求来验证之前的POST请求是否正确。 相比为这些接口编写文档的工作，我们增加的配置内容是非常少而且精简的，对于原有代码的侵入也在忍受范围之内。因此，在构建RESTful API的同时，加入swagger来对API文档进行管理，是个不错的选择。 下面说下在项目使用中遇到的问题：按照以上demo的配置访问swagger-ui.html是404状态(error:No mapping found for HTTP request with URI [/swagger-ui.html])，最后在github上提的Issues上找到了答案 链接：https://github.com/springfox/springfox/issues/776问题是15年提的，最后有解决办法，不知道我项目是没配置对还是什么情况用的最新版本的jar没有加载到。解决办法是在Swagger2类加上@EnableWebMv或者继承WebMvcConfigurationSupport然后重写addResourceHandlers()方法解决了加载不到404问题123456789101112131415161718192021222324252627282930313233@Configuration@EnableSwagger2/** * 继承是加路径是无奈之举 默认是不需要继承 * */public class Swagger2 extends WebMvcConfigurationSupport &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors .basePackage("com.ysstech.micro.web")) .paths(PathSelectors.any()).build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title("Spring Boot中使用Swagger2构建RESTful APIs") .contact("ysstech").version("1.0").build(); &#125; @Override protected void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler("/swagger-ui.html").addResourceLocations( "classpath:/META-INF/resources/"); registry.addResourceHandler("/webjars/**").addResourceLocations( "classpath:/META-INF/resources/webjars/"); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Boot 静态资源处理]]></title>
      <url>%2F2017%2FSpringboot3-Static-Resources%2F</url>
      <content type="text"><![CDATA[摘要:spring Boot 默认的处理方式就已经足够了，默认情况下Spring Boot 使用WebMvcAutoConfiguration中配置的各种属性。但是如果你想要自己配置一些项目的设置，你可以在@Configuration注解的配置类上增加@EnableWebMvc或者继承WebMvcConfigurationSupport和WebMvcConfigurationAdapter 正文:首先解析@EnableWebMvc 、WebMvcConfigurationSupport和WebMvcConfigurerAdapter #在spring-boot+spring mvc 的项目中，有些时候我们需要自己配置一些项目的设置，就会涉及到这三个，那么，他们之间有什么关系呢？首先，@EnableWebMvc=WebMvcConfigurationSupport，使用了@EnableWebMvc注解等于扩展了WebMvcConfigurationSupport但是没有重写任何方法，所以有以下几种使用方式： @EnableWebMvc+extends WebMvcConfigurerAdapter，在扩展的类中重写父类的方法即可，这种方式会屏蔽springboot的@EnableAutoConfiguration中的设置 extends WebMvcConfigurationSupport，在扩展的类中重写父类的方法即可，这种方式会屏蔽springboot的@EnableAutoConfiguration中的设置 extends WebMvcConfigurerAdapter，在扩展的类中重写父类的方法即可，这种方式依旧使用springboot的@EnableAutoConfiguration中的设置 具体哪种方法适合，看个人对于项目的需求和要把控的程度，在WebMvcConfigurationSupport（@EnableWebMvc）和@EnableAutoConfiguration这两种方式都有一些默认的设定，而WebMvcConfigurationAdapter则是一个abstract class。具体如何类内如何进行个性化的设置，可以参考以下文章： Spring Boot：定制HTTP消息转换器 EnableWebMvc官方文档 然后重写addResourceHandlers方法12345678//例如对Swagger资源处理@Overridepublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler("/swagger-ui.html").addResourceLocations( "classpath:/META-INF/resources/"); registry.addResourceHandler("/webjars/**").addResourceLocations( "classpath:/META-INF/resources/webjars/");&#125; 至于是继承WebMvcConfigurationSupport还是WebMvcConfigurerAdapter看个人需求。 Swagger路径问题在使用Swagger时候是正常可以访问的在加入Security后发现若不排除Swagger-ui.html则资源权限不足401的问题，最后发现路径并不是springfox-swagger-ui.jar下的webjar/xxx，而是/swagger-resources/xx和/v2/xx:这样就可以正常访问Swagger的ui界面啦]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于Java变量的可见性问题]]></title>
      <url>%2F2017%2Fjavase-Java-volatile%2F</url>
      <content type="text"><![CDATA[摘要:关于java变量在工作内存和主存中的可见性问题 正文:123456789101112131415161718192021222324252627282930313233343536373839package com.test;import java.util.concurrent.TimeUnit; public class test1 &#123; private static boolean is = true; public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; int i = 0; while(test1.is)&#123; i++; //synchronized (this) &#123; &#125; 会强制刷新主内存的变量值到线程栈? //System.out.println("1"); println 是synchronized 的,会强制刷新主内存的变量值到线程栈? //sleep 会从新load主内存的值? // try &#123; // TimeUnit.MICROSECONDS.sleep(1); // &#125;catch (InterruptedException e) &#123; // e.printStackTrace(); // &#125; &#125; &#125; &#125;).start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; new Thread(new Runnable() &#123; @Override public void run() &#123; is = false; //设置is为false，使上面的线程结束while循环 &#125; &#125;).start(); &#125;&#125; 问： 为什么整个程序不会终止？ 为什么取消注释中的任何一个代码块(1，2，3)，程序才会终止？synchronized 会强制刷新住内存的变量值到线程栈? sleep 会干什么呢？涉及知识解释 volatile：此关键字保证了变量在线程的可见性，所有线程访问由volatile修饰的变量，都必须从主存中读取后操作，并在工作内存修改后立即写回主存，保证了其他线程的可见性，同样效果的关键字还有final。 synchronized：所有同步操作都必须保证 1、原子性 2、可见性，所以在同步块中发生的变化会立马写回主存 sleep：此方法只会让出CPU执行时间，并不会释放锁。 问题分析Q1：为什么注释代码后程序不会终止？ A1：因为 boolean is=true 的变量值被前面线程（简称线程A）加载到自己的工作内存，在后面的线程（简称线程B）改变 boolean is=false 之后不一定会立马写入主存(不过这道题中应该会马上写入主存，因为线程执行完 is=false之后线程就要退出了)，即便立马写入了主存后线程A也不一定马上load到工作内存中，所以程序一直不会终止？这个是我们大多数人想到的，但其实JVM针对现在的硬件水平已经做了很大程度的优化，基本上很大程度的保障了工作内存和主内存的及时同步，相当于默认使用了volatile。但只是最大程度！在CPU资源一直被占用的时候，工作内存与主内存中间的同步，也就是变量的可见性就会不那么及时！后面会验证结论。 Q2：为什么取消注释中的任何一个代码块(1，2，3)，程序才会终止？ A2：行号为1、2的代码有一个共同特点，就是都涉及到了synchronized 同步锁，那么是否像提问作者猜想的那样synchronized会强制刷新主内存的变量值到线程栈？，以及sleep方法也会刷新主存的变量值到线程栈呢？，事实上我们前面说了synchronized只会保证在同步块中的变量的可见性，而is变量并不在该同步块中，所以显然不是这个导致的。接下来我们在代码i++;后面加上以下代码： 123for(int k=0;k&lt;100000;k++)&#123; new Object();&#125; 再Run，程序立刻终止！为什么？在上面的 A1 中我们已经说了即便有JVM的优化，但当CPU一直被占用的时候，数据的可见性得不到很好的保证，就像上面的程序一直循环做i++;运算占用CPU，而为什么加上上面的代码后程序就会停止呢？因为对于大量new Object()操作来说，CPU已经不是主要占时间的操作，真正的耗时应该在内存的分配上（因为CPU的处理速度明显快过内存，不然也不会有CPU的寄存器了），所以CPU空闲后会遵循JVM优化基准，尽可能快的保证数据的可见性，从而从主存同步is变量到工作内存，最终导致程序结束，这也是为什么sleep()方法虽然没有涉及同步操作，但是依然可以使程序终止，因为sleep()方法会释放CPU，但不释放锁！ 结束]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL5.7安装常见问题]]></title>
      <url>%2F2017%2Fdatabase-mysql-install%2F</url>
      <content type="text"><![CDATA[摘要:从MySQL 5.7开始没有data文件夹，如果不进行初始化的话，mysql服务是无法启动的 正文:MySQL的安装 去官网下载zip格式的Mysql Server的压缩包（绿色版），根据个人电脑选择x86或者x64版本，点击最下面的跳过登录下载。 解压，复制my-dafault.ini到bin目录下，重命名为my.ini。可以根据需要复制以下内容： 12345678910111213141516[mysql]# 设置mysql客户端默认字符集default-character-set=utf8 [mysqld]#设置3306端口port = 3306 # 设置mysql的安装目录basedir=D:\mysql\mysql-5.6.35-winx64# 设置mysql数据库的数据的存放目录datadir=D:\mysql\mysql-5.6.35-winx64\data# 允许最大连接数max_connections=200# 服务端使用的字符集默认为8比特编码的latin1字符集character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB 从MySQL5.7开始，MySQL没有5.6那么易用，没有data文件夹使网上很多配置方法都会失效，如果不进行初始化的话，mysql服务是无法启动的 以管理员身份运行cmd，cd到mysql的bin目录下，执行命令：mysqld –initialize –user=mysql –console 该命令会去创建data目录与数据库，生成root用户和临时密码，在执行后的最后一行：localhost: xxxxxx 配置环境变量，将bin所在的文件夹路径添加到path的最后，例如： path=..xxx；D:\mysql\mysql-5.6.35-winx64\bin\my.ini 运行cmd，输入net start mysql启动mysql服务，再输入mysql -u root -p,然后输入临时密码。修改密码：set password=password(‘新密码’);，然后回车，注意分号不要忽略。卸载 关闭服务以管理员身份运行cmd，执行： 1net stop mysql 卸载 1mysqld -remove [服务名] 删除文件 删除注册表信息清除注册表中的该MySQL服务，有几个地方:a、HKEY_LOCAL_MACHINE\SYSTEM\ControlSet001\Services\Eventlog\Application\MySQL 目录删除b、HKEY_LOCAL_MACHINE\SYSTEM\ControlSet002\Services\Eventlog\Application\MySQL 目录删除c、HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Eventlog\Application\MySQL 目录删除注册表中的ControlSet001、ControlSet002不一定是001和002，可能是ControlSet005、006之类，删除的时候都删除就可以 。常见问题 data文件错误MySQL服务正在启动..MySQL服务无法启动。 服务没有报告任何错误。原因：原因：一般初始化之前已存在data文件就会出现这个错误，或者data文件缺少了某些文件 解决：先执行mysqld -remove，然后把data文件删除，如果删除不了重启一下就可以了，之后重新进行安装就没问题了。如果想保留之前的data文件，可以先把data文件拷贝到其他地方，安装好之后再将原data文件中多的文件拷贝进去就行了 密码错误（Error password Error 1045…Access denied）原因1：使用mysqld –initialize方法安装会生成一个随机字符串组成的密码，这个密码在错误日志D:\mysql\mysql-5.6.35-winx64\data\xxx.err（xxx是用户名）可以找到。原因2：忘记密码解决：如果忘记密码或找不到随机密码，可以通过以下方法跳过权限修改密码以管理员身份运行cmd，执行以下命令： 12net stop mysql//关闭服务mysqld --skip-grant-tables;//设置mysql登录--skip-grant-tables模式 打开一个新的cmd 1234mysql//直接登录mysql update mysql.user set authentication_string=password('123456') where user='root' and Host = 'localhost';//修改密码 //特别提醒注意的一点是，新版的mysql数据库下的user表中已经没有Password字段了，而是将加密后的用户密码存储于authentication_string字段 flush privileges;//刷新权限，退出--skip-grant-tables模式，很重要！ 重启电脑，然后mysql就可以连接了但是此时操作似乎功能不完全，还要在登录状态下修改一次密码12345alter user 'root'@'localhost' identified by '123456';还可以这样：set password for 'root'@'localhost'=password('123456')；或这样：set password=password('123456'); 其实mysql的安装卸载过程很简单，一般出了问题之后，把data文件备份后重装，然后把原data中的数据库文件拷贝回来就可以了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker在Ubuntu下私服搭建]]></title>
      <url>%2F2017%2FDocker-registry%2F</url>
      <content type="text"><![CDATA[摘要:docker同maven一样，虽然有中央仓库，但是都不是国内的下载速度较慢影响开发进度（当然maven可以配置阿里云的镜像速度很快）。 正文:一、我们希望构建和存储包含不想被公开的信息或数据的镜像。这个时候我们有以下两种选择：1.利用docker hub上的私有仓库。（下载速度较慢不适合企业开发）2.在防火墙后面运行自己的Registry(如开发环境的内网)。二、从Docker容器安装一个Registry非常简单，运行docker提供的容器即可。 1sudo docker run -p 5000:5000 registry:2 说明：若之前没有安装registry容器则会自动下载并启动一个registry容器，创建本地的私有仓库服 务。三、接下来需要为镜像打上标签：例如hello-world 1sudo docker tag hello-world localhost:5000/hello-world 然后doker images则会看到：localhost:5000/hello-world这个镜像四、随后我们将此镜像push到registry 1sudo docker push localhost:5000/hello-world 五、最后可以通过访问http://ip:port/v2/hello-world/tags/list来查看返回的json串是否存在hello-world六、同样，客户端则是通过： 1sudo docker pull ip:5000/hello-world来获取镜像到本地 以上是一个大概的安装过程，网上都有，重要的是一些碰到的bug需要配置一些东西（版本不同配置也不同，本人是docker version：1.12.1 registry version:v2）bug1：Error response from daemon: Get https://IP:5000/v1/_ping: http: server gave HTTP response to HTTPS client解决方案：echo ‘{ “insecure-registries”:[“你的IP:5000”] }’ /etc/docker/daemon.jsoncat /etc/docker/daemon.json { “insecure-registries”:[“你的IP:5000”] }然后重启daemon 1sodo /etc/init.d/docker restart 来获取镜像到本地随后会一直更新….]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于SpringBoot bean无法注入的问题]]></title>
      <url>%2F2017%2FSpringboot1%2F</url>
      <content type="text"><![CDATA[摘要:Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程 正文:今天初次使用springboot搭建了Demo，联合mybatis时候(因为连接数据库需要创建vo层)出现bean无法导入的问题。网上谷歌了下后来找到了一个很容易忽视的原因。这个是我的包结构，注意Application的位置，刚开始我并没有放在现在这个位置，而是和bean以及接口UserMapper是平行的包下。然后就报了Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}这个错 关于SpringBoot bean无法注入的问题将Application放在了最外层的包才解决问题。 原因是：SpringBoot项目的Bean装配默认规则是根据Application类所在的包位置从上往下扫描！所以一定要放在最外层！]]></content>
    </entry>

    
  
  
</search>
